# Arxiv Results
## Keyword: kv cache 
 ### MCBP: A Memory-Compute Efficient LLM Inference Accelerator Leveraging   Bit-Slice-enabled Sparsity and Repetitiveness
**Authors**: Huizheng Wang, Zichuan Wang, Zhiheng Yue, Yousheng Long, Taiquan Wei, Jianxun Yang, Yang Wang, Chao Li, Shaojun Wei, Yang Hu, Shouyi Yin

**Updated**: 2025-09-12T16:05:27Z

**Summary**: Large language models (LLMs) face significant inference latency due to inefficiencies in GEMM operations, weight access, and KV cache access, especially in real-time scenarios. This highlights the need for a versatile compute-memory efficient accelerator. Unfortunately, existing Transformer accelerators struggle to address both aspects simultaneously, as they focus on value-level processing, missing fine-grained opportunities to optimize computation and memory collaboratively. This paper introduces MCBP, a bit-grained compute-memory efficient algorithm-hardware co-design that leverages bit-slice (BS) enabled repetitiveness and sparsity to accelerate LLM inference. MCBP features three key innovations: 1) BS-repetitiveness-enabled computation reduction (BRCR), which eliminates redundant GEMM computations via leveraging redundancy hidden among BS vectors; 2) BS-sparsity-enabled two-state coding (BSTC), which reduces weight access via exploiting significant sparsity in high-order bit-slice weight; 3) Bit-grained progressive prediction (BGPP), which reduces KV cache access by leveraging early-termination-based bit-grained prediction. These techniques, supported by custom accelerator designs, effectively alleviate the burden in GEMM, weight access, and KV cache access. Extensive experiments on 26 benchmarks show that MCBP achieves 9.43x speed up and 31.1x higher energy efficiency than Nvidia A100 GPU. Compared to SOTA Transformer accelerators, MCBP achieves 35x, 5.2x and 3.2x energy saving than Spatten, FACT and SOFA, respectively.

**Link**: [arxiv](http://arxiv.org/abs/2509.10372v1),  [pdf](http://arxiv.org/pdf/2509.10372v1)

**Tags**: cs.AR 



### Compute Only 16 Tokens in One Timestep: Accelerating Diffusion   Transformers with Cluster-Driven Feature Caching
**Authors**: Zhixin Zheng, Xinyu Wang, Chang Zou, Shaobo Wang, Linfeng Zhang

**Updated**: 2025-09-12T14:53:45Z

**Summary**: Diffusion transformers have gained significant attention in recent years for their ability to generate high-quality images and videos, yet still suffer from a huge computational cost due to their iterative denoising process. Recently, feature caching has been introduced to accelerate diffusion transformers by caching the feature computation in previous timesteps and reusing it in the following timesteps, which leverage the temporal similarity of diffusion models while ignoring the similarity in the spatial dimension. In this paper, we introduce Cluster-Driven Feature Caching (ClusCa) as an orthogonal and complementary perspective for previous feature caching. Specifically, ClusCa performs spatial clustering on tokens in each timestep, computes only one token in each cluster and propagates their information to all the other tokens, which is able to reduce the number of tokens by over 90%. Extensive experiments on DiT, FLUX and HunyuanVideo demonstrate its effectiveness in both text-to-image and text-to-video generation. Besides, it can be directly applied to any diffusion transformer without requirements for training. For instance, ClusCa achieves 4.96x acceleration on FLUX with an ImageReward of 99.49%, surpassing the original model by 0.51%. The code is available at https://github.com/Shenyi-Z/Cache4Diffusion.

**Link**: [arxiv](http://arxiv.org/abs/2509.10312v1),  [pdf](http://arxiv.org/pdf/2509.10312v1)

**Tags**: cs.CV 



### XBOF: A Cost-Efficient CXL JBOF with Inter-SSD Compute Resource Sharing
**Authors**: Shushu Yi, Yuda An, Li Peng, Xiurui Pan, Qiao Li, Jieming Yin, Guangyan Zhang, Wenfei Wu, Diyu Zhou, Zhenlin Wang, Xiaolin Wang, Yingwei Luo, Ke Zhou, Jie Zhang

**Updated**: 2025-09-12T13:49:27Z

**Summary**: Enterprise SSDs integrate numerous computing resources (e.g., ARM processor and onboard DRAM) to satisfy the ever-increasing performance requirements of I/O bursts. While these resources substantially elevate the monetary costs of SSDs, the sporadic nature of I/O bursts causes severe SSD resource underutilization in just a bunch of flash (JBOF) level. Tackling this challenge, we propose XBOF, a cost-efficient JBOF design, which only reserves moderate computing resources in SSDs at low monetary cost, while achieving demanded I/O performance through efficient inter-SSD resource sharing. Specifically, XBOF first disaggregates SSD architecture into multiple disjoint parts based on their functionality, enabling fine-grained SSD internal resource management. XBOF then employs a decentralized scheme to manage these disaggregated resources and harvests the computing resources of idle SSDs to assist busy SSDs in handling I/O bursts. This idea is facilitated by the cache-coherent capability of Compute eXpress Link (CXL), with which the busy SSDs can directly utilize the harvested computing resources to accelerate metadata processing. The evaluation results show that XBOF improves SSD resource utilization by 50.4% and saves 19.0% monetary costs with a negligible performance loss, compared to existing JBOF designs.

**Link**: [arxiv](http://arxiv.org/abs/2509.10251v1),  [pdf](http://arxiv.org/pdf/2509.10251v1)

**Tags**: cs.OS 



### SvalMIZ-25 Svalbard Marginal Ice Zone Campaign 2025 -- Cruise Report
**Authors**: M. Müller, J. Rabault, C. Palerme, J. Tjernström

**Updated**: 2025-09-12T07:20:53Z

**Summary**: The coupling of weather, sea-ice, ocean, and wave forecasting systems has been a long-standing research focus to improve Arctic forecasting systems and their realism and is also a priority of international initiatives such as the WMO research project PCAPS. The goal of the Svalbard Marginal Ice Zone 2025 Campaign (SvalMIZ-25) was to observe and better understand the complex interplay between atmosphere, waves, and sea-ice in the winter Marginal Ice Zone (MIZ) in order to advance predictive skill of coupled Arctic forecasting systems. The main objective has been to set up a network of observations with a spatial distribution that allows for a representative comparison between in situ observations and gridded model data. The observed variables include air and surface temperature, sea-ice drift, and wave energy spectra. With the support of the Norwegian Coast Guard, we participated in the research cruise with KV Svalbard from 22.April - 11.May 2025. In total 21 buoys were deployed in the Marginal Ice Zone north of the Svalbard Archipelago.

**Link**: [arxiv](http://arxiv.org/abs/2509.10016v1),  [pdf](http://arxiv.org/pdf/2509.10016v1)

**Tags**: physics.ao-ph 



### LAVa: Layer-wise KV Cache Eviction with Dynamic Budget Allocation
**Authors**: Yiqun Shen, Song Yuan, Zhengze Zhang, Xiaoliang Wang, Daxin Jiang, Nguyen Cam-Tu

**Updated**: 2025-09-11T16:48:24Z

**Summary**: KV Cache is commonly used to accelerate LLM inference with long contexts, yet its high memory demand drives the need for cache compression. Existing compression methods, however, are largely heuristic and lack dynamic budget allocation. To address this limitation, we introduce a unified framework for cache compression by minimizing information loss in Transformer residual streams. Building on it, we analyze the layer attention output loss and derive a new metric to compare cache entries across heads, enabling layer-wise compression with dynamic head budgets. Additionally, by contrasting cross-layer information, we also achieve dynamic layer budgets. LAVa is the first unified strategy for cache eviction and dynamic budget allocation that, unlike prior methods, does not rely on training or the combination of multiple strategies. Experiments with benchmarks (LongBench, Needle-In-A-Haystack, Ruler, and InfiniteBench) demonstrate its superiority. Moreover, our experiments reveal a new insight: dynamic layer budgets are crucial for generation tasks (e.g., code completion), while dynamic head budgets play a key role in extraction tasks (e.g., extractive QA). As a fully dynamic compression method, LAVa consistently maintains top performance across task types. Our code is available at https://github.com/MGDDestiny/Lava.

**Link**: [arxiv](http://arxiv.org/abs/2509.09754v1),  [pdf](http://arxiv.org/pdf/2509.09754v1)

**Tags**: cs.LG cs.AI 



### TrEnv: Transparently Share Serverless Execution Environments Across   Different Functions and Nodes
**Authors**: Jialiang Huang, Teng Ma, Zheng Liu, Sixing Lin, Kang Chen, Jinlei Jiang, Xia Liao, Yingdi Shan, Yongwei Wu, Ning Zhang, Mengting Lu, Tao Ma, Haifeng Gong, Mingxing Zhang

**Updated**: 2025-09-11T15:06:03Z

**Summary**: Serverless computing provides dynamic scalability, but its infrastructure overhead becomes a bottleneck for emerging workloads such as LLM agents, which exhibit unpredictable invocation patterns and variable resource demands. Our analysis shows that for these agents, the cost of running on serverless platforms can reach up to 70% of the cost of LLM API calls. This finding motivates the need for a more efficient, high-density serverless platform. We present TrEnv, a co-designed serverless platform that supports both container- and VM-based environments, optimized for the unique demands of LLM agents. TrEnv reduces startup latency and memory usage through repurposable sandboxes and memory templates, which enable fast reuse and restoration of execution environments. To further reduce overhead in VM-based agent workloads, TrEnv leverages browser sharing and a page cache bypassing mechanism. Evaluations show that TrEnv reduces P99 latency by up to 7X and memory usage by 48% in container-based settings, and achieves up to 58% lower P99 latency and 61% memory savings for VM-based agents compared to state-of-the-art systems like E2B.

**Link**: [arxiv](http://arxiv.org/abs/2509.09525v1),  [pdf](http://arxiv.org/pdf/2509.09525v1)

**Tags**: cs.DC cs.OS 



### In-Loop Filtering Using Learned Look-Up Tables for Video Coding
**Authors**: Zhuoyuan Li, Jiacheng Li, Yao Li, Jialin Li, Li Li, Dong Liu, Feng Wu

**Updated**: 2025-09-11T14:34:01Z

**Summary**: In-loop filtering (ILF) is a key technology in video coding standards to reduce artifacts and enhance visual quality. Recently, neural network-based ILF schemes have achieved remarkable coding gains, emerging as a powerful candidate for next-generation video coding standards. However, the use of deep neural networks (DNN) brings significant computational and time complexity or high demands for dedicated hardware, making it challenging for general use. To address this limitation, we study a practical ILF solution by adopting look-up tables (LUTs). After training a DNN with a restricted reference range for ILF, all possible inputs are traversed, and the output values of the DNN are cached into LUTs. During the coding process, the filtering process is performed by simply retrieving the filtered pixel through locating the input pixels and interpolating between the cached values, instead of relying on heavy inference computations. In this paper, we propose a universal LUT-based ILF framework, termed LUT-ILF++. First, we introduce the cooperation of multiple kinds of filtering LUTs and propose a series of customized indexing mechanisms to enable better filtering reference perception with limited storage consumption. Second, we propose the cross-component indexing mechanism to enable the filtering of different color components jointly. Third, in order to make our solution practical for coding uses, we propose the LUT compaction scheme to enable the LUT pruning, achieving a lower storage cost of the entire solution. The proposed framework is implemented in the VVC reference software. Experimental results show that the proposed framework achieves on average 0.82%/2.97%/1.63% and 0.85%/4.11%/2.06% bitrate reduction for common test sequences, under the AI and RA configurations, respectively. Compared to DNN-based solutions, our proposed solution has much lower time complexity and storage cost.

**Link**: [arxiv](http://arxiv.org/abs/2509.09494v1),  [pdf](http://arxiv.org/pdf/2509.09494v1)

**Tags**: eess.IV cs.CV cs.MM 



### VFlowOpt: A Token Pruning Framework for LMMs with Visual Information   Flow-Guided Optimization
**Authors**: Sihan Yang, Runsen Xu, Chenhang Cui, Tai Wang, Dahua Lin, Jiangmiao Pang

**Updated**: 2025-09-11T12:06:49Z

**Summary**: Large Multimodal Models (LMMs) excel in visual-language tasks by leveraging numerous visual tokens for fine-grained visual information, but this token redundancy results in significant computational costs. Previous research aimed at reducing visual tokens during inference typically leverages importance maps derived from attention scores among vision-only tokens or vision-language tokens to prune tokens across one or multiple pruning stages. Despite this progress, pruning frameworks and strategies remain simplistic and insufficiently explored, often resulting in substantial performance degradation. In this paper, we propose VFlowOpt, a token pruning framework that introduces an importance map derivation process and a progressive pruning module with a recycling mechanism. The hyperparameters of its pruning strategy are further optimized by a visual information flow-guided method. Specifically, we compute an importance map for image tokens based on their attention-derived context relevance and patch-level information entropy. We then decide which tokens to retain or prune and aggregate the pruned ones as recycled tokens to avoid potential information loss. Finally, we apply a visual information flow-guided method that regards the last token in the LMM as the most representative signal of text-visual interactions. This method minimizes the discrepancy between token representations in LMMs with and without pruning, thereby enabling superior pruning strategies tailored to different LMMs. Experiments demonstrate that VFlowOpt can prune 90% of visual tokens while maintaining comparable performance, leading to an 89% reduction in KV-Cache memory and 3.8 times faster inference.

**Link**: [arxiv](http://arxiv.org/abs/2508.05211v2),  [pdf](http://arxiv.org/pdf/2508.05211v2)

**Tags**: cs.CV 



### Universal Workers: A Vision for Eliminating Cold Starts in Serverless   Computing
**Authors**: Saman Akbari, Manfred Hauswirth

**Updated**: 2025-09-11T10:20:20Z

**Summary**: Serverless computing enables developers to deploy code without managing infrastructure, but suffers from cold start overhead when initializing new function instances. Existing solutions such as "keep-alive" or "pre-warming" are costly and unreliable under bursty workloads. We propose universal workers, which are computational units capable of executing any function with minimal initialization overhead. Based on an analysis of production workload traces, our key insight is that requests in Function-as-a-Service (FaaS) platforms show a highly skewed distribution, with most requests invoking a small subset of functions. We exploit this observation to approximate universal workers through locality groups and three-tier caching (handler, install, import). With this work, we aim to enable more efficient and scalable FaaS platforms capable of handling diverse workloads with minimal initialization overhead.

**Link**: [arxiv](http://arxiv.org/abs/2505.19880v2),  [pdf](http://arxiv.org/pdf/2505.19880v2)

**Tags**: cs.DC cs.PF 



### Spotlight Attention: Towards Efficient LLM Generation via Non-linear   Hashing-based KV Cache Retrieval
**Authors**: Wenhao Li, Yuxin Zhang, Gen Luo, Haiyuan Wan, Ziyang Gong, Fei Chao, Rongrong Ji

**Updated**: 2025-09-11T06:45:58Z

**Summary**: Reducing the key-value (KV) cache burden in Large Language Models (LLMs) significantly accelerates inference. Dynamically selecting critical KV caches during decoding helps maintain performance. Existing methods use random linear hashing to identify important tokens, but this approach is inefficient due to the orthogonal distribution of queries and keys within two narrow cones in LLMs. We introduce Spotlight Attention, a novel method that employs non-linear hashing functions to optimize the embedding distribution of queries and keys, enhancing coding efficiency and robustness. We also developed a lightweight, stable training framework using a Bradley-Terry ranking-based loss, enabling optimization of the non-linear hashing module on GPUs with 16GB memory in 8 hours. Experimental results show that Spotlight Attention drastically improves retrieval precision while shortening the length of the hash code at least 5$\times$ compared to traditional linear hashing. Finally, we exploit the computational advantages of bitwise operations by implementing specialized CUDA kernels, achieving hashing retrieval for 512K tokens in under 100$\mu$s on a single A100 GPU, with end-to-end throughput up to 3$\times$ higher than vanilla decoding.

**Link**: [arxiv](http://arxiv.org/abs/2508.19740v3),  [pdf](http://arxiv.org/pdf/2508.19740v3)

**Tags**: cs.CL 



### Bidirectional Sparse Attention for Faster Video Diffusion Training
**Authors**: Chenlu Zhan, Wen Li, Chuyu Shen, Jun Zhang, Suhui Wu, Hao Zhang

**Updated**: 2025-09-11T06:16:31Z

**Summary**: Video diffusion Transformer (DiT) models excel in generative quality but hit major computational bottlenecks when producing high-resolution, long-duration videos. The quadratic complexity of full attention leads to prohibitively high training and inference costs. Full attention inefficiency stems from two key challenges: excessive computation due to the inherent sparsity of Queries and Key-Value pairs, and redundant computation as fixed sparse patterns fail to leverage DiT's dynamic attention. To overcome this limitation, we propose a Bidirectional Sparse Attention (BSA) framework for faster video DiT training, the first to dynamically sparsify both Queries and Key-Value pairs within 3D full attention, thereby substantially improving training and inference efficiency. BSA addresses these issues through two key components. Query sparsity is optimized by selecting the most informative query tokens via semantic similarity and with a dynamic spatial-time training strategy, while KV sparsity is achieved by computing a statistical dynamic threshold to retain only the most salient KV blocks for computation. Extensive experiments demonstrate that BSA significantly accelerates DiT training across long sequences, reducing FLOPs by up to 20x and achieving 17.79x faster attention training, while preserving or even surpassing the generative quality of full attention.

**Link**: [arxiv](http://arxiv.org/abs/2509.01085v3),  [pdf](http://arxiv.org/pdf/2509.01085v3)

**Tags**: cs.CV 



### Coherence-Aware Task Graph Modeling for Realistic Application
**Authors**: Guochu Xiong, Xiangzhong Luo, Weichen Liu

**Updated**: 2025-09-11T02:00:27Z

**Summary**: As multicore systems continue to scale, cache coherence has emerged as a critical determinant of system performance, with coherence behavior and task execution closely intertwined, reshaping inter-task dependencies. Task graph modeling provides a structured way to capture such dependencies and serves as the foundation for many system-level design strategies. However, these strategies typically rely on predefined task graphs, while many real-world applications lack explicit graphs and exhibit dynamic, data-dependent behavior, limiting the effectiveness of static approaches. To address this, several task graph modeling methods for realistic workloads have been developed. Yet, they either rely on implicit techniques that use application-specific features without producing explicit graphs, or they generate graphs tailored to fixed scheduling models, which limits generality. More importantly, they often overlook coherence interactions, creating a gap between design assumptions and actual runtime behavior. To overcome these limitations, we propose CoTAM, a Coherence-Aware Task Graph Modeling framework for realistic workloads that constructs a unified task graph reflecting runtime behavior. CoTAM analyzes the impact of coherence by decoupling its effects from overall execution, quantifies its influence through a learned weighting scheme, and infers inter-task dependencies for coherence-aware graph generation. Extensive experiments show that CoTAM outperforms implicit methods, bridging the gap between dynamic workload behavior and existing designs while demonstrating the importance of incorporating cache coherence into task graph modeling for accurate and generalizable system-level analysis.

**Link**: [arxiv](http://arxiv.org/abs/2509.09094v1),  [pdf](http://arxiv.org/pdf/2509.09094v1)

**Tags**: cs.DC 



### TweakLLM: A Routing Architecture for Dynamic Tailoring of Cached   Responses
**Authors**: Muhammad Taha Cheema, Abeer Aamir, Khawaja Gul Muhammad, Naveed Anwar Bhatti, Ihsan Ayyub Qazi, Zafar Ayyub Qazi

**Updated**: 2025-09-10T17:59:08Z

**Summary**: Large Language Models (LLMs) process millions of queries daily, making efficient response caching a compelling optimization for reducing cost and latency. However, preserving relevance to user queries using this approach proves difficult due to the personalized nature of chatbot interactions and the limited accuracy of semantic similarity search. To address this, we present TweakLLM, a novel routing architecture that employs a lightweight LLM to dynamically adapt cached responses to incoming prompts. Through comprehensive evaluation, including user studies with side-by-side comparisons, satisfaction voting, as well as multi-agent LLM debates, we demonstrate that TweakLLM maintains response quality comparable to frontier models while significantly improving cache effectiveness. Our results across real-world datasets highlight TweakLLM as a scalable, resource-efficient caching solution for high-volume LLM deployments without compromising user experience.

**Link**: [arxiv](http://arxiv.org/abs/2507.23674v2),  [pdf](http://arxiv.org/pdf/2507.23674v2)

**Tags**: cs.LG cs.CL 



### Accelerating Diffusion Transformer-Based Text-to-Speech with Transformer   Layer Caching
**Authors**: Siratish Sakpiboonchit

**Updated**: 2025-09-10T15:41:15Z

**Summary**: This paper presents a method to accelerate the inference process of diffusion transformer (DiT)-based text-to-speech (TTS) models by applying a selective caching mechanism to transformer layers. Specifically, I integrate SmoothCache into the F5-TTS architecture, focusing on caching outputs of self-attention and feed-forward network layers to reduce redundant computations during the denoising process. A calibration phase is introduced to analyze L1 relative errors between timesteps, guiding the selection of cache schedules that minimize quality degradation. To address the problem of inter-layer dependency, a unified caching schedule is adopted, applying the cache pattern derived from self-attention layers to both layer types. Experiments on LibriSpeech-PC and Seed-TTS datasets evaluate various cache thresholds and denoising step configurations. Results show that caching at higher denoising steps reduces inference time without compromising output quality, whereas caching at lower steps can negatively impact synthesis quality similarly to reducing the total number of denoising steps. Objective and subjective metrics confirm the effectiveness of SmoothCache in maintaining performance while improving computational efficiency. Comparisons between cached inference and reduced-step inference further highlight the benefits of selective caching, especially under high-step configurations. This work demonstrates that transformer layer caching is a practical solution for optimizing diffusion transformer-based TTS models without requiring architectural changes or retraining. Example inference results can be heard at https://siratish.github.io/F5-TTS_SmoothCache/ .

**Link**: [arxiv](http://arxiv.org/abs/2509.08696v1),  [pdf](http://arxiv.org/pdf/2509.08696v1)

**Tags**: eess.AS cs.SD 



### BitROM: Weight Reload-Free CiROM Architecture Towards Billion-Parameter   1.58-bit LLM Inference
**Authors**: Wenlun Zhang, Xinyu Li, Shimpei Ando, Kentaro Yoshioka

**Updated**: 2025-09-10T12:46:29Z

**Summary**: Compute-in-Read-Only-Memory (CiROM) accelerators offer outstanding energy efficiency for CNNs by eliminating runtime weight updates. However, their scalability to Large Language Models (LLMs) is fundamentally constrained by their vast parameter sizes. Notably, LLaMA-7B - the smallest model in LLaMA series - demands more than 1,000 cm2 of silicon area even in advanced CMOS nodes. This paper presents BitROM, the first CiROM-based accelerator that overcomes this limitation through co-design with BitNet's 1.58-bit quantization model, enabling practical and efficient LLM inference at the edge. BitROM introduces three key innovations: 1) a novel Bidirectional ROM Array that stores two ternary weights per transistor; 2) a Tri-Mode Local Accumulator optimized for ternary-weight computations; and 3) an integrated Decode-Refresh (DR) eDRAM that supports on-die KV-cache management, significantly reducing external memory access during decoding. In addition, BitROM integrates LoRA-based adapters to enable efficient transfer learning across various downstream tasks. Evaluated in 65nm CMOS, BitROM achieves 20.8 TOPS/W and a bit density of 4,967 kB/mm2 - offering a 10x improvement in area efficiency over prior digital CiROM designs. Moreover, the DR eDRAM contributes to a 43.6% reduction in external DRAM access, further enhancing deployment efficiency for LLMs in edge applications.

**Link**: [arxiv](http://arxiv.org/abs/2509.08542v1),  [pdf](http://arxiv.org/pdf/2509.08542v1)

**Tags**: cs.AR 



### Accelerating Mixture-of-Expert Inference with Adaptive Expert Split   Mechanism
**Authors**: Jiaming Yan, Jianchun Liu, Hongli Xu, Liusheng Huang

**Updated**: 2025-09-10T07:28:24Z

**Summary**: Mixture-of-Experts (MoE) has emerged as a promising architecture for modern large language models (LLMs). However, massive parameters impose heavy GPU memory (i.e., VRAM) demands, hindering the widespread adoption of MoE LLMs. Offloading the expert parameters to CPU RAM offers an effective way to alleviate the VRAM requirements for MoE inference. Existing approaches typically cache a small subset of experts in VRAM and dynamically prefetch experts from RAM during inference, leading to significant degradation in inference speed due to the poor cache hit rate and substantial expert loading latency. In this work, we propose MoEpic, an efficient MoE inference system with a novel expert split mechanism. Specifically, each expert is vertically divided into two segments: top and bottom. MoEpic caches the top segment of hot experts, so that more experts will be stored under the limited VRAM budget, thereby improving the cache hit rate. During each layer's inference, MoEpic predicts and prefetches the activated experts for the next layer. Since the top segments of cached experts are exempt from fetching, the loading time is reduced, which allows efficient transfer-computation overlap. Nevertheless, the performance of MoEpic critically depends on the cache configuration (i.e., each layer's VRAM budget and expert split ratio). To this end, we propose a divide-and-conquer algorithm based on fixed-point iteration for adaptive cache configuration. Extensive experiments on popular MoE LLMs demonstrate that MoEpic can save about half of the GPU cost, while lowering the inference latency by about 37.51%-65.73% compared to the baselines.

**Link**: [arxiv](http://arxiv.org/abs/2509.08342v1),  [pdf](http://arxiv.org/pdf/2509.08342v1)

**Tags**: cs.LG cs.AI 



### EvolKV: Evolutionary KV Cache Compression for LLM Inference
**Authors**: Bohan Yu, Yekun Chai

**Updated**: 2025-09-10T06:32:49Z

**Summary**: Existing key-value (KV) cache compression methods typically rely on heuristics, such as uniform cache allocation across layers or static eviction policies, however, they ignore the critical interplays among layer-specific feature patterns and task performance, which can lead to degraded generalization. In this paper, we propose EvolKV, an adaptive framework for layer-wise, task-driven KV cache compression that jointly optimizes the memory efficiency and task performance. By reformulating cache allocation as a multi-objective optimization problem, EvolKV leverages evolutionary search to dynamically configure layer budgets while directly maximizing downstream performance. Extensive experiments on 11 tasks demonstrate that our approach outperforms all baseline methods across a wide range of KV cache budgets on long-context tasks and surpasses heuristic baselines by up to 7 percentage points on GSM8K. Notably, EvolKV achieves superior performance over the full KV cache setting on code completion while utilizing only 1.5% of the original budget, suggesting the untapped potential in learned compression strategies for KV cache budget allocation.

**Link**: [arxiv](http://arxiv.org/abs/2509.08315v1),  [pdf](http://arxiv.org/pdf/2509.08315v1)

**Tags**: cs.LG cs.CL cs.NE 



### TokenSelect: Efficient Long-Context Inference and Length Extrapolation   for LLMs via Dynamic Token-Level KV Cache Selection
**Authors**: Wei Wu, Zhuoshi Pan, Chao Wang, Liyi Chen, Yunchu Bai, Tianfu Wang, Kun Fu, Zheng Wang, Hui Xiong

**Updated**: 2025-09-09T13:30:17Z

**Summary**: Rapid advances in Large Language Models (LLMs) have spurred demand for processing extended context sequences in contemporary applications. However, this progress faces two challenges: performance degradation due to sequence lengths out-of-distribution, and excessively long inference times caused by the quadratic computational complexity of attention. These issues limit LLMs in long-context scenarios. In this paper, we propose Dynamic Token-Level KV Cache Selection (TokenSelect), a training-free method for efficient and accurate long-context inference. TokenSelect builds upon the observation of non-contiguous attention sparsity, using QK dot products to measure per-head KV Cache criticality at token-level. By per-head soft voting mechanism, TokenSelect selectively involves a few critical KV cache tokens in attention calculation without sacrificing accuracy. To further accelerate TokenSelect, we design the Selection Cache based on observations of consecutive Query similarity and implemented the efficient Paged Dot Product Kernel, significantly reducing the selection overhead. A comprehensive evaluation of TokenSelect demonstrates up to $23.84\times$ speedup in attention computation and up to $2.28\times$ acceleration in end-to-end latency, while providing superior performance compared to state-of-the-art long-context inference methods.

**Link**: [arxiv](http://arxiv.org/abs/2411.02886v3),  [pdf](http://arxiv.org/pdf/2411.02886v3)

**Tags**: cs.CL cs.AI cs.LG 



### DuoServe-MoE: Dual-Phase Expert Prefetch and Cache Scheduling for   Efficient MoE LLM Inference
**Authors**: Yuning Zhang, Grant Pinkert, Nan Yang, Yanli Li, Dong Yuan

**Updated**: 2025-09-09T04:00:43Z

**Summary**: Large Language Models (LLMs) have demonstrated impressive performance across a wide range of deep learning tasks. Mixture of Experts (MoE) further enhances their capabilities by increasing model width through sparsely activated expert branches, which keeps inference computation efficient. However, the large number of expert weights introduces significant GPU memory pressure, especially in resource-constrained environments such as single-GPU servers. More importantly, MoE inference consists of two fundamentally different stages: a prefill stage where most experts are activated densely, and a decode stage where only a few experts are triggered sparsely. Treating these stages with a uniform scheduling strategy often leads to suboptimal latency and memory usage. To address this, we propose DuoServe-MoE, an inference serving system that explicitly separates prefill and decode stages and applies tailored expert scheduling strategies to each. In the prefill stage, DuoServe-MoE uses a two-stream CUDA pipeline that overlaps expert weight prefetching with the computation of non-MoE layers, limiting expert residency in GPU memory. In the decode stage, a lightweight layer-level predictor trained offline from activation traces is used to prefetch only the most likely activated experts, without requiring any changes to the model. Experiments on 4-bit Mixtral-8x7B and 8x22B models show that DuoServe-MoE improves end-to-end latency by 1.42 to 7.54 times while keeping peak memory usage at only 15 percent of the full model size.

**Link**: [arxiv](http://arxiv.org/abs/2509.07379v1),  [pdf](http://arxiv.org/pdf/2509.07379v1)

**Tags**: cs.DC 



### BOLT: Bandwidth-Optimized Lightning-Fast Oblivious Map powered by Secure   HBM Accelerators
**Authors**: Yitong Guo, Hongbo Chen, Haobin Hiroki Chen, Yukui Luo, XiaoFeng Wang, Chenghong Wang

**Updated**: 2025-09-09T00:15:05Z

**Summary**: While Trusted Execution Environments provide a strong foundation for secure cloud computing, they remain vulnerable to access pattern leakages. Oblivious Maps (OMAPs) mitigate this by fully hiding access patterns but suffer from high overhead due to randomized remapping and worst-case padding. We argue these costs are not fundamental. Modern accelerators featuring High-Bandwidth Memory (HBM) offer a new opportunity: Vaswani et al. [OSDI'18] point out that eavesdropping on HBM is difficult -- even for physical attackers -- as its memory channels are sealed together with processor cores inside the same physical package. Later, Hunt et al. [NSDI'20] show that, with proper isolation, HBM can be turned into an unobservable region where both data and memory traces are hidden. This motivates a rethink of OMAP design with HBM-backed solutions to finally overcome their traditional performance limits. Building on these insights, we present BOLT, a Bandwidth Optimized, Lightning-fast OMAP accelerator that, for the first time, achieves O(1) + O(log_2(log_2 (N))) bandwidth overhead. BOLT introduces three key innovations: (i) a new OMAP algorithm that leverages isolated HBM as an unobservable cache to accelerate oblivious access to large host memory; (ii) a self-hosted architecture that offloads execution and memory control from the host to mitigate CPU-side leakage; and (iii) tailored algorithm-architecture co-designs that maximize resource efficiency. We implement a prototype BOLT on a Xilinx U55C FPGA. Evaluations show that BOLT achieves up to 279x and 480x speedups in initialization and query time, respectively, over state-of-the-art OMAPs, including an industry implementation from Facebook.

**Link**: [arxiv](http://arxiv.org/abs/2509.01742v2),  [pdf](http://arxiv.org/pdf/2509.01742v2)

**Tags**: cs.CR cs.AR 



### Revolutionizing Reinforcement Learning Framework for Diffusion Large   Language Models
**Authors**: Yinjie Wang, Ling Yang, Bowen Li, Ye Tian, Ke Shen, Mengdi Wang

**Updated**: 2025-09-08T17:58:06Z

**Summary**: We propose TraceRL, a trajectory-aware reinforcement learning framework for diffusion language models (DLMs) that incorporates preferred inference trajectory into post-training, and is applicable across different architectures. Equipped with a diffusion-based value model that enhances training stability, we demonstrate improved reasoning performance on complex math and coding tasks. Besides, it can also be applied to adapt block-specific models to larger blocks, which improves sampling flexibility. Employing TraceRL, we derive a series of state-of-the-art diffusion language models, namely TraDo. Although smaller than 7B-scale AR models, TraDo-4B-Instruct still consistently outperforms them across complex math reasoning tasks. TraDo-8B-Instruct achieves relative accuracy improvements of 6.1% over Qwen2.5-7B-Instruct and 51.3% over Llama3.1-8B-Instruct on mathematical reasoning benchmarks. Through curriculum learning, we also derive the first long-CoT DLM, outperforming Qwen2.5-7B-Instruct on MATH500 with an 18.1% relative accuracy gain. To facilitate reproducible research and practical applications, we release a comprehensive open-source framework for building, training, and deploying diffusion LLMs across diverse architectures. The framework integrates accelerated KV-cache techniques and inference engines for both inference and reinforcement learning, and includes implementations of various supervised fine-tuning and RL methods for mathematics, coding, and general tasks. Code and Models: https://github.com/Gen-Verse/dLLM-RL

**Link**: [arxiv](http://arxiv.org/abs/2509.06949v1),  [pdf](http://arxiv.org/pdf/2509.06949v1)

**Tags**: cs.CL 



### Amplifying Effective CXL Memory Bandwidth for LLM Inference via   Transparent Near-Data Processing
**Authors**: Rui Xie, Asad Ul Haq, Linsen Ma, Yunhua Fang, Zirak Burzin Engineer, Liu Liu, Tong Zhang

**Updated**: 2025-09-08T17:22:17Z

**Summary**: Large language model (LLM) inference is bottlenecked by the limited bandwidth of CXL-based memory used for capacity expansion. We introduce CXL-NDP, a transparent near-data processing architecture that amplifies effective CXL bandwidth without requiring changes to the CXL.mem interface or AI models. CXL-NDP integrates a precision-scalable bit-plane layout for dynamic quantization with transparent lossless compression of weights and KV caches directly within the CXL device. In end-to-end serving, CXL-NDP improves throughput by 43%, extends the maximum context length by 87%, and reduces the KV cache footprint by 46.9% without accuracy loss. Hardware synthesis confirms its practicality with a modest silicon footprint, lowering the barrier for adopting efficient, scalable CXL-based memory in generative AI infrastructure.

**Link**: [arxiv](http://arxiv.org/abs/2509.03377v2),  [pdf](http://arxiv.org/pdf/2509.03377v2)

**Tags**: cs.AR 



### X-EcoMLA: Upcycling Pre-Trained Attention into MLA for Efficient and   Extreme KV Compression
**Authors**: Guihong Li, Mehdi Rezagholizadeh, Mingyu Yang, Vikram Appia, Emad Barsoum

**Updated**: 2025-09-08T13:34:54Z

**Summary**: Multi-head latent attention (MLA) is designed to optimize KV cache memory through low-rank key-value joint compression. Rather than caching keys and values separately, MLA stores their compressed latent representations, reducing memory overhead while maintaining the performance. While MLA improves memory efficiency without compromising language model accuracy, its major limitation lies in its integration during the pre-training phase, requiring models to be trained from scratch. This raises a key question: can we use MLA's benefits fully or partially in models that have already been pre-trained with different attention mechanisms? In this paper, we propose X-EcoMLA to deploy post training distillation to enable the upcycling of Transformer-based attention into an efficient hybrid MLA variant through lightweight post-training adaptation, bypassing the need for extensive pre-training. We demonstrate that leveraging the dark knowledge of a well-trained model can enhance training accuracy and enable extreme KV cache compression in MLA without compromising model performance. The experimental results show that our proposed method can effectively compress the KV cache while preserving the performance on the benchmarks; specifically, for Llama3.2-1B-Instruct baseline, a 6.4x compression achieves the same average score by using only 3.6B training tokens and 70 GPU hours on AMD MI300, whereas a 10.6x compression have less than 0.1% average score drop with 7B training tokens and 140 GPU hours. The code for this work is available at https://github.com/AMD-AGI/AMD-Hybrid-Models.

**Link**: [arxiv](http://arxiv.org/abs/2503.11132v4),  [pdf](http://arxiv.org/pdf/2503.11132v4)

**Tags**: cs.CL 



### CausNVS: Autoregressive Multi-view Diffusion for Flexible 3D Novel View   Synthesis
**Authors**: Xin Kong, Daniel Watson, Yannick Strümpler, Michael Niemeyer, Federico Tombari

**Updated**: 2025-09-08T11:49:51Z

**Summary**: Multi-view diffusion models have shown promise in 3D novel view synthesis, but most existing methods adopt a non-autoregressive formulation. This limits their applicability in world modeling, as they only support a fixed number of views and suffer from slow inference due to denoising all frames simultaneously. To address these limitations, we propose CausNVS, a multi-view diffusion model in an autoregressive setting, which supports arbitrary input-output view configurations and generates views sequentially. We train CausNVS with causal masking and per-frame noise, using pairwise-relative camera pose encodings (CaPE) for precise camera control. At inference time, we combine a spatially-aware sliding-window with key-value caching and noise conditioning augmentation to mitigate drift. Our experiments demonstrate that CausNVS supports a broad range of camera trajectories, enables flexible autoregressive novel view synthesis, and achieves consistently strong visual quality across diverse settings. Project page: https://kxhit.github.io/CausNVS.html.

**Link**: [arxiv](http://arxiv.org/abs/2509.06579v1),  [pdf](http://arxiv.org/pdf/2509.06579v1)

**Tags**: cs.CV 



### Scaling up Multi-Turn Off-Policy RL and Multi-Agent Tree Search for LLM   Step-Provers
**Authors**: Ran Xin, Zeyu Zheng, Yanchen Nie, Kun Yuan, Xia Xiao

**Updated**: 2025-09-08T09:54:18Z

**Summary**: The integration of Large Language Models (LLMs) into automated theorem proving has shown immense promise, yet is fundamentally constrained by challenges in scaling up both training-time reinforcement learning (RL) and inference-time compute. This paper introduces \texttt{BFS-Prover-V2}, a system designed to address this dual scaling problem. We present two primary innovations. The first is a novel multi-turn off-policy RL framework for continually improving the performance of LLM step-prover at training time. This framework, inspired by the principles of AlphaZero, utilizes a multi-stage expert iteration pipeline featuring adaptive tactic-level data filtering and periodic retraining to surmount the performance plateaus that typically curtail long-term RL in LLM-based agents. The second innovation is a planner-enhanced multi-agent search architecture that scales reasoning capabilities at inference time. This architecture employs a general reasoning model as a high-level planner to iteratively decompose complex theorems into a sequence of simpler subgoals. This hierarchical approach substantially reduces the search space, enabling a team of parallel prover agents to collaborate efficiently by leveraging a shared proof cache. We demonstrate that this dual approach to scaling yields state-of-the-art results on established formal mathematics benchmarks. \texttt{BFS-Prover-V2} achieves 95.08\% and 41.4\% on the MiniF2F and ProofNet test sets respectively. While demonstrated in the domain of formal mathematics, the RL and inference techniques presented in this work are of broader interest and may be applied to other domains requiring long-horizon multi-turn reasoning and complex search.

**Link**: [arxiv](http://arxiv.org/abs/2509.06493v1),  [pdf](http://arxiv.org/pdf/2509.06493v1)

**Tags**: cs.AI 



### Physical Autoregressive Model for Robotic Manipulation without Action   Pretraining
**Authors**: Zijian Song, Sihan Qin, Tianshui Chen, Liang Lin, Guangrun Wang

**Updated**: 2025-09-08T09:09:36Z

**Summary**: The scarcity of manipulation data has motivated the use of pretrained large models from other modalities in robotics. In this work, we build upon autoregressive video generation models to propose a Physical Autoregressive Model (PAR), where physical tokens combine frames and actions to represent the joint evolution of the robot and its environment. PAR leverages the world knowledge embedded in video pretraining to understand physical dynamics without requiring action pretraining, enabling accurate video prediction and consistent action trajectories. It also adopts a DiT-based de-tokenizer to model frames and actions as continuous tokens, mitigating quantization errors and facilitating mutual enhancement. Furthermore, we incorporate a causal mask with inverse kinematics, parallel training, and the KV-cache mechanism to further improve performance and efficiency. Experiments on the ManiSkill benchmark show that PAR achieves a 100\% success rate on the PushCube task, matches the performance of action-pretrained baselines on other tasks, and accurately predicts future videos with tightly aligned action trajectories. These findings underscore a promising direction for robotic manipulation by transferring world knowledge from autoregressive video pretraining. The project page is here: https://hcplab-sysu.github.io/PhysicalAutoregressiveModel/

**Link**: [arxiv](http://arxiv.org/abs/2508.09822v4),  [pdf](http://arxiv.org/pdf/2508.09822v4)

**Tags**: cs.CV 



### HyFedRAG: A Federated Retrieval-Augmented Generation Framework for   Heterogeneous and Privacy-Sensitive Data
**Authors**: Cheng Qian, Hainan Zhang, Yongxin Tong, Hong-Wei Zheng, Zhiming Zheng

**Updated**: 2025-09-08T08:44:24Z

**Summary**: Centralized RAG pipelines struggle with heterogeneous and privacy-sensitive data, especially in distributed healthcare settings where patient data spans SQL, knowledge graphs, and clinical notes. Clinicians face difficulties retrieving rare disease cases due to privacy constraints and the limitations of traditional cloud-based RAG systems in handling diverse formats and edge devices. To address this, we introduce HyFedRAG, a unified and efficient Federated RAG framework tailored for Hybrid data modalities. By leveraging an edge-cloud collaborative mechanism, HyFedRAG enables RAG to operate across diverse data sources while preserving data privacy. Our key contributions are: (1) We design an edge-cloud collaborative RAG framework built on Flower, which supports querying structured SQL data, semi-structured knowledge graphs, and unstructured documents. The edge-side LLMs convert diverse data into standardized privacy-preserving representations, and the server-side LLMs integrates them for global reasoning and generation. (2) We integrate lightweight local retrievers with privacy-aware LLMs and provide three anonymization tools that enable each client to produce semantically rich, de-identified summaries for global inference across devices. (3) To optimize response latency and reduce redundant computation, we design a three-tier caching strategy consisting of local cache, intermediate representation cache, and cloud inference cache. Experimental results on PMC-Patients demonstrate that HyFedRAG outperforms existing baselines in terms of retrieval quality, generation consistency, and system efficiency. Our framework offers a scalable and privacy-compliant solution for RAG over structural-heterogeneous data, unlocking the potential of LLMs in sensitive and diverse data environments.

**Link**: [arxiv](http://arxiv.org/abs/2509.06444v1),  [pdf](http://arxiv.org/pdf/2509.06444v1)

**Tags**: cs.AI 



### Tree of Agents: Improving Long-Context Capabilities of Large Language   Models through Multi-Perspective Reasoning
**Authors**: Song Yu, Xiaofei Xu, Ke Deng, Li Li, Lin Tian

**Updated**: 2025-09-08T08:34:02Z

**Summary**: Large language models (LLMs) face persistent challenges when handling long-context tasks, most notably the lost in the middle issue, where information located in the middle of a long input tends to be underutilized. Some existing methods that reduce input have the risk of discarding key information, while others that extend context windows often lead to attention dispersion. To address these limitations, we propose Tree of Agents (TOA), a multi-agent reasoning framework that segments the input into chunks processed by independent agents. Each agent generates its local cognition, then agents dynamically exchange information for collaborative reasoning along tree-structured paths. TOA enables agents to probe different reasoning orders for multi-perspective understanding, effectively mitigating position bias and reducing hallucinations. To improve processing efficiency, we incorporate prefix-hash caching and adaptive pruning strategies, achieving significant performance improvements with comparable API overhead. Experiments show that TOA, powered by compact LLaMA3.1-8B, significantly outperforms multiple baselines and demonstrates comparable performance to the latest and much larger commercial models, such as Gemini1.5-pro, on various long-context tasks. Code is available at https://github.com/Aireduce952/Tree-of-Agents.

**Link**: [arxiv](http://arxiv.org/abs/2509.06436v1),  [pdf](http://arxiv.org/pdf/2509.06436v1)

**Tags**: cs.AI 



### FineServe: Precision-Aware KV Slab and Two-Level Scheduling for   Heterogeneous Precision LLM Serving
**Authors**: Kyungmin Bin, Seungbeom Choi, Jimyoung Son, Jieun Choi, Daseul Bae, Daehyeon Baek, Kihyo Moon, Minsung Jang, Hyojung Lee

**Updated**: 2025-09-08T00:57:50Z

**Summary**: Recent advances in Post-Training Quantization (PTQ) techniques have significantly increased demand for serving quantized large language models (LLMs), enabling higher throughput and substantially reduced memory usage with minimal accuracy loss. Quantized models address memory constraints in LLMs and enhance GPU resource utilization through efficient GPU sharing. However, quantized models have smaller KV block sizes than non-quantized models, causing limited memory efficiency due to memory fragmentation. Also, distinct resource usage patterns between quantized and non-quantized models require efficient scheduling to maximize throughput. To address these challenges, we propose FineServe, an inference serving framework for mixed-precision LLMs. FineServe's key contributions include: (1) KV Slab, a precision-aware adaptive memory management technique dynamically allocating KV cache based on model quantization characteristics, significantly reducing GPU memory fragmentation, and (2) a two-level scheduling framework comprising a global scheduler that places models to GPUs based on request rates, latency SLOs, and memory constraints and efficiency, and a local scheduler that adaptively adjusts batch sizes according to real-time request fluctuations. Experimental results demonstrate that FineServe achieves up to 2.2x higher SLO attainment and 1.8x higher token generation throughput compared to the state-of-the-art GPU sharing systems.

**Link**: [arxiv](http://arxiv.org/abs/2509.06261v1),  [pdf](http://arxiv.org/pdf/2509.06261v1)

**Tags**: cs.DC cs.LG 



### A facile vector substrate platform via BaTiO3 membrane transfer enables   high quality solution processed epitaxial PZT on silicon
**Authors**: Asraful Haque, Antony Jeyaseelan, Shubham Kumar Parate, Srinivasan Raghavan, Pavan Nukala

**Updated**: 2025-09-07T13:15:17Z

**Summary**: The direct integration of high-performance ferroelectric oxides with silicon remains challenging due to lattice mismatch, thermal incompatibility, and the need for high-temperature epitaxial growth. Here, a hybrid integration approach is demonstrated in which crystalline BaTiO3 (BTO) membranes are first transferred onto Pt coated Si substrates and subsequently used as vector substrates (VS) for the growth of epitaxial (001) Pb(Zr0.52Ti0.48)O3 (PZT) thin films via chemical solution deposition (CSD). A KI and HCl based etchant enables rapid and complete dissolution of the SrVO3 sacrificial layer in about 30 minutes, reducing the release time from days to minutes compared with conventional water based approaches to dissolve AVO3 and AMoO3 (A is Ca, Sr, Ba). The BTO VS imposes dominant (00l) out of plane orientation and in plane cube on cube epitaxy in the overlying PZT. Devices exhibit remnant polarization 10 to 12 micro coulomb/cm2 and coercive field of 100 kV/cm, with stable switching to 10^8 cycles on the VS. From piezoelectric butterfly loops, we extract effective d33 of 70 pm/V for PZT on VS, and 54 pm/V for PZT grown on conventional Pt Si substrates. This approach demonstrates a scalable and cost effective route for integrating functional ferroelectric materials onto silicon and offers a promising platform for future CMOS compatible oxide electronics.

**Link**: [arxiv](http://arxiv.org/abs/2509.06047v1),  [pdf](http://arxiv.org/pdf/2509.06047v1)

**Tags**: cond-mat.mtrl-sci 



### Tight Cache Contention Analysis for WCET Estimation on Multicore Systems
**Authors**: Shuai Zhao, Jieyu Jiang, Shenlin Cai, Yaowei Liang, Chen Jie, Yinjie Fang, Wei Zhang, Guoquan Zhang, Yaoyao Gu, Xiang Xiao, Wei Qin, Xiangzhen Ouyang, Wanli Chang

**Updated**: 2025-09-06T05:58:51Z

**Summary**: WCET (Worst-Case Execution Time) estimation on multicore architecture is particularly challenging mainly due to the complex accesses over cache shared by multiple cores. Existing analysis identifies possible contentions between parallel tasks by leveraging the partial order of the tasks or their program regions. Unfortunately, they overestimate the number of cache misses caused by a remote block access without considering the actual cache state and the number of accesses. This paper reports a new analysis for inter-core cache contention. Based on the order of program regions in a task, we first identify memory references that could be affected if a remote access occurs in a region. Afterwards, a fine-grained contention analysis is constructed that computes the number of cache misses based on the access quantity of local and remote blocks. We demonstrate that the overall inter-core cache interference of a task can be obtained via dynamic programming. Experiments show that compared to existing methods, the proposed analysis reduces inter-core cache interference and WCET estimations by 52.31% and 8.94% on average, without significantly increasing computation overhead.

**Link**: [arxiv](http://arxiv.org/abs/2508.13863v2),  [pdf](http://arxiv.org/pdf/2508.13863v2)

**Tags**: cs.SE 



### RapidGNN: Energy and Communication-Efficient Distributed Training on   Large-Scale Graph Neural Networks
**Authors**: Arefin Niam, Tevfik Kosar, M S Q Zulkar Nine

**Updated**: 2025-09-05T16:10:20Z

**Summary**: Graph Neural Networks (GNNs) have become popular across a diverse set of tasks in exploring structural relationships between entities. However, due to the highly connected structure of the datasets, distributed training of GNNs on large-scale graphs poses significant challenges. Traditional sampling-based approaches mitigate the computational loads, yet the communication overhead remains a challenge. This paper presents RapidGNN, a distributed GNN training framework with deterministic sampling-based scheduling to enable efficient cache construction and prefetching of remote features. Evaluation on benchmark graph datasets demonstrates RapidGNN's effectiveness across different scales and topologies. RapidGNN improves end-to-end training throughput by 2.46x to 3.00x on average over baseline methods across the benchmark datasets, while cutting remote feature fetches by over 9.70x to 15.39x. RapidGNN further demonstrates near-linear scalability with an increasing number of computing units efficiently. Furthermore, it achieves increased energy efficiency over the baseline methods for both CPU and GPU by 44% and 32%, respectively.

**Link**: [arxiv](http://arxiv.org/abs/2509.05207v1),  [pdf](http://arxiv.org/pdf/2509.05207v1)

**Tags**: cs.LG cs.AI 



### KVCompose: Efficient Structured KV Cache Compression with Composite   Tokens
**Authors**: Dmitry Akulov, Mohamed Sana, Antonio De Domenico, Tareq Si Salem, Nicola Piovesan, Fadhel Ayed

**Updated**: 2025-09-05T14:58:24Z

**Summary**: Large language models (LLMs) rely on key-value (KV) caches for efficient autoregressive decoding; however, cache size grows linearly with context length and model depth, becoming a major bottleneck in long-context inference. Prior KV cache compression methods either enforce rigid heuristics, disrupt tensor layouts with per-attention-head variability, or require specialized compute kernels.   We propose a simple, yet effective, KV cache compression framework based on attention-guided, layer-adaptive composite tokens. Our method aggregates attention scores to estimate token importance, selects head-specific tokens independently, and aligns them into composite tokens that respect the uniform cache structure required by existing inference engines. A global allocation mechanism further adapts retention budgets across layers, assigning more capacity to layers with informative tokens. This approach achieves significant memory reduction while preserving accuracy, consistently outperforming prior structured and semi-structured methods. Crucially, our approach remains fully compatible with standard inference pipelines, offering a practical and scalable solution for efficient long-context LLM deployment.

**Link**: [arxiv](http://arxiv.org/abs/2509.05165v1),  [pdf](http://arxiv.org/pdf/2509.05165v1)

**Tags**: cs.LG 



### Mainframe-Style Channel Controllers for Modern Disaggregated Memory   Systems
**Authors**: Zikai Liu, Jasmin Schult, Pengcheng Xu, Timothy Roscoe

**Updated**: 2025-09-05T10:39:03Z

**Summary**: Despite the promise of alleviating the main memory bottleneck, and the existence of commercial hardware implementations, techniques for Near-Data Processing have seen relatively little real-world deployment. The idea has received renewed interest with the appearance of disaggregated or "far" memory, for example in the use of CXL memory pools.   However, we argue that the lack of a clear OS-centric abstraction of Near-Data Processing is a major barrier to adoption of the technology. Inspired by the channel controllers which interface the CPU to disk drives in mainframe systems, we propose memory channel controllers as a convenient, portable, and virtualizable abstraction of Near-Data Processing for modern disaggregated memory systems.   In addition to providing a clean abstraction that enables OS integration while requiring no changes to CPU architecture, memory channel controllers incorporate another key innovation: they exploit the cache coherence provided by emerging interconnects to provide a much richer programming model, with more fine-grained interaction, than has been possible with existing designs.

**Link**: [arxiv](http://arxiv.org/abs/2506.09758v2),  [pdf](http://arxiv.org/pdf/2506.09758v2)

**Tags**: cs.OS cs.AR cs.ET 



### PagedEviction: Structured Block-wise KV Cache Pruning for Efficient   Large Language Model Inference
**Authors**: Krishna Teja Chitty-Venkata, Jie Ye, Xian-He Sun, Anthony Kougkas, Murali Emani, Venkatram Vishwanath, Bogdan Nicolae

**Updated**: 2025-09-04T16:40:01Z

**Summary**: KV caching significantly improves the efficiency of Large Language Model (LLM) inference by storing attention states from previously processed tokens, enabling faster generation of subsequent tokens. However, as sequence length increases, the KV cache quickly becomes a major memory bottleneck. To address this, we propose PagedEviction, a novel fine-grained, structured KV cache pruning strategy that enhances the memory efficiency of vLLM's PagedAttention. Unlike existing approaches that rely on attention-based token importance or evict tokens across different vLLM pages, PagedEviction introduces an efficient block-wise eviction algorithm tailored for paged memory layouts. Our method integrates seamlessly with PagedAttention without requiring any modifications to its CUDA attention kernels. We evaluate PagedEviction across Llama-3.1-8B-Instruct, Llama-3.2-1B-Instruct, and Llama-3.2-3B-Instruct models on the LongBench benchmark suite, demonstrating improved memory usage with better accuracy than baselines on long context tasks.

**Link**: [arxiv](http://arxiv.org/abs/2509.04377v1),  [pdf](http://arxiv.org/pdf/2509.04377v1)

**Tags**: cs.LG 



### Dissecting the NVIDIA Hopper Architecture through Microbenchmarking and   Multiple Level Analysis
**Authors**: Weile Luo, Ruibo Fan, Zeyu Li, Dayou Du, Hongyuan Liu, Qiang Wang, Xiaowen Chu

**Updated**: 2025-09-04T15:21:11Z

**Summary**: This study presents a comprehensive multi-level analysis of the NVIDIA Hopper GPU architecture, focusing on its performance characteristics and novel features. We benchmark Hopper's memory subsystem, highlighting improvements in the L2 partitioned cache and global memory access compared to Ampere and Ada Lovelace. The evaluation of Hopper's fourth-generation tensor cores reveals the benefits of FP8 precision and asynchronous wgmma instructions for matrix operations. Additionally, we investigate the performance of DPX instructions for dynamic programming, distributed shared memory (DSM) for inter-SM communication, and the Tensor Memory Accelerator (TMA) for asynchronous data movement. Through multi-level evaluation, we discover that the Hopper architecture demonstrates significant acceleration potential in real-world applications. For instance, the asynchronous programming model supported by TMA achieves a 1.5x speedup in matrix multiplication, FP8 delivers nearly double the performance of FP16, and DPX instructions accelerate a computational biology algorithm by at least 4.75x. Our findings provide actionable insights for optimizing compute-intensive workloads, from AI training to bioinformatics, on Hopper GPUs.

**Link**: [arxiv](http://arxiv.org/abs/2501.12084v2),  [pdf](http://arxiv.org/pdf/2501.12084v2)

**Tags**: cs.DC cs.AR cs.PF 



### InferLog: Accelerating LLM Inference for Online Log Parsing via   ICL-oriented Prefix Caching
**Authors**: Yilun Wang, Pengfei Chen, Haiyu Huang, Zilong He, Gou Tan, Chuanfu Zhang, Jingkai He, Zibin Zheng

**Updated**: 2025-09-04T13:14:33Z

**Summary**: Modern software systems generate massive volumes of runtime logs, necessitating efficient and accurate log parsing to enable critical downstream tasks such as anomaly detection and root cause analysis. Recently, large language models (LLMs) have achieved advanced accuracy on log parsing, but their deployment in production environments faces two major limitations: (1) the privacy risks associated with commercial LLMs, driving the adoption of local deployment, and (2) the stringent latency and throughput requirements imposed by high-volume log streams, which existing LLM-based parsers fail to meet. Although recent efforts have reduced the number of LLM queries, they overlook the high latency of the LLM invocations, where concurrent log parsing requests can cause serve performance degradation of LLM inference system.   In this study, we present InferLog, the first LLM inference optimization method for online log parsing. Our key insight is that the inference efficiency emerges as the vital bottleneck in LLM-based online log parsing, rather than parsing accuracy. InferLog accelerates inference by designing (1) A Prefix-aware ICL Refinement policy to refine the examples and permutation of in-context learning to improve the prefix caching efficiency. (2) A rapid and task-specific configuration tuning pipeline based on meta-learning to find the optimal LLM scheduling-related configuration for dynamic log parsing workloads. The experimental results based on Loghub dataset and vLLM demonstrate that InferLog significantly outperforms existing inference optimization methods and markedly accelerates the state-of-the-art LLM-based log parser without compromising parsing accuracy.

**Link**: [arxiv](http://arxiv.org/abs/2507.08523v2),  [pdf](http://arxiv.org/pdf/2507.08523v2)

**Tags**: cs.SE 



### Set Block Decoding is a Language Model Inference Accelerator
**Authors**: Itai Gat, Heli Ben-Hamu, Marton Havasi, Daniel Haziza, Jeremy Reizenstein, Gabriel Synnaeve, David Lopez-Paz, Brian Karrer, Yaron Lipman

**Updated**: 2025-09-04T13:02:39Z

**Summary**: Autoregressive next token prediction language models offer powerful capabilities but face significant challenges in practical deployment due to the high computational and memory costs of inference, particularly during the decoding stage. We introduce Set Block Decoding (SBD), a simple and flexible paradigm that accelerates generation by integrating standard next token prediction (NTP) and masked token prediction (MATP) within a single architecture. SBD allows the model to sample multiple, not necessarily consecutive, future tokens in parallel, a key distinction from previous acceleration methods. This flexibility allows the use of advanced solvers from the discrete diffusion literature, offering significant speedups without sacrificing accuracy. SBD requires no architectural changes or extra training hyperparameters, maintains compatibility with exact KV-caching, and can be implemented by fine-tuning existing next token prediction models. By fine-tuning Llama-3.1 8B and Qwen-3 8B, we demonstrate that SBD enables a 3-5x reduction in the number of forward passes required for generation while achieving same performance as equivalent NTP training.

**Link**: [arxiv](http://arxiv.org/abs/2509.04185v1),  [pdf](http://arxiv.org/pdf/2509.04185v1)

**Tags**: cs.LG 



### VisioFirm: Cross-Platform AI-assisted Annotation Tool for Computer   Vision
**Authors**: Safouane El Ghazouali, Umberto Michelucci

**Updated**: 2025-09-04T12:54:32Z

**Summary**: AI models rely on annotated data to learn pattern and perform prediction. Annotation is usually a labor-intensive step that require associating labels ranging from a simple classification label to more complex tasks such as object detection, oriented bounding box estimation, and instance segmentation. Traditional tools often require extensive manual input, limiting scalability for large datasets. To address this, we introduce VisioFirm, an open-source web application designed to streamline image labeling through AI-assisted automation. VisioFirm integrates state-of-the-art foundation models into an interface with a filtering pipeline to reduce human-in-the-loop efforts. This hybrid approach employs CLIP combined with pre-trained detectors like Ultralytics models for common classes and zero-shot models such as Grounding DINO for custom labels, generating initial annotations with low-confidence thresholding to maximize recall. Through this framework, when tested on COCO-type of classes, initial prediction have been proven to be mostly correct though the users can refine these via interactive tools supporting bounding boxes, oriented bounding boxes, and polygons. Additionally, VisioFirm has on-the-fly segmentation powered by Segment Anything accelerated through WebGPU for browser-side efficiency. The tool supports multiple export formats (YOLO, COCO, Pascal VOC, CSV) and operates offline after model caching, enhancing accessibility. VisioFirm demonstrates up to 90\% reduction in manual effort through benchmarks on diverse datasets, while maintaining high annotation accuracy via clustering of connected CLIP-based disambiguate components and IoU-graph for redundant detection suppression. VisioFirm can be accessed from \href{https://github.com/OschAI/VisioFirm}{https://github.com/OschAI/VisioFirm}.

**Link**: [arxiv](http://arxiv.org/abs/2509.04180v1),  [pdf](http://arxiv.org/pdf/2509.04180v1)

**Tags**: cs.CV cs.AI 



### Systematic Timing Leakage Analysis of NIST PQDSS Candidates: Tooling and   Lessons Learned
**Authors**: Olivier Adjonyo, Sebastien Bardin, Emanuele Bellini, Gilbert Ndollane Dione, Mahmudul Faisal Al Ameen, Robert Merget, Frederic Recoules, Yanis Sellami

**Updated**: 2025-09-04T08:41:06Z

**Summary**: The PQDSS standardization process requires cryptographic primitives to be free from vulnerabilities, including timing and cache side-channels. Resistance to timing leakage is therefore an essential property, and achieving this typically relies on software implementations that follow constant-time principles. Moreover, ensuring that all implementations are constant-time is crucial for fair performance comparisons, as secure implementations often incur additional overhead. Such analysis also helps identify scheme proposals that are inherently difficult to implement in constant time. Because constant-time properties can be broken during compilation, it is often necessary to analyze the compiled binary directly. Since manual binary analysis is extremely challenging, automated analysis becomes highly important. Although several tools exist to assist with such analysis, they often have usability limitations and are difficult to set up correctly. To support the developers besides the NIST committee in verifying candidates, we developed a toolchain that automates configuration, execution, and result analysis for several widely used constant-time analysis tools. We selected TIMECOP and Binsec/Rel2 to verify constant-time policy compliance at the binary level, and dudect and RTLF to detect side-channel vulnerabilities through statistical analysis of execution time behavior. We demonstrate its effectiveness and practicability by evaluating the NIST PQDSS round 1 and round 2 implementations. We reported 26 issues in total to the respective developers, and 5 of them have already been fixed. We also discuss our different findings, as well as the benefits of shortcomings of the different tools.

**Link**: [arxiv](http://arxiv.org/abs/2509.04010v1),  [pdf](http://arxiv.org/pdf/2509.04010v1)

**Tags**: cs.CR 



### IC-Cache: Efficient Large Language Model Serving via In-context Caching
**Authors**: Yifan Yu, Yu Gan, Nikhil Sarda, Lillian Tsai, Jiaming Shen, Yanqi Zhou, Arvind Krishnamurthy, Fan Lai, Henry M. Levy, David Culler

**Updated**: 2025-09-04T06:20:55Z

**Summary**: Large language models (LLMs) have excelled in various applications, yet serving them at scale is challenging due to their substantial resource demands and high latency. Our real-world studies reveal that over 70% of user requests to LLMs have semantically similar counterparts, suggesting the potential for knowledge transfer among requests. However, naively caching and reusing past responses leads to a big quality drop. In this paper, we introduce IC-Cache, a caching system that enables live LLM capability augmentation to improve serving efficiency: by leveraging historical request-response pairs from larger models as in-context examples, IC-Cache empowers small LLMs to imitate and even exceed the compositional abilities (e.g., reasoning) of their larger counterparts, enabling selective offloading of requests to reduce cost and latency. Achieving this live augmentation at scale introduces intricate trade-offs between response quality, latency, and system throughput. For a new request, IC-Cache efficiently selects similar, high-utility examples to prepend them to the new request's input. At scale, it adaptively routes requests across LLMs of varying capabilities, accounting for response quality and serving loads. IC-Cache employs a cost-aware cache replay mechanism that refines example quality offline to maximize online cache utility and efficiency. Evaluations on millions of realistic requests demonstrate that IC-Cache improves LLM serving throughput by 1.4-5.9x and reduces latency by 28-71% without hurting response quality.

**Link**: [arxiv](http://arxiv.org/abs/2501.12689v3),  [pdf](http://arxiv.org/pdf/2501.12689v3)

**Tags**: cs.LG 



### ConServe: Fine-Grained GPU Harvesting for LLM Online and Offline   Co-Serving
**Authors**: Yifan Qiao, Shu Anzai, Shan Yu, Haoran Ma, Shuo Yang, Yang Wang, Miryung Kim, Yongji Wu, Yang Zhou, Jiarong Xing, Joseph E. Gonzalez, Ion Stoica, Harry Xu

**Updated**: 2025-09-03T20:54:57Z

**Summary**: Large language model (LLM) serving demands low latency and high throughput, but high load variability makes it challenging to achieve high GPU utilization. In this paper, we identify a synergetic but overlooked opportunity to co-serve latency-critical online requests alongside latency-tolerant offline tasks such as model benchmarking. While promising, existing serving systems fail to co-serve them efficiently, as their coarse-grained resource management at the request or iteration level cannot harvest millisecond-level GPU idle cycles without introducing interference that violates online latency objectives. ConServe is a new LLM co-serving system that achieves high throughput and strong online latency guarantees by managing resources at finer granularities. ConServe introduces three techniques: (1) a latency-aware token-level scheduler that precisely sizes offline batches and tokens to fit within online latency objectives; (2) sub-iteration, layer-wise preemption that allows offline tasks to yield to online load spikes; and (3) incremental KV cache management that enables preempting and resuming offline requests at near-zero cost. Evaluations with Llama-3.1 and Qwen-2.5 models on real-world workloads show that ConServe delivers an average of 2.2$\times$ higher throughput and reduces online serving tail latency by 2.9$\times$ on average compared to state-of-the-art systems.

**Link**: [arxiv](http://arxiv.org/abs/2410.01228v2),  [pdf](http://arxiv.org/pdf/2410.01228v2)

**Tags**: cs.DC cs.LG 



### CloudFormer: An Attention-based Performance Prediction for Public Clouds   with Unknown Workload
**Authors**: Amirhossein Shahbazinia, Darong Huang, Luis Costero, David Atienza

**Updated**: 2025-09-03T15:15:44Z

**Summary**: Cloud platforms are increasingly relied upon to host diverse, resource-intensive workloads due to their scalability, flexibility, and cost-efficiency. In multi-tenant cloud environments, virtual machines are consolidated on shared physical servers to improve resource utilization. While virtualization guarantees resource partitioning for CPU, memory, and storage, it cannot ensure performance isolation. Competition for shared resources such as last-level cache, memory bandwidth, and network interfaces often leads to severe performance degradation. Existing management techniques, including VM scheduling and resource provisioning, require accurate performance prediction to mitigate interference. However, this remains challenging in public clouds due to the black-box nature of VMs and the highly dynamic nature of workloads. To address these limitations, we propose CloudFormer, a dual-branch Transformer-based model designed to predict VM performance degradation in black-box environments. CloudFormer jointly models temporal dynamics and system-level interactions, leveraging 206 system metrics at one-second resolution across both static and dynamic scenarios. This design enables the model to capture transient interference effects and adapt to varying workload conditions without scenario-specific tuning. Complementing the methodology, we provide a fine-grained dataset that significantly expands the temporal resolution and metric diversity compared to existing benchmarks. Experimental results demonstrate that CloudFormer consistently outperforms state-of-the-art baselines across multiple evaluation metrics, achieving robust generalization across diverse and previously unseen workloads. Notably, CloudFormer attains a mean absolute error (MAE) of just 7.8%, representing a substantial improvement in predictive accuracy and outperforming existing methods at least by 28%.

**Link**: [arxiv](http://arxiv.org/abs/2509.03394v1),  [pdf](http://arxiv.org/pdf/2509.03394v1)

**Tags**: cs.DC cs.LG cs.PF 



### Mooncake: A KVCache-centric Disaggregated Architecture for LLM Serving
**Authors**: Ruoyu Qin, Zheming Li, Weiran He, Mingxing Zhang, Yongwei Wu, Weimin Zheng, Xinran Xu

**Updated**: 2025-09-03T14:56:29Z

**Summary**: Mooncake is the serving platform for Kimi, a leading LLM service provided by Moonshot AI. It features a KVCache-centric disaggregated architecture that separates the prefill and decoding clusters. It also leverages the underutilized CPU, DRAM, and SSD resources of the GPU cluster to implement a disaggregated cache of KVCache. The core of Mooncake is its KVCache-centric scheduler, which balances maximizing overall effective throughput while meeting latency-related Service Level Objectives (SLOs). Unlike traditional studies that assume all requests will be processed, Mooncake faces challenges due to highly overloaded scenarios. To mitigate these, we developed a prediction-based early rejection policy. Experiments show that Mooncake excels in long-context scenarios. Compared to the baseline method, Mooncake can achieve up to a 525% increase in throughput in certain simulated scenarios while adhering to SLOs. Under real workloads, Mooncake's innovative architecture enables Kimi to handle 75% more requests.

**Link**: [arxiv](http://arxiv.org/abs/2407.00079v4),  [pdf](http://arxiv.org/pdf/2407.00079v4)

**Tags**: cs.DC cs.AI cs.AR 



### RAT: Bridging RNN Efficiency and Attention Accuracy via Chunk-based   Sequence Modeling
**Authors**: Xiuying Wei, Anunay Yadav, Razvan Pascanu, Caglar Gulcehre

**Updated**: 2025-09-03T14:28:23Z

**Summary**: Transformers have become the cornerstone of modern large-scale language models, but their reliance on softmax attention poses a computational bottleneck at both training and inference. Recurrent models offer high efficiency, but compressing the full sequence into a fixed-size and holistic representation suffers from memory degradation in long contexts and limits fine-grained retrieval. To address this, we propose RAT, an intermediate design that bridges the efficiency of RNNs and capacity of attention. RAT partitions the input into chunks, applies recurrence within each chunk for local dependencies, and softmax-based attention across chunks for long-range interactions. This design mitigates memory degradation and enables direct access to distant tokens, while retaining computational efficiency. Empirically, with a chunk size of 16, the RAT block achieves a 7x improvement in training speed with 100K token sequences and 9x in generation at the 4K position, while maintaining similar performance compared to standard attention. We demonstrate this by training 1.3B parameter models from scratch and performing large-scale evaluations, including short- and long-context benchmarks, as well as supervised fine-tuning~(SFT). We further propose a hybrid architecture that interleaves RAT with local attention. By combining efficient long-range modeling with strong local interactions, this hybrid design not only improves inference speed and reduces cache memory usage, but also consistently enhances performance and shows the overall best results. Code is available at https://github.com/CLAIRE-Labo/RAT.

**Link**: [arxiv](http://arxiv.org/abs/2507.04416v2),  [pdf](http://arxiv.org/pdf/2507.04416v2)

**Tags**: cs.CL 



### A Cegar-centric Bounded Reachability Analysis for Compositional Affine   Hybrid Systems
**Authors**: Atanu Kundu, Pratyay Sarkar, Rajarshi Ray

**Updated**: 2025-09-03T11:23:35Z

**Summary**: Reachability analysis of compositional hybrid systems, where individual components are modeled as hybrid automata, poses unique challenges. In addition to preserving the compositional semantics while computing system behaviors, algorithms have to cater to the explosion in the number of locations in the parallel product automaton. In this paper, we propose a bounded reachability analysis algorithm for compositional hybrid systems with piecewise affine dynamics, based on the principle of counterexample guided abstraction refinement (CEGAR). In particular, the algorithm searches for a counterexample in the discrete abstraction of the composition model, without explicitly computing a product automaton. When a counterexample is discovered in the abstraction, its validity is verified by a refinement of the state-space guided by the abstract counterexample. The state-space refinement is through a symbolic reachability analysis, particularly using a state-of-the-art algorithm with support functions as the continuous state representation. In addition, the algorithm mixes different semantics of composition with the objective of improved efficiency. Step compositional semantics is followed while exploring the abstract (discrete) state-space, while shallow compositional semantics is followed during state-space refinement with symbolic reachability analysis. Optimizations such as caching the results of the symbolic reachability analysis, which can be later reused, have been proposed. We implement this algorithm in the tool SAT-Reach and demonstrate the scalability benefits.

**Link**: [arxiv](http://arxiv.org/abs/2509.03560v1),  [pdf](http://arxiv.org/pdf/2509.03560v1)

**Tags**: cs.LO 



### Adaptive KV-Cache Compression without Manually Setting Budget
**Authors**: Chenxia Tang, Jianchun Liu, Hongli Xu, Liusheng Huang

**Updated**: 2025-09-03T08:38:40Z

**Summary**: Large language models (LLMs) inference relies heavily on KV-caches to accelerate autoregressive decoding, but the resulting memory footprint grows rapidly with sequence length, posing significant efficiency challenges. Current KV-cache compression methods suffer from a Procrustes' bed problem: they force diverse workloads into fixed compression ratios, leading to suboptimal resource allocation and inference performance. To this end, we present GVote, an adaptive KV-cache compression scheme that eliminates manual budget specification while achieving superior accuracy-efficiency trade-offs. GVote operates on the principle that the important keys are the aggregation of keys required by future queries. The method predicts future query attention demands by Monte-Carlo style sampling potential queries and aggregating selected keys to determine the optimal cache budget without manual specification. Experimental evaluation demonstrates GVote's effectiveness across multiple benchmarks, including GSM8K, RULER and Longbench. Compared to baselines, GVote exhibits 2$\times$ memory reduction while the accuracy maintains higher or comparable.

**Link**: [arxiv](http://arxiv.org/abs/2509.03136v1),  [pdf](http://arxiv.org/pdf/2509.03136v1)

**Tags**: cs.DB cs.AI 



### FastCache: Fast Caching for Diffusion Transformer Through Learnable   Linear Approximation
**Authors**: Dong Liu, Yanxuan Yu, Jiayi Zhang, Yifan Li, Ben Lengerich, Ying Nian Wu

**Updated**: 2025-09-03T06:56:21Z

**Summary**: Diffusion Transformers (DiT) are powerful generative models but remain computationally intensive due to their iterative structure and deep transformer stacks. To alleviate this inefficiency, we propose FastCache, a hidden-state-level caching and compression framework that accelerates DiT inference by exploiting redundancy within the model's internal representations. FastCache introduces a dual strategy: (1) a spatial-aware token selection mechanism that adaptively filters redundant tokens based on hidden state saliency, and (2) a transformer-level cache that reuses latent activations across timesteps when changes are statistically insignificant. These modules work jointly to reduce unnecessary computation while preserving generation fidelity through learnable linear approximation. Theoretical analysis shows that FastCache maintains bounded approximation error under a hypothesis-testing-based decision rule. Empirical evaluations across multiple DiT variants demonstrate substantial reductions in latency and memory usage, with best generation output quality compared to other cache methods, as measured by FID and t-FID. Code implementation of FastCache is available on GitHub at https://github.com/NoakLiu/FastCache-xDiT.

**Link**: [arxiv](http://arxiv.org/abs/2505.20353v2),  [pdf](http://arxiv.org/pdf/2505.20353v2)

**Tags**: cs.LG cs.AI cs.CV cs.MM cs.PF 



### Digital Network Twins for Next-generation Wireless: Creation,   Optimization, and Challenges
**Authors**: Zifan Zhang, Zhiyuan Peng, Hanzhi Yu, Mingzhe Chen, Yuchen Liu

**Updated**: 2025-09-02T18:10:00Z

**Summary**: Digital network twins (DNTs), by representing a physical network using a virtual model, offer significant benefits such as streamlined network development, enhanced productivity, and cost reduction for next-generation (nextG) communication infrastructure. Existing works mainly describe the deployment of DNT technologies in various service sections.The full life cycle of DNTs for telecommunication has not yet been comprehensively studied, particularly in the aspects of fine-grained creation, real-time adaptation, resource-efficient deployment, and security protection. This article presents an in-depth overview of DNTs, exploring their concrete integration into networks and communication, covering the fundamental designs, the emergent applications, and critical challenges in multiple dimensions. We also include two detailed case studies to illustrate how DNTs can be applied in real-world scenarios such as wireless traffic forecasting and edge caching. Additionally, a forward-looking vision of the research opportunities in tackling the challenges of DNTs is provided, aiming to fully maximize the benefits of DNTs in nextG networks.

**Link**: [arxiv](http://arxiv.org/abs/2410.18002v2),  [pdf](http://arxiv.org/pdf/2410.18002v2)

**Tags**: cs.NI 



### A Novel Coded Caching Scheme for Partially Cooperative Device-to-Device   Networks
**Authors**: Rashid Ummer N. T., K. K. Krishnan Namboodiri, B. Sundar Rajan

**Updated**: 2025-09-02T17:35:42Z

**Summary**: Device-to-device (D2D) communication is one of the most promising techniques for future wireless cellular communication systems. This paper considers coded caching in a partially cooperative wireless D2D network, where only a subset of users transmit during delivery, while all users request files. The non-transmitting users are referred to as selfish users. All existing schemes that do not require knowledge of the identity of selfish users before content placement are limited to the high-memory regime, particularly when the number of selfish users is large. We propose a novel coded caching scheme for a partially cooperative D2D network that operates in all feasible memory regimes, regardless of the number of selfish users. We also derive a lower bound on the transmission load of a partially cooperative D2D coded caching scheme. Using this bound, the proposed scheme is shown to be optimal in the high-memory regime.

**Link**: [arxiv](http://arxiv.org/abs/2509.02532v1),  [pdf](http://arxiv.org/pdf/2509.02532v1)

**Tags**: cs.IT math.IT 



### REPS: Recycled Entropy Packet Spraying for Adaptive Load Balancing and   Failure Mitigation
**Authors**: Tommaso Bonato, Abdul Kabbani, Ahmad Ghalayini, Michael Papamichael, Mohammad Dohadwala, Lukas Gianinazzi, Mikhail Khalilov, Elias Achermann, Daniele De Sensi, Torsten Hoefler

**Updated**: 2025-09-02T16:39:56Z

**Summary**: Next-generation datacenters require highly efficient network load balancing to manage the growing scale of artificial intelligence (AI) training and general datacenter traffic. However, existing Ethernet-based solutions, such as Equal Cost Multi-Path (ECMP) and oblivious packet spraying (OPS), struggle to maintain high network utilization due to both increasing traffic demands and the expanding scale of datacenter topologies, which also exacerbate network failures. To address these limitations, we propose REPS, a lightweight decentralized per-packet adaptive load balancing algorithm designed to optimize network utilization while ensuring rapid recovery from link failures. REPS adapts to network conditions by caching good-performing paths. In case of a network failure, REPS re-routes traffic away from it in less than 100 microseconds. REPS is designed to be deployed with next-generation out-of-order transports, such as Ultra Ethernet, and uses less than 25 bytes of per-connection state regardless of the topology size. We extensively evaluate REPS in large-scale simulations and FPGA-based NICs.

**Link**: [arxiv](http://arxiv.org/abs/2407.21625v5),  [pdf](http://arxiv.org/pdf/2407.21625v5)

**Tags**: cs.NI 



### MLP-Offload: Multi-Level, Multi-Path Offloading for LLM Pre-training to   Break the GPU Memory Wall
**Authors**: Avinash Maurya, M. Mustafa Rafique, Franck Cappello, Bogdan Nicolae

**Updated**: 2025-09-02T16:30:49Z

**Summary**: Training LLMs larger than the aggregated memory of multiple GPUs is increasingly necessary due to the faster growth of LLM sizes compared to GPU memory. To this end, multi-tier host memory or disk offloading techniques are proposed by state of art. Despite advanced asynchronous multi-tier read/write strategies, such offloading strategies result in significant I/O overheads in the critical path of training, resulting in slower iterations. To this end, we propose MLP-Offload, a novel multi-level, multi-path offloading engine specifically designed for optimizing LLM training on resource-constrained setups by mitigating I/O bottlenecks. We make several key observations that drive the design of MLP-Offload, such as I/O overheads during the update dominate the iteration time; I/O bandwidth of the third-level remote storage tier remains unutilized; and, contention due to concurrent offloading amplifies I/O bottlenecks. Driven by these insights, we design and implement MLP-Offload to offload the optimizer states across multiple tiers in a cache-efficient and concurrency-controlled fashion to mitigate I/O bottlenecks during the backward and update phases. Evaluations on models up to 280B parameters shows that MLP-Offload achieves 2.5$\times$ faster iterations compared to the state-of-the-art LLM training runtimes.

**Link**: [arxiv](http://arxiv.org/abs/2509.02480v1),  [pdf](http://arxiv.org/pdf/2509.02480v1)

**Tags**: cs.DC cs.AI cs.LG H.2.0; E.2; I.2.11 



### Cache Management for Mixture-of-Experts LLMs -- extended version
**Authors**: Spyros Angelopoulos, Loris Marchal, Adrien Obrecht, Bertrand Simon

**Updated**: 2025-09-02T15:19:06Z

**Summary**: Large language models (LLMs) have demonstrated remarkable capabilities across a variety of tasks. One of the main challenges towards the successful deployment of LLMs is memory management, since they typically involve billions of parameters. To this end, architectures based on Mixture-of-Experts have been proposed, which aim to reduce the size of the parameters that are activated when producing a token. This raises the equally critical issue of efficiently managing the limited cache of the system, in that frequently used experts should be stored in the fast cache rather than in the slower secondary memory.   In this work, we introduce and study a new paging problem that models expert management optimization. Our formulation captures both the layered architecture of LLMs and the requirement that experts are cached efficiently. We first present lower bounds on the competitive ratio of both deterministic and randomized algorithms, which show that under mild assumptions, LRU-like policies have good theoretical competitive performance. We then propose a layer-based extension of LRU that is tailored to the problem at hand.   Extensive simulations on both synthetic datasets and actual traces of MoE usage show that our algorithm outperforms policies for the classic paging problem, such as the standard LRU.

**Link**: [arxiv](http://arxiv.org/abs/2509.02408v1),  [pdf](http://arxiv.org/pdf/2509.02408v1)

**Tags**: cs.LG cs.DS 



### Leveraging Approximate Caching for Faster Retrieval-Augmented Generation
**Authors**: Shai Bergman, Zhang Ji, Anne-Marie Kermarrec, Diana Petrescu, Rafael Pires, Mathis Randl, Martijn de Vos

**Updated**: 2025-09-02T13:09:37Z

**Summary**: Retrieval-augmented generation (RAG) improves the reliability of large language model (LLM) answers by integrating external knowledge. However, RAG increases the end-to-end inference time since looking for relevant documents from large vector databases is computationally expensive. To address this, we introduce Proximity, an approximate key-value cache that optimizes the RAG workflow by leveraging similarities in user queries. Instead of treating each query independently, Proximity reuses previously retrieved documents when similar queries appear, substantially reducing reliance on expensive vector database lookups. To scale efficiently, Proximity employs a locality-sensitive hashing (LSH) scheme that enables fast cache lookups while preserving retrieval accuracy. We evaluate Proximity using the MMLU and MedRAG question answering benchmarks. Our experiments demonstrate that Proximity with our LSH scheme and a realistically skewed MedRAG workload reduces database calls by 78.9% while maintaining database recall and test accuracy. We experiment with different similarity tolerances and cache capacities, and show that the time spent within the Proximity cache remains low and constant (4.8 microseconds) even as the cache grows substantially in size. Our work highlights that approximate caching is a viable and effective strategy for optimizing RAG-based systems.

**Link**: [arxiv](http://arxiv.org/abs/2503.05530v2),  [pdf](http://arxiv.org/pdf/2503.05530v2)

**Tags**: cs.DB cs.LG cs.PF 



### Efficient Geometry Compression and Communication for 3D Gaussian   Splatting Point Clouds
**Authors**: Liang Xie, Yanting Li, Luyang Tang, Wei Gao

**Updated**: 2025-09-02T11:58:06Z

**Summary**: Storage and transmission challenges in dynamic 3D scene representation based on the i3DV platform, With increasing scene complexity, the explosive growth of 3D Gaussian data volume causes excessive storage space occupancy. To address this issue, we propose adopting the AVS PCRM reference software for efficient compression of Gaussian point cloud geometry data. The strategy deeply integrates the advanced encoding capabilities of AVS PCRM into the i3DV platform, forming technical complementarity with the original rate-distortion optimization mechanism based on binary hash tables. On one hand, the hash table efficiently caches inter-frame Gaussian point transformation relationships, which allows for high-fidelity transmission within a 40 Mbps bandwidth constraint. On the other hand, AVS PCRM performs precise compression on geometry data. Experimental results demonstrate that the joint framework maintains the advantages of fast rendering and high-quality synthesis in 3D Gaussian technology while achieving significant 10\%-25\% bitrate savings on universal test sets. It provides a superior rate-distortion tradeoff solution for the storage, transmission, and interaction of 3D volumetric video.

**Link**: [arxiv](http://arxiv.org/abs/2509.02232v1),  [pdf](http://arxiv.org/pdf/2509.02232v1)

**Tags**: cs.MM 



### SparK: Query-Aware Unstructured Sparsity with Recoverable KV Cache   Channel Pruning
**Authors**: Huanxuan Liao, Yixing Xu, Shizhu He, Guanchen Li, Xuanwu Yin, Dong Li, Emad Barsoum, Jun Zhao, Kang Liu

**Updated**: 2025-09-02T11:29:34Z

**Summary**: Long-context inference in large language models (LLMs) is increasingly constrained by the KV cache bottleneck: memory usage grows linearly with sequence length, while attention computation scales quadratically. Existing approaches address this issue by compressing the KV cache along the temporal axis through strategies such as token eviction or merging to reduce memory and computational overhead. However, these methods often neglect fine-grained importance variations across feature dimensions (i.e., the channel axis), thereby limiting their ability to effectively balance efficiency and model accuracy. In reality, we observe that channel saliency varies dramatically across both queries and positions: certain feature channels carry near-zero information for a given query, while others spike in relevance. To address this oversight, we propose SPARK, a training-free plug-and-play method that applies unstructured sparsity by pruning KV at the channel level, while dynamically restoring the pruned entries during attention score computation. Notably, our approach is orthogonal to existing KV compression and quantization techniques, making it compatible for integration with them to achieve further acceleration. By reducing channel-level redundancy, SPARK enables processing of longer sequences within the same memory budget. For sequences of equal length, SPARK not only preserves or improves model accuracy but also reduces KV cache storage by over 30% compared to eviction-based methods. Furthermore, even with an aggressive pruning ratio of 80%, SPARK maintains performance with less degradation than 5% compared to the baseline eviction method, demonstrating its robustness and effectiveness. Our code will be available at https://github.com/Xnhyacinth/SparK.

**Link**: [arxiv](http://arxiv.org/abs/2508.15212v2),  [pdf](http://arxiv.org/pdf/2508.15212v2)

**Tags**: cs.CL cs.AI cs.LG 



### Batch Query Processing and Optimization for Agentic Workflows
**Authors**: Junyi Shen, Noppanat Wadlom, Yao Lu

**Updated**: 2025-09-02T09:17:40Z

**Summary**: Large Language Models (LLMs) in agentic workflows combine multi-step reasoning, tool use, and collaboration across multiple specialized agents. Existing LLM serving engines optimize individual calls in isolation, while multi-agent frameworks focus on orchestration without system-level performance planning. As a result, repeated prompts, overlapping contexts, and concurrent executions create substantial redundancy and poor GPU utilization, especially in batch analytics scenarios. We introduce Halo, a system that brings batch query processing and optimization into agentic LLM workflows. Halo represents each workflow as a structured query plan DAG and constructs a consolidated graph for batched queries that exposes shared computation. Guided by a cost model that jointly considers prefill and decode costs, cache reuse, and GPU placement, Halo performs plan-level optimization to minimize redundant execution. Its runtime integrates adaptive batching, KV-cache sharing and migration, along with compute-communication overlap to maximize hardware efficiency. Evaluation across six benchmarks shows that Halo achieves up to 18.6x speedup for batch inference and 4.7x throughput improvement under online serving, scaling to workloads of tens of thousands of queries and complex graphs. These gains are achieved without compromising output quality. By unifying query optimization with LLM serving, Halo enables efficient agentic workflows in data analytics and decision-making applications.

**Link**: [arxiv](http://arxiv.org/abs/2509.02121v1),  [pdf](http://arxiv.org/pdf/2509.02121v1)

**Tags**: cs.DB cs.DC 



### Augmented Shuffle Differential Privacy Protocols for Large-Domain   Categorical and Key-Value Data
**Authors**: Takao Murakami, Yuichi Sei, Reo Eriguchi

**Updated**: 2025-09-02T06:40:45Z

**Summary**: Shuffle DP (Differential Privacy) protocols provide high accuracy and privacy by introducing a shuffler who randomly shuffles data in a distributed system. However, most shuffle DP protocols are vulnerable to two attacks: collusion attacks by the data collector and users and data poisoning attacks. A recent study addresses this issue by introducing an augmented shuffle DP protocol, where users do not add noise and the shuffler performs random sampling and dummy data addition. However, it focuses on frequency estimation over categorical data with a small domain and cannot be applied to a large domain due to prohibitively high communication and computational costs.   In this paper, we fill this gap by introducing a novel augmented shuffle DP protocol called the FME (Filtering-with-Multiple-Encryption) protocol. Our FME protocol uses a hash function to filter out unpopular items and then accurately calculates frequencies for popular items. To perform this within one round of interaction between users and the shuffler, our protocol carefully communicates within a system using multiple encryption. We also apply our FME protocol to more advanced KV (Key-Value) statistics estimation with an additional technique to reduce bias. For both categorical and KV data, we prove that our protocol provides computational DP, high robustness to the above two attacks, accuracy, and efficiency. We show the effectiveness of our proposals through comparisons with twelve existing protocols.

**Link**: [arxiv](http://arxiv.org/abs/2509.02004v1),  [pdf](http://arxiv.org/pdf/2509.02004v1)

**Tags**: cs.CR 



### LLMs cannot spot math errors, even when allowed to peek into the   solution
**Authors**: KV Aditya Srivatsa, Kaushal Kumar Maurya, Ekaterina Kochmar

**Updated**: 2025-09-01T11:41:10Z

**Summary**: Large language models (LLMs) demonstrate remarkable performance on math word problems, yet they have been shown to struggle with meta-reasoning tasks such as identifying errors in student solutions. In this work, we investigate the challenge of locating the first error step in stepwise solutions using two error reasoning datasets: VtG and PRM800K. Our experiments show that state-of-the-art LLMs struggle to locate the first error step in student solutions even when given access to the reference solution. To that end, we propose an approach that generates an intermediate corrected student solution, aligning more closely with the original student's solution, which helps improve performance.

**Link**: [arxiv](http://arxiv.org/abs/2509.01395v1),  [pdf](http://arxiv.org/pdf/2509.01395v1)

**Tags**: cs.CL cs.AI 



### Rotate, Clip, and Partition: Towards W2A4KV4 Quantization by Integrating   Rotation and Learnable Non-uniform Quantizer
**Authors**: Euntae Choi, Sumin Song, Woosang Lim, Sungjoo Yoo

**Updated**: 2025-09-01T07:26:57Z

**Summary**: We propose Rotate, Clip, and Partition (RCP), a quantization-aware training (QAT) approach that first realizes extreme compression of LLMs with W2A4KV4(2-bit weight, 4-bit activation, and 4-bit KV cache) configuration. RCP integrates recent rotation techniques with a novel non-uniform weight quantizer design, by quantitatively analyzing the impact of random rotation on 2-bit weight quantization. Our weight quantizer features Learnable Direct Partitioning (LDP), which introduces learnable parameters to directly learn non-uniform intervals jointly with LLM weights. We also present a specialized GPU kernel that supports GEMV on non-uniform W2A4. Experiments show that RCP can compress LLaMA-2-7B to W2A4KV4 with a loss of only 2.84 WikiText2 ppl and 5.29 times reduced memory footprint. Furthermore, RCP can quantize challenging mobile-targeted LLaMA-3.2 models and domain-specific WizardCoder-7B and MetaMath-7B with no critical problems such as convergence failure and repetition. Code is available at https://github.com/ songsm921/RCP.

**Link**: [arxiv](http://arxiv.org/abs/2502.15779v2),  [pdf](http://arxiv.org/pdf/2502.15779v2)

**Tags**: cs.LG cs.AI cs.CL 



### ProMoE: Fast MoE-based LLM Serving using Proactive Caching
**Authors**: Xiaoniu Song, Zihang Zhong, Rong Chen, Haibo Chen

**Updated**: 2025-09-01T03:51:09Z

**Summary**: The promising applications of large language models are often limited by the constrained GPU memory capacity available on edge devices. Mixture-of-Experts (MoE) models help address this issue by activating only a subset of the model's parameters during computation. This approach allows the unused parameters to be offloaded to host memory, thereby reducing the overall GPU memory demand. However, existing cache-based offloading solutions handle cache misses reactively, which significantly impacts system performance. In this paper, we introduce ProMoE, a novel proactive caching system that utilizes intermediate results to predict subsequent expert usage. By proactively fetching experts in advance, ProMoE eliminates passive cache misses, removes loading time from the critical path, and reduces the performance overhead associated with offloading. Our evaluations demonstrate that ProMoE achieves an average speedup of 2.20x (up to 3.21x) and 2.07x (up to 5.02x) in the prefill and decode stages, respectively, compared to existing offloading solutions.

**Link**: [arxiv](http://arxiv.org/abs/2410.22134v3),  [pdf](http://arxiv.org/pdf/2410.22134v3)

**Tags**: cs.DC cs.AI 



### REFRAG: Rethinking RAG based Decoding
**Authors**: Xiaoqiang Lin, Aritra Ghosh, Bryan Kian Hsiang Low, Anshumali Shrivastava, Vijai Mohan

**Updated**: 2025-09-01T03:31:44Z

**Summary**: Large Language Models (LLMs) have demonstrated remarkable capabilities in leveraging extensive external knowledge to enhance responses in multi-turn and agentic applications, such as retrieval-augmented generation (RAG). However, processing long-context inputs introduces significant system latency and demands substantial memory for the key-value cache, resulting in reduced throughput and a fundamental trade-off between knowledge enrichment and system efficiency. While minimizing latency for long-context inputs is a primary objective for LLMs, we contend that RAG require specialized consideration. In RAG, much of the LLM context consists of concatenated passages from retrieval, with only a small subset directly relevant to the query. These passages often exhibit low semantic similarity due to diversity or deduplication during re-ranking, leading to block-diagonal attention patterns that differ from those in standard LLM generation tasks. Based on this observation, we argue that most computations over the RAG context during decoding are unnecessary and can be eliminated with minimal impact on performance. To this end, we propose REFRAG, an efficient decoding framework that compresses, senses, and expands to improve latency in RAG applications. By exploiting the sparsity structure, we demonstrate a 30.85 the time-to-first-token acceleration (3.75 improvement to previous work) without loss in perplexity. In addition, our optimization framework for large context enables REFRAG to extend the context size of LLMs by 16. We provide rigorous validation of REFRAG across diverse long-context tasks, including RAG, multi-turn conversations, and long document summarization, spanning a wide range of datasets. Experimental results confirm that REFRAG delivers substantial speedup with no loss in accuracy compared to LLaMA models and other state-of-the-art baselines across various context sizes.

**Link**: [arxiv](http://arxiv.org/abs/2509.01092v1),  [pdf](http://arxiv.org/pdf/2509.01092v1)

**Tags**: cs.CL cs.AI cs.LG 



### LLM Serving Optimization with Variable Prefill and Decode Lengths
**Authors**: Meixuan Wang, Yinyu Ye, Zijie Zhou

**Updated**: 2025-08-31T15:09:36Z

**Summary**: We study the problem of serving LLM (Large Language Model) requests where each request has heterogeneous prefill and decode lengths. In LLM serving, the prefill length corresponds to the input prompt length, which determines the initial memory usage in the KV cache. The decode length refers to the number of output tokens generated sequentially, with each additional token increasing the KV cache memory usage by one unit. Given a set of n requests, our goal is to schedule and process them to minimize the total completion time. We show that this problem is NP-hard due to the interplay of batching, placement constraints, precedence relationships, and linearly increasing memory usage. We then analyze commonly used scheduling strategies in practice, such as First-Come-First-Serve (FCFS) and Shortest-First (SF), and prove that their competitive ratios scale up sublinearly with the memory limit-a significant drawback in real-world settings where memory demand is large. To address this, we propose a novel algorithm based on a new selection metric that efficiently forms batches over time. We prove that this algorithm achieves a constant competitive ratio. Finally, we develop and evaluate a few algorithm variants inspired by this approach, including dynamic programming variants, local search methods, and an LP-based scheduler, demonstrating through comprehensive simulations that they outperform standard baselines while maintaining computational efficiency.

**Link**: [arxiv](http://arxiv.org/abs/2508.06133v2),  [pdf](http://arxiv.org/pdf/2508.06133v2)

**Tags**: math.OC cs.AI cs.LG 



### Accelerating Latency-Critical Applications with AI-Powered   Semi-Automatic Fine-Grained Parallelization on SMT Processors
**Authors**: Denis Los, Igor Petushkov

**Updated**: 2025-08-31T14:51:19Z

**Summary**: Latency-critical applications tend to show low utilization of functional units due to frequent cache misses and mispredictions during speculative execution in high-performance superscalar processors. However, due to significant impact on single-thread performance, Simultaneous Multithreading (SMT) technology is rarely used with heavy threads of latency-critical applications. In this paper, we explore utilization of SMT technology to support fine-grained parallelization of latency-critical applications. Following the advancements in the development of Large Language Models (LLMs), we introduce Aira, an AI-powered Parallelization Adviser. To implement Aira, we extend AI Coding Agent in Cursor IDE with additional tools connected through Model Context Protocol, enabling end-to-end AI Agent for parallelization. Additional connected tools enable LLM-guided hotspot detection, collection of dynamic dependencies with Dynamic Binary Instrumentation, SMT-aware performance simulation to estimate performance gains. We apply Aira with Relic parallel framework for fine-grained task parallelism on SMT cores to parallelize latency-critical benchmarks representing real-world applications used in industry. We show 17% geomean performance gain from parallelization of latency-critical benchmarks using Aira with Relic framework.

**Link**: [arxiv](http://arxiv.org/abs/2509.00883v1),  [pdf](http://arxiv.org/pdf/2509.00883v1)

**Tags**: cs.DC cs.AI 



### Yet Another Mirage of Breaking MIRAGE: Debunking Occupancy-based   Side-Channel Attacks on Fully Associative Randomized Caches
**Authors**: Chris Cao, Gururaj Saileshwar

**Updated**: 2025-08-31T05:43:55Z

**Summary**: Recent work presented at USENIX Security 2025 (SEC'25) claims that occupancy-based attacks can recover AES keys from the MIRAGE randomized cache. In this paper, we examine these claims and find that they arise from a modeling flaw in the SEC'25 paper. Most critically, the SEC'25 paper's simulation of MIRAGE uses a constant seed to initialize the random number generator used for global evictions in MIRAGE, causing every AES encryption they trace to evict the same deterministic sequence of cache lines. This artificially creates a highly repeatable timing pattern that is not representative of a realistic implementation of MIRAGE, where eviction sequences vary randomly between encryptions. When we instead randomize the eviction seed for each run, reflecting realistic operation, the correlation between AES T-table accesses and attacker runtimes disappears, and the attack fails. These findings show that the reported leakage is an artifact of incorrect modeling, and not an actual vulnerability in MIRAGE.

**Link**: [arxiv](http://arxiv.org/abs/2508.10431v3),  [pdf](http://arxiv.org/pdf/2508.10431v3)

**Tags**: cs.CR 



### NetGent: Agent-Based Automation of Network Application Workflows
**Authors**: Jaber Daneshamooz, Eugene Vuong, Laasya Koduru, Sanjay Chandrasekaran, Arpit Gupta

**Updated**: 2025-08-30T22:47:15Z

**Summary**: We present NetGent, an AI-agent framework for automating complex application workflows to generate realistic network traffic datasets. Developing generalizable ML models for networking requires data collection from network environments with traffic that results from a diverse set of real-world web applications. However, using existing browser automation tools that are diverse, repeatable, realistic, and efficient remains fragile and costly. NetGent addresses this challenge by allowing users to specify workflows as natural-language rules that define state-dependent actions. These abstract specifications are compiled into nondeterministic finite automata (NFAs), which a state synthesis component translates into reusable, executable code. This design enables deterministic replay, reduces redundant LLM calls through state caching, and adapts quickly when application interfaces change. In experiments, NetGent automated more than 50+ workflows spanning video-on-demand streaming, live video streaming, video conferencing, social media, and web scraping, producing realistic traffic traces while remaining robust to UI variability. By combining the flexibility of language-based agents with the reliability of compiled execution, NetGent provides a scalable foundation for generating the diverse, repeatable datasets needed to advance ML in networking.

**Link**: [arxiv](http://arxiv.org/abs/2509.00625v1),  [pdf](http://arxiv.org/pdf/2509.00625v1)

**Tags**: cs.AI 



### KVComp: A High-Performance, LLM-Aware, Lossy Compression Framework for   KV Cache
**Authors**: Bo Jiang, Taolue Yang, Youyuan Liu, Chengming Zhang, Xubin He, Sian Jin

**Updated**: 2025-08-30T18:25:19Z

**Summary**: Transformer-based large language models (LLMs) demonstrate impressive potential in various practical applications. However, long context inference poses a significant challenge due to the enormous memory requirements of the key-value (KV) cache, which can scale to multiple gigabytes as sequence length and batch size increase. In this paper, we present KVComp, a generic and efficient KV cache management framework optimized for long-text generation that synergistically works with both latency-critical and throughput-critical inference systems. KVComp employs novel lossy compression techniques specifically designed for KV cache data characteristics, featuring careful co-design of compression algorithms and system architecture. Our approach maintains compatibility with the growing nature of KV cache while preserving high computational efficiency. Experimental results show that KVComp achieves on average 47\% and up to 83\% higher memory reduction rate compared to existing methods with little/no model accuracy degradation. Furthermore, KVComp achieves extremely high execution throughput, effectively reducing decompression overhead and, in some cases, even accelerating the matrix-vector multiplication operation and outperform cuBLAS-based attention kernels with less data movement.

**Link**: [arxiv](http://arxiv.org/abs/2509.00579v1),  [pdf](http://arxiv.org/pdf/2509.00579v1)

**Tags**: cs.DC cs.AI 



### Discrete and Continuous Caching Games
**Authors**: Áron Jánosik, Csenge Miklós, Dániel G. Simon, Kristóf Zólomy

**Updated**: 2025-08-30T14:49:34Z

**Summary**: We investigate a discrete search game called the Multiple Caching Game where the searcher's aim is to find all of a set of $d$ treasures hidden in $n$ locations. Allowed queries are sets of locations of size $k$, and the searcher wins if in all $d$ queries, at least one treasure is hidden in one of the $k$ picked locations. P\'alv\"olgyi showed that the value of the game is at most $\frac{k^d}{\binom{n+d-1}{d}}$, with equality for large enough $n$. We conjecture the exact cases of equality. We also investigate variants of the game and show an example where their values are different, answering a question of P\'alv\"olgyi.   This game is closely related to a continuous variant, Alpern's Caching Game, based on which we define other continous variants of the multiple caching game and examine their values.

**Link**: [arxiv](http://arxiv.org/abs/2310.13777v2),  [pdf](http://arxiv.org/pdf/2310.13777v2)

**Tags**: math.OC math.CO 91A05 



### DiffKV: Differentiated Memory Management for Large Language Models with   Parallel KV Compaction
**Authors**: Yanqi Zhang, Yuwei Hu, Runyuan Zhao, John C. S. Lui, Haibo Chen

**Updated**: 2025-08-30T09:35:22Z

**Summary**: Large language models (LLMs) demonstrate remarkable capabilities but face substantial serving costs due to their high memory demands, with the key-value (KV) cache being a primary bottleneck. State-of-the-art KV cache compression techniques, such as quantization and pruning, apply uniform treatment to both keys and values, and discard unimportant tokens entirely, overlooking the fine-grained distinctions in the significance of individual KV cache components. To address such limitations, we introduce \textit{DiffKV}, a novel framework for efficient KV cache compression that exploits three levels of differentiation in the KV cache: (1) the differing impact of keys and values on attention computation, (2) the varying importance of tokens, and (3) the diverse dynamic sparsity patterns across attention heads. These levels of differentiation introduce irregular memory usage patterns across different requests and attention heads, posing significant scalability challenges for memory management. To address these challenges, DiffKV proposes an on-GPU memory manager that compacts fragmented free memory list into contiguous regions in parallel, effectively translating sparsity in the KV cache into performance gains. We evaluate DiffKV on several mainstream LLMs, including the emerging thinking models that generate extended chains of thought. DiffKV is able to compress the KV cache by $2.7\times$ to $5.7\times$ with near-lossless accuracy on complex workloads requiring sophisticated reasoning and long-generation capabilities, and enhances throughput by $1.9\times$ to $5.4\times$. Source codes of DiffKV are available at https://github.com/zyqCSL/DiffKV.

**Link**: [arxiv](http://arxiv.org/abs/2412.03131v3),  [pdf](http://arxiv.org/pdf/2412.03131v3)

**Tags**: cs.LG cs.DC 



### LightVLM: Acceleraing Large Multimodal Models with Pyramid Token Merging   and KV Cache Compression
**Authors**: Lianyu Hu, Fanhua Shang, Wei Feng, Liang Wan

**Updated**: 2025-08-30T08:57:53Z

**Summary**: In this paper, we introduce LightVLM, a simple but effective method that can be seamlessly deployed upon existing Vision-Language Models (VLMs) to greatly accelerate the inference process in a training-free manner. We divide the inference procedure of VLMs into two stages, i.e., encoding and decoding, and propose to simultaneously accelerate VLMs in both stages to largely improve model efficiency. During encoding, we propose pyramid token merging to reduce tokens of different LLM layers in a hierarchical manner by finally only keeping a few dominant tokens to achieve high efficiency. During decoding, aimed at reducing the high latency of outputting long sequences, we propose KV Cache compression to remove unnecessary caches to increase the network throughput. Experimental results show that LightVLM successfully retains 100% performance when only preserving 35% image tokens, and maintains around 98% performance when keeping only 3% image tokens. LightVLM could 2.02$\times$ the network throughput and reduce the prefilling time by 3.65$\times$. LightVLM also makes large VLMs faster again by enabling a heavy model (e.g., InternVL2.5 26B) to infer faster than significantly smaller models (e.g., InternVL2.5 8B), hopefully facilitating the real-world deployment. When generating long text sequences (e.g., 4096 tokens), LightVLM could reduce the inference time by 3.21$\times$, largely outperforming existing methods.

**Link**: [arxiv](http://arxiv.org/abs/2509.00419v1),  [pdf](http://arxiv.org/pdf/2509.00419v1)

**Tags**: cs.CV 



### GraphKV: Breaking the Static Selection Paradigm with Graph-Based KV   Cache Eviction
**Authors**: Xuelin Li, Xiangqi Jin, Linfeng Zhang

**Updated**: 2025-08-30T06:56:28Z

**Summary**: Efficient Key-Value (KV) cache management is essential for processing long text sequences in large language models (LLMs), where memory constraints often limit performance. Conventional KV eviction strategies, such as top-k selection based on attention scores, depend on static heuristics that fail to capture the evolving implicit dependencies among tokens during inference. To overcome this, we propose GraphKV, a graph-based framework that redefines token selection for KV cache compression. In GraphKV, tokens are modeled as nodes with importance scores, and edges represent their similarity relationships. Through a decay-signal-propagation mechanism, token importance is dynamically updated by propagating information across the graph, enabling adaptive retention of the most contextually significant tokens. GraphKV can be seamlessly utilized in existing KV cache eviction methods such as SnapKV and PyramidKV in a plug-and-play manner. Codes will be released on Github.

**Link**: [arxiv](http://arxiv.org/abs/2509.00388v1),  [pdf](http://arxiv.org/pdf/2509.00388v1)

**Tags**: cs.CL 



### Robust Containment Queries over Collections of Trimmed NURBS Surfaces   via Generalized Winding Numbers
**Authors**: Jacob Spainhour, Kenneth Weiss

**Updated**: 2025-08-29T20:39:21Z

**Summary**: We propose a containment query that is robust to the watertightness of regions bound by trimmed NURBS surfaces, as this property is difficult to guarantee for in-the-wild CAD models. Containment is determined through the generalized winding number (GWN), a mathematical construction that is indifferent to the arrangement of surfaces in the shape. Applying contemporary techniques for the 3D GWN to trimmed NURBS surfaces requires some form of geometric discretization, introducing computational inefficiency to the algorithm and even risking containment misclassifications near the surface. In contrast, our proposed method uses a novel reformulation of the relevant surface integral based on Stokes' theorem, which operates on the boundary and trimming curves as provided through rapidly converging adaptive quadrature. Batches of queries are further accelerated by memoizing (i.e.\ caching and reusing) quadrature node positions and tangents as they are evaluated. We demonstrate that our GWN method is robust to complex trimming geometry in a CAD model, and is accurate up to arbitrary precision at arbitrary distances from the surface. The derived containment query is therefore robust to model non-watertightness while respecting all curved features of the input shape.

**Link**: [arxiv](http://arxiv.org/abs/2504.11435v2),  [pdf](http://arxiv.org/pdf/2504.11435v2)

**Tags**: cs.GR cs.CG cs.NA math.NA 68U05 I.3.5 



### From TLinFormer to TConstFormer: The Leap to Constant-Time Transformer   Attention: Achieving O(1) Computation and O(1) KV Cache during Autoregressive   Inference
**Authors**: Zhongpan Tang

**Updated**: 2025-08-29T19:23:35Z

**Summary**: Although the Transformer has become the cornerstone of modern AI, its autoregressive inference suffers from a linearly growing KV Cache and a computational complexity of O(N^2 d), severely hindering its ability to process ultra-long sequences. To overcome this limitation, this paper introduces the TConstFormer architecture, building upon our previous work, TLinFormer. TConstFormer employs an innovative periodic state update mechanism to achieve a truly constant-size O(1) KV Cache. The computational complexity of this mechanism is also O(1) in an amortized sense: it performs purely constant-time computations for $k-1$ consecutive steps (e.g., $k=256$) and executes a single linear-time global information synchronization only on the $k$-th step. Theoretical calculations and experimental results demonstrate that TConstFormer exhibits an overwhelming advantage over baseline models in terms of speed, memory efficiency, and overall performance on long-text inference tasks. This breakthrough paves the way for efficient and robust streaming language model applications.

**Link**: [arxiv](http://arxiv.org/abs/2509.00202v1),  [pdf](http://arxiv.org/pdf/2509.00202v1)

**Tags**: cs.LG 



### Democratizing Agentic AI with Fast Test-Time Scaling on the Edge
**Authors**: Hao Mark Chen, Zhiwen Mo, Guanxi Lu, Shuang Liang, Lingxiao Ma, Wayne Luk, Hongxiang Fan

**Updated**: 2025-08-29T19:12:04Z

**Summary**: Deploying agentic AI on edge devices is crucial for privacy and responsiveness, but memory constraints typically relegate these systems to smaller Large Language Models (LLMs) with inferior reasoning capabilities. Test-Time Scaling (TTS) can bridge this reasoning gap by dedicating more compute during inference, but existing methods incur prohibitive overhead on edge hardware. To overcome this, we introduce FlashTTS, a serving system that makes TTS practical for memory-constrained LLM reasoning. FlashTTS introduces three synergistic optimizations: (i) Speculative Beam Extension to mitigate system stragglers from irregular reasoning paths; (ii) Asymmetric Multi-Model Memory Allocation to dynamically balance memory between generation and verification; and (iii) Dynamic Prefix-Aware Scheduling to maximize KV-cache reuse. Built as a plug-and-play library for vLLM, FlashTTS enables edge LLMs on a single consumer GPU (24 GB) to match the accuracy and latency of large cloud models. Our evaluation demonstrates that FlashTTS achieves an average 2.2x higher goodput and reduces latency by 38%-68% compared to a vLLM baseline, paving the way for democratized, high-performance agentic AI on edge devices.

**Link**: [arxiv](http://arxiv.org/abs/2509.00195v1),  [pdf](http://arxiv.org/pdf/2509.00195v1)

**Tags**: cs.LG 



### Towards Compute-Optimal Many-Shot In-Context Learning
**Authors**: Shahriar Golchin, Yanfei Chen, Rujun Han, Manan Gandhi, Tianli Yu, Swaroop Mishra, Mihai Surdeanu, Rishabh Agarwal, Chen-Yu Lee, Tomas Pfister

**Updated**: 2025-08-29T18:45:22Z

**Summary**: Long-context large language models (LLMs) are able to process inputs containing up to several million tokens. In the scope of in-context learning (ICL), this translates into using hundreds/thousands of demonstrations in the input prompt, enabling many-shot ICL. In practice, a fixed set of demonstrations is often selected at random in many-shot settings due to (1) high inference costs, (2) the benefits of caching and reusing computations, and (3) the similar performance offered by this strategy compared to others when scaled. In this work, we propose two straightforward strategies for demonstration selection in many-shot ICL that improve performance with minimal computational overhead. Our first method combines a small number of demonstrations, selected based on their similarity to each test sample, with a disproportionately larger set of random demonstrations that are cached. The second strategy improves the first by replacing random demonstrations with those selected using centroids derived from test sample representations via k-means clustering. Our experiments with Gemini Pro and Flash across several datasets indicate that our strategies consistently outperform random selection and surpass or match the most performant selection approach while supporting caching and reducing inference cost by up to an order of magnitude. We also show that adjusting the proportion of demonstrations selected based on different criteria can balance performance and inference cost in many-shot ICL.

**Link**: [arxiv](http://arxiv.org/abs/2507.16217v2),  [pdf](http://arxiv.org/pdf/2507.16217v2)

**Tags**: cs.CL cs.AI cs.LG 



### Neural Visibility Cache for Real-Time Light Sampling
**Authors**: Jakub Bokšanský, Daniel Meister

**Updated**: 2025-08-29T09:58:17Z

**Summary**: Direct illumination with many lights is an inherent component of physically-based rendering, remaining challenging, especially in real-time scenarios. We propose an online-trained neural cache that stores visibility between lights and 3D positions. We feed light visibility to weighted reservoir sampling (WRS) to sample a light source. The cache is implemented as a fully-fused multilayer perceptron (MLP) with multi-resolution hash-grid encoding, enabling online training and efficient inference on modern GPUs in real-time frame rates. The cache can be seamlessly integrated into existing rendering frameworks and can be used in combination with other real-time techniques such as spatiotemporal reservoir sampling (ReSTIR).

**Link**: [arxiv](http://arxiv.org/abs/2506.05930v2),  [pdf](http://arxiv.org/pdf/2506.05930v2)

**Tags**: cs.GR 



### FedSEA-LLaMA: A Secure, Efficient and Adaptive Federated Splitting   Framework for Large Language Models
**Authors**: Zishuai Zhang, Hainan zhang, Weihua Li, Qinnan zhang, jin Dong, Yongxin Tong, Zhiming Zheng

**Updated**: 2025-08-29T07:40:34Z

**Summary**: Private data holds promise for improving LLMs due to its high quality, but its scattered distribution across data silos and the high computational demands of LLMs limit their deployment in federated environments. To address this, the transformer-based federated split models are proposed, which offload most model parameters to the server (or distributed clients) while retaining only a small portion on the client to ensure data privacy. Despite this design, they still face three challenges: 1) Peer-to-peer key encryption struggles to secure transmitted vectors effectively; 2) The auto-regressive nature of LLMs means that federated split learning can only train and infer sequentially, causing high communication overhead; 3) Fixed partition points lack adaptability to downstream tasks. In this paper, we introduce FedSEA-LLaMA, a Secure, Efficient, and Adaptive Federated splitting framework based on LLaMA2. First, we inject Gaussian noise into forward-pass hidden states to enable secure end-to-end vector transmission. Second, we employ attention-mask compression and KV cache collaboration to reduce communication costs, accelerating training and inference. Third, we allow users to dynamically adjust the partition points for input/output blocks based on specific task requirements. Experiments on natural language understanding, summarization, and conversational QA tasks show that FedSEA-LLaMA maintains performance comparable to centralized LLaMA2 and achieves up to 8x speedups in training and inference. Further analysis of privacy attacks and different partition points also demonstrates the effectiveness of FedSEA-LLaMA in security and adaptability.

**Link**: [arxiv](http://arxiv.org/abs/2505.15683v2),  [pdf](http://arxiv.org/pdf/2505.15683v2)

**Tags**: cs.CL cs.AI cs.DC 



### Enhancing LLM Efficiency: Targeted Pruning for Prefill-Decode   Disaggregation in Inference
**Authors**: Hao Zhang, Mengsi Lyu, Yulong Ao, Yonghua Lin

**Updated**: 2025-08-29T02:29:52Z

**Summary**: Large Language Models (LLMs) demonstrate exceptional capabilities across various tasks, but their deployment is constrained by high computational and memory costs. Model pruning provides an effective means to alleviate these demands. However, existing methods often ignore the characteristics of prefill-decode (PD) disaggregation in practice. In this paper, we propose a novel pruning method for PD disaggregation inference, enabling more precise and efficient block and KV Cache pruning. Our approach constructs pruning and distillation sets to perform iterative block removal independently for the prefill and decode stages, obtaining better pruning solutions. Moreover, we introduce a token-aware cache pruning mechanism that retains all KV Cache in the prefill stage but selectively reuses entries for the first and last token sequences in selected layers during decode, reducing communication costs with minimal overhead. Extensive experiments demonstrate that our approach consistently achieves strong performance in both PD disaggregation and PD unified settings without disaggregation. Under the default settings, our method achieves a 20.56% inference speedup and a 4.95 times reduction in data transmission bandwidth consumption.

**Link**: [arxiv](http://arxiv.org/abs/2509.04467v1),  [pdf](http://arxiv.org/pdf/2509.04467v1)

**Tags**: cs.CL cs.AI 



### Deep Multiple Quantization Network on Long Behavior Sequence for   Click-Through Rate Prediction
**Authors**: Zhuoxing Wei, Qi Liu, Qingchen Xie

**Updated**: 2025-08-28T14:58:47Z

**Summary**: In Click-Through Rate (CTR) prediction, the long behavior sequence, comprising the user's long period of historical interactions with items has a vital influence on assessing the user's interest in the candidate item. Existing approaches strike efficiency and effectiveness through a two-stage paradigm: first retrieving hundreds of candidate-related items and then extracting interest intensity vector through target attention. However, we argue that the discrepancy in target attention's relevance distribution between the retrieved items and the full long behavior sequence inevitably leads to a performance decline. To alleviate the discrepancy, we propose the Deep Multiple Quantization Network (DMQN) to process long behavior sequence end-to-end through compressing the long behavior sequence. Firstly, the entire spectrum of long behavior sequence will be quantized into multiple codeword sequences based on multiple independent codebooks. Hierarchical Sequential Transduction Unit is incorporated to facilitate the interaction of reduced codeword sequences. Then, attention between the candidate and multiple codeword sequences will output the interest vector. To enable online serving, intermediate representations of the codeword sequences are cached, significantly reducing latency. Our extensive experiments on both industrial and public datasets confirm the effectiveness and efficiency of DMQN. The A/B test in our advertising system shows that DMQN improves CTR by 3.5% and RPM by 2.0%.

**Link**: [arxiv](http://arxiv.org/abs/2508.20865v1),  [pdf](http://arxiv.org/pdf/2508.20865v1)

**Tags**: cs.IR 



### SOT-MRAM Bitcell Scaling with BEOL Read Selectors: A DTCO Study
**Authors**: Yang Xiang, Fernando García-Redondo, Arvind Sharma, Van Dai Nguyen, Andrea Fantini, Philippe Matagne, Siddharth Rao, Subhali Subhechha, Lynn Verschueren, Mohammed Aftab Baig, Marie Garcia Bardon, Geert Hellings

**Updated**: 2025-08-28T08:49:24Z

**Summary**: This work explores the cross-node scaling potential of SOT-MRAM for last-level caches (LLCs) under heterogeneous system scaling paradigm. We perform extensive Design-Technology Co-Optimization (DTCO) exercises to evaluate the bitcell footprint for different cell configurations at a representative 7 nm technology and to assess their implications on read and write power-performance. We crucially identify the MTJ routing struggle in conventional two-transistor one-resistor (2T1R) SOT-MRAMs as the primary bitcell area scaling challenge and propose to use BEOL read selectors (BEOL RSs) that enable (10 -- 40) % bitcell area reduction and eventually match sub-N3 SRAM. On writability, we affirm that BEOL RS-based bitcells could meet the required SOT switching current, provided the magnetic free layer properties be engineered in line with LLC-specific, (0.1 -- 100) s retention targets. This is particularly to attribute to their (i) more available Si fins for write transistor and (ii) lower bitline resistance at reduced cell width. We nevertheless underscore the read tradeoff associated with BEOL RSs, with the low-drive IGZO-FET selector sacrificing the latency up to (3 -- 5) ns and the imperfectly rectifying diode selectors suffering (2.5 -- 5)$\times$ energy cost relative to 2T1R. This article thus highlights the realistic prospects and hurdles of BEOL RSs towards holistic power-performance-area scaling of SOT-MRAM.

**Link**: [arxiv](http://arxiv.org/abs/2508.18250v2),  [pdf](http://arxiv.org/pdf/2508.18250v2)

**Tags**: cs.ET 



### Matrixed-Spectrum Decomposition Accelerated Linear Boltzmann Transport   Equation Solver for Fast Scatter Correction in Multi-Spectral CT
**Authors**: Guoxi Zhu, Li Zhang, Zhiqiang Chen, Hewei Gao

**Updated**: 2025-08-28T08:05:42Z

**Summary**: X-ray scatter has been a serious concern in computed tomography (CT), leading to image artifacts and distortion of CT values. The linear Boltzmann transport equation (LBTE) is recognized as a fast and accurate approach for scatter estimation. However, for multi-spectral CT, it is cumbersome to compute multiple scattering components for different spectra separately when applying LBTE-based scatter correction. In this work, we propose a Matrixed-Spectrum Decomposition accelerated LBTE solver (MSD-LBTE) that can be used to compute X-ray scatter distributions from CT acquisitions at two or more different spectra simultaneously, in a unified framework with no sacrifice in accuracy and nearly no increase in computation in theory. First, a matrixed-spectrum solver of LBTE is obtained by introducing an additional label dimension to expand the phase space. Then, we propose a ``spectrum basis'' for LBTE and a principle of selection of basis using the QR decomposition, along with the above solver to construct the MSD-LBTE. Based on MSD-LBTE, a unified scatter correction method can be established for multi-spectral CT. We validate the effectiveness and accuracy of our method by comparing it with the Monte Carlo method, including the computational time. We also evaluate the scatter correction performance using two different phantoms for fast-kV switching based dual-energy CT, and using an elliptical phantom in a numerical simulation for kV-modulation enabled CT scans, validating that our proposed method can significantly reduce the computational cost at multiple spectra and effectively reduce scatter artifact in reconstructed CT images.

**Link**: [arxiv](http://arxiv.org/abs/2508.20524v1),  [pdf](http://arxiv.org/pdf/2508.20524v1)

**Tags**: physics.med-ph 



### MegaCacheX: Towards Cost-Effective Hierarchical Collaborative Content   Caching in Emerging Mega-Constellations
**Authors**: Haoyang Shi, Xing Zhang, Sitong Li, Minghang Li, Xinming Lu, Shaoxiang Xu, Guoquan Wang

**Updated**: 2025-08-28T05:22:25Z

**Summary**: Significant latency in global content delivery primarily arises from insufficient terrestrial infrastructure. Deploying space-based content delivery networks within emerging mega-constellations provides an effective means to bridge the digital divide. However, space-based caching faces constraints from physical-layer dynamics, including dynamic topologies, time-varying inter-satellite link conditions, and limited onboard energy. In addition, existing mechanisms often lack fine-grained content categorization and global optimization. This paper proposes MegaCacheX, a cost-effective hierarchical framework for collaborative content distribution that achieves "Earth-independence" by providing cloud services directly from space. Specifically, data centers in Sun-synchronous orbit act as primary content sources, while caching nodes in mega-constellations and ground stations collaboratively form a distributed edge layer. MegaCacheX optimizes caching strategies by integrating content popularity, regional user distribution, and satellite trajectory predictions. Multi-tier caching nodes serve as service anchors, enabling seamless content delivery with low latency. A prototype implemented on a microservices-based, containerized testbed demonstrates that MegaCacheX reduces global content access latency by about 36% compared to baseline approaches, while maintaining cost efficiency.

**Link**: [arxiv](http://arxiv.org/abs/2508.20433v1),  [pdf](http://arxiv.org/pdf/2508.20433v1)

**Tags**: eess.SY cs.SY 



### Breaking Diffusion with Cache: Exploiting Approximate Caches in   Diffusion Models
**Authors**: Desen Sun, Shuncheng Jie, Sihang Liu

**Updated**: 2025-08-28T04:46:44Z

**Summary**: Diffusion models are a powerful class of generative models that produce content, such as images, from user prompts, but they are computationally intensive. To mitigate this cost, recent academic and industry work has adopted approximate caching, which reuses intermediate states from similar prompts in a cache. While efficient, this optimization introduces new security risks by breaking isolation among users. This work aims to comprehensively assess new security vulnerabilities arising from approximate caching. First, we demonstrate a remote covert channel established with the cache, where a sender injects prompts with special keywords into the cache and a receiver can recover that even after days, to exchange information. Second, we introduce a prompt stealing attack using the cache, where an attacker can recover existing cached prompts based on cache hit prompts. Finally, we introduce a poisoning attack that embeds the attacker's logos into the previously stolen prompt, to render them in future user prompts that hit the cache. These attacks are all performed remotely through the serving system, which indicates severe security vulnerabilities in approximate caching.

**Link**: [arxiv](http://arxiv.org/abs/2508.20424v1),  [pdf](http://arxiv.org/pdf/2508.20424v1)

**Tags**: cs.CR 



### Rethinking Transformer Connectivity: TLinFormer, A Path to Exact, Full   Context-Aware Linear Attention
**Authors**: Zhongpan Tang

**Updated**: 2025-08-28T04:10:19Z

**Summary**: The Transformer architecture has become a cornerstone of modern artificial intelligence, but its core self-attention mechanism suffers from a complexity bottleneck that scales quadratically with sequence length, severely limiting its application in long-sequence tasks. To address this challenge, existing linear attention methods typically sacrifice model performance by relying on data-agnostic kernel approximations or restrictive context selection. This paper returns to the first principles of connectionism, starting from the topological structure of information flow, to introduce a novel linear attention architecture-\textbf{TLinFormer}. By reconfiguring neuron connection patterns, TLinFormer achieves strict linear complexity while computing exact attention scores and ensuring information flow remains aware of the full historical context. This design aims to bridge the performance gap prevalent between existing efficient attention methods and standard attention. Through a series of experiments, we systematically evaluate the performance of TLinFormer against a standard Transformer baseline on long-sequence inference tasks. The results demonstrate that TLinFormer exhibits overwhelming advantages in key metrics such as \textbf{inference latency}, \textbf{KV cache efficiency}, \textbf{memory footprint}, and \textbf{overall speedup}.

**Link**: [arxiv](http://arxiv.org/abs/2508.20407v1),  [pdf](http://arxiv.org/pdf/2508.20407v1)

**Tags**: cs.LG 



### ASVD: Activation-aware Singular Value Decomposition for Compressing   Large Language Models
**Authors**: Zhihang Yuan, Yuzhang Shang, Yue Song, Dawei Yang, Qiang Wu, Yan Yan, Guangyu Sun

**Updated**: 2025-08-28T03:57:52Z

**Summary**: In this paper, we introduce a new post-training compression paradigm for Large Language Models (LLMs) to facilitate their wider adoption. We delve into LLM weight low-rank decomposition, and find that the challenges of this task stem from (1) the distribution variance in the LLM activations and (2) the sensitivity difference among various kinds of layers. To address these issues, we propose a training-free approach called Activation-aware Singular Value Decomposition (ASVD). Specifically, ASVD manages activation outliers by transforming the weight matrix based on the activation distribution. This transformation allows the outliers in the activation matrix to be absorbed into the transformed weight matrix, thereby enhancing decomposition accuracy. Additionally, we propose an efficient iterative calibration process to optimize layer-specific decomposition by addressing the varying sensitivity of different LLM layers. In this way, ASVD can compress a network by 10%-30%. Based on the success of the low-rank decomposition of projection matrices in the self-attention module, we further introduce ASVD to compress the KV cache. By reducing the channel dimension of KV activations, memory requirements for KV cache can be largely reduced. ASVD can further achieve 50% KV cache reductions without performance drop in a training-free manner.

**Link**: [arxiv](http://arxiv.org/abs/2312.05821v5),  [pdf](http://arxiv.org/pdf/2312.05821v5)

**Tags**: cs.CL 



### Climber: Toward Efficient Scaling Laws for Large Recommendation Models
**Authors**: Songpei Xu, Shijia Wang, Da Guo, Xianwen Guo, Qiang Xiao, Bin Huang, Guanlin Wu, Chuanjiang Luo

**Updated**: 2025-08-28T01:40:30Z

**Summary**: Transformer-based generative models have achieved remarkable success across domains with various scaling law manifestations. However, our extensive experiments reveal persistent challenges when applying Transformer to recommendation systems: (1) Transformer scaling is not ideal with increased computational resources, due to structural incompatibilities with recommendation-specific features such as multi-source data heterogeneity; (2) critical online inference latency constraints (tens of milliseconds) that intensify with longer user behavior sequences and growing computational demands. We propose Climber, an efficient recommendation framework comprising two synergistic components: the model architecture for efficient scaling and the co-designed acceleration techniques. Our proposed model adopts two core innovations: (1) multi-scale sequence extraction that achieves a time complexity reduction by a constant factor, enabling more efficient scaling with sequence length; (2) dynamic temperature modulation adapting attention distributions to the multi-scenario and multi-behavior patterns. Complemented by acceleration techniques, Climber achieves a 5.15$\times$ throughput gain without performance degradation by adopting a "single user, multiple item" batched processing and memory-efficient Key-Value caching. Comprehensive offline experiments on multiple datasets validate that Climber exhibits a more ideal scaling curve. To our knowledge, this is the first publicly documented framework where controlled model scaling drives continuous online metric growth (12.19\% overall lift) without prohibitive resource costs. Climber has been successfully deployed on Netease Cloud Music, one of China's largest music streaming platforms, serving tens of millions of users daily.

**Link**: [arxiv](http://arxiv.org/abs/2502.09888v2),  [pdf](http://arxiv.org/pdf/2502.09888v2)

**Tags**: cs.IR 



### AdaptCache: KV Cache Native Storage Hierarchy for Low-Delay and   High-Quality Language Model Serving
**Authors**: Shaoting Feng, Hanchen Li, Kuntai Du, Zhuohan Gu, Yuhan Liu, Jiayi Yao, Siddhant Ray, Samuel Shen, Yihua Cheng, Ganesh Ananthanarayanan, Junchen Jiang

**Updated**: 2025-08-28T00:46:51Z

**Summary**: Large language model (LLM) applications often reuse previously processed context, such as chat history and documents, which introduces significant redundant computation. Existing LLM serving systems address such redundant computation by storing the KV caches of processed context and loading the corresponding KV cache when a new request reuses the context. Further, as these LLM applications scale, the total size of KV caches becomes excessively large and requires both DRAM and SSD for full storage.   However, prior work that stores KV caches in DRAM and SSD suffers from high loading delays, as most KV cache hits come from SSD, which is slow to load. To increase the KV cache hit rate on DRAM, we identify lossy KV cache compression as a promising approach. We design a lossy compression system that decides the compression algorithm, compression rate and device placement for each KV cache entry to maximise DRAM hits and minimise loading delay without significantly degrading generation quality. Compared to various static compression baselines across three tasks, our system AdaptCache achieves 1.43--2.4 x delay savings at the same quality and 6--55% quality improvements at the same delay.

**Link**: [arxiv](http://arxiv.org/abs/2509.00105v1),  [pdf](http://arxiv.org/pdf/2509.00105v1)

**Tags**: cs.OS 



### DRR-MDPF: A Queue Management Strategy Based on Dynamic Resource   Allocation and Markov Decision Process in Named Data Networking (NDN)
**Authors**: Fatemeh Roshanzadeh, Hamid Barati, Ali Barati

**Updated**: 2025-08-27T21:05:05Z

**Summary**: Named Data Networking (NDN) represents a transformative shift in network architecture, prioritizing content names over host addresses to enhance data dissemination. Efficient queue and resource management are critical to NDN performance, especially under dynamic and high-traffic conditions. This paper introduces DRR-MDPF, a novel hybrid strategy that integrates the Markov Decision Process Forwarding (MDPF) model with the Deficit Round Robin (DRR) algorithm. MDPF enables routers to intelligently predict optimal forwarding decisions based on key metrics such as bandwidth, delay, and the number of unsatisfied Interests, while DRR ensures fair and adaptive bandwidth allocation among competing data flows. The proposed method models each router as a learning agent capable of adjusting its strategies through continuous feedback and probabilistic updates. Simulation results using ndnSIM demonstrate that DRR-MDPF significantly outperforms state-of-the-art strategies including SAF, RFA, SMDPF, and LA-MDPF across various metrics such as throughput, Interest Satisfaction Rate (ISR), packet drop rate, content retrieval time, and load balancing. Notably, DRR-MDPF maintains robustness under limited cache sizes and heavy traffic, offering enhanced adaptability and lower computational complexity due to its single-path routing design. Furthermore, its multi-metric decision-making capability enables more accurate interface selection, leading to optimized network performance. Overall, DRR-MDPF serves as an intelligent, adaptive, and scalable queue management solution for NDN, effectively addressing core challenges such as resource allocation, congestion control, and route optimization in dynamic networking environments.

**Link**: [arxiv](http://arxiv.org/abs/2508.20272v1),  [pdf](http://arxiv.org/pdf/2508.20272v1)

**Tags**: cs.NI 



### SpeedMalloc: Improving Multi-threaded Applications via a Lightweight   Core for Memory Allocation
**Authors**: Ruihao Li, Qinzhe Wu, Krishna Kavi, Gayatri Mehta, Jonathan C. Beard, Neeraja J. Yadwadkar, Lizy K. John

**Updated**: 2025-08-27T20:18:37Z

**Summary**: Memory allocation, though constituting only a small portion of the executed code, can have a "butterfly effect" on overall program performance, leading to significant and far-reaching impacts. Despite accounting for just approximately 5% of total instructions, memory allocation can result in up to a 2.7x performance variation depending on the allocator used. This effect arises from the complexity of memory allocation in modern multi-threaded multi-core systems, where allocator metadata becomes intertwined with user data, leading to cache pollution or increased cross-thread synchronization overhead. Offloading memory allocators to accelerators, e.g., Mallacc and Memento, is a potential direction to improve the allocator performance and mitigate cache pollution. However, these accelerators currently have limited support for multi-threaded applications, and synchronization between cores and accelerators remains a significant challenge.   We present SpeedMalloc, using a lightweight support-core to process memory allocation tasks in multi-threaded applications. The support-core is a lightweight programmable processor with efficient cross-core data synchronization and houses all allocator metadata in its own caches. This design minimizes cache conflicts with user data and eliminates the need for cross-core metadata synchronization. In addition, using a general-purpose core instead of domain-specific accelerators makes SpeedMalloc capable of adopting new allocator designs. We compare SpeedMalloc with state-of-the-art software and hardware allocators, including Jemalloc, TCMalloc, Mimalloc, Mallacc, and Memento. SpeedMalloc achieves 1.75x, 1.18x, 1.15x, 1.23x, and 1.18x speedups on multithreaded workloads over these five allocators, respectively.

**Link**: [arxiv](http://arxiv.org/abs/2508.20253v1),  [pdf](http://arxiv.org/pdf/2508.20253v1)

**Tags**: cs.DC cs.AR 



### MODE: Mixture of Document Experts for RAG
**Authors**: Rahul Anand

**Updated**: 2025-08-27T17:45:16Z

**Summary**: Retrieval-Augmented Generation (RAG) often relies on large vector databases and cross-encoders tuned for large-scale corpora, which can be excessive for small, domain-specific collections. We present MODE (Mixture of Document Experts), a lightweight alternative that replaces fine-grained nearest-neighbor search with cluster-and-route retrieval. Documents are embedded, grouped into semantically coherent clusters, and represented by cached centroids. At query time, we route to the top centroid(s) and retrieve context only within those clusters, eliminating external vector-database infrastructure and reranking while keeping latency low. On HotpotQA and SQuAD corpora with 100-500 chunks, MODE matches or exceeds a dense-retrieval baseline in answer quality while reducing end-to-end retrieval time. Ablations show that cluster granularity and multi-cluster routing control the recall/precision trade-off, and that tighter clusters improve downstream accuracy. MODE offers a practical recipe for small and medium corpora where simplicity, speed, and topical focus matter.

**Link**: [arxiv](http://arxiv.org/abs/2509.00100v1),  [pdf](http://arxiv.org/pdf/2509.00100v1)

**Tags**: cs.AI 



### Apple Intelligence Foundation Language Models: Tech Report 2025
**Authors**: Ethan Li, Anders Boesen Lindbo Larsen, Chen Zhang, Xiyou Zhou, Jun Qin, Dian Ang Yap, Narendran Raghavan, Xuankai Chang, Margit Bowler, Eray Yildiz, John Peebles, Hannah Gillis Coleman, Matteo Ronchi, Peter Gray, Keen You, Anthony Spalvieri-Kruse, Ruoming Pang, Reed Li, Yuli Yang, Emad Soroush, Zhiyun Lu, Crystal Xiao, Rong Situ, Jordan Huffaker, David Griffiths, Zaid Ahmed, Peng Zhang, Daniel Parilla, Asaf Liberman, Jennifer Mallalieu, Parsa Mazaheri, Qibin Chen, Manjot Bilkhu, Aonan Zhang, Eric Wang, Dave Nelson, Michael FitzMaurice, Thomas Voice, Jeremy Liu, Josh Shaffer, Shiwen Zhao, Prasanth Yadla, Farzin Rasteh, Pengsheng Guo, Arsalan Farooq, Jeremy Snow, Stephen Murphy, Tao Lei, Minsik Cho, George Horrell, Sam Dodge, Lindsay Hislop, Sumeet Singh, Alex Dombrowski, Aiswarya Raghavan, Sasha Sirovica, Mandana Saebi, Faye Lao, Max Lam, TJ Lu, Zhaoyang Xu, Karanjeet Singh, Marc Kirchner, David Mizrahi, Rajat Arora, Haotian Zhang, Henry Mason, Lawrence Zhou, Yi Hua, Ankur Jain, Felix Bai, Joseph Astrauskas, Floris Weers, Josh Gardner, Mira Chiang, Yi Zhang, Pulkit Agrawal, Tony Sun, Quentin Keunebroek, Matthew Hopkins, Bugu Wu, Tao Jia, Chen Chen, Xingyu Zhou, Nanzhu Wang, Peng Liu, Ruixuan Hou, Rene Rauch, Yuan Gao, Afshin Dehghan, Jonathan Janke, Zirui Wang, Cha Chen, Xiaoyi Ren, Feng Nan, Josh Elman, Dong Yin, Yusuf Goren, Jeff Lai, Yiran Fei, Syd Evans, Muyang Yu, Guoli Yin, Yi Qin, Erin Feldman, Isha Garg, Aparna Rajamani, Karla Vega, Walker Cheng, TJ Collins, Hans Han, Raul Rea Menacho, Simon Yeung, Sophy Lee, Phani Mutyala, Ying-Chang Cheng, Zhe Gan, Sprite Chu, Justin Lazarow, Alessandro Pappalardo, Federico Scozzafava, Jing Lu, Erik Daxberger, Laurent Duchesne, Jen Liu, David Güera, Stefano Ligas, Mary Beth Kery, Brent Ramerth, Ciro Sannino, Marcin Eichner, Haoshuo Huang, Rui Qian, Moritz Schwarzer-Becker, David Riazati, Mingfei Gao, Bailin Wang, Jack Cackler, Yang Lu, Ransen Niu, John Dennison, Guillaume Klein, Jeffrey Bigham, Deepak Gopinath, Navid Shiee, Darren Botten, Guillaume Tartavel, Alex Guillen Garcia, Sam Xu, Victoria MönchJuan Haladjian, Zi-Yi Dou, Matthias Paulik, Adolfo Lopez Mendez, Zhen Li, Hong-You Chen, Chao Jia, Dhaval Doshi, Zhengdong Zhang, Raunak Manjani, Aaron Franklin, Zhile Ren, David Chen, Artsiom Peshko, Nandhitha Raghuram, Hans Hao, Jiulong Shan, Kavya Nerella, Ramsey Tantawi, Vivek Kumar, Saiwen Wang, Brycen Wershing, Bhuwan Dhingra, Dhruti Shah, Ob Adaranijo, Xin Zheng, Tait Madsen, Hadas Kotek, Chang Liu, Yin Xia, Hanli Li, Suma Jayaram, Yanchao Sun, Ahmed Fakhry, Vasileios Saveris, Dustin Withers, Yanghao Li, Alp Aygar, Andres Romero Mier Y Teran, Kaiwei Huang, Mark Lee, Xiujun Li, Yuhong Li, Tyler Johnson, Jay Tang, Joseph Yitan Cheng, Futang Peng, Andrew Walkingshaw, Lucas Guibert, Abhishek Sharma, Cheng Shen, Piotr Maj, Yasutaka Tanaka, You-Cyuan Jhang, Vivian Ma, Tommi Vehvilainen, Kelvin Zou, Jeff Nichols, Matthew Lei, David Qiu, Yihao Qian, Gokul Santhanam, Wentao Wu, Yena Han, Dominik Moritz, Haijing Fu, Mingze Xu, Vivek Rathod, Jian Liu, Louis D'hauwe, Qin Ba, Haitian Sun, Haoran Yan, Philipp Dufter, Anh Nguyen, Yihao Feng, Emma Wang, Keyu He, Rahul Nair, Sanskruti Shah, Jiarui Lu, Patrick Sonnenberg, Jeremy Warner, Yuanzhi Li, Bowen Pan, Ziyi Zhong, Joe Zhou, Sam Davarnia, Olli Saarikivi, Irina Belousova, Rachel Burger, Shang-Chen Wu, Di Feng, Bas Straathof, James Chou, Yuanyang Zhang, Marco Zuliani, Eduardo Jimenez, Abhishek Sundararajan, Xianzhi Du, Chang Lan, Nilesh Shahdadpuri, Peter Grasch, Sergiu Sima, Josh Newnham, Varsha Paidi, Jianyu Wang, Kaelen Haag, Alex Braunstein, Daniele Molinari, Richard Wei, Brenda Yang, Nicholas Lusskin, Joanna Arreaza-Taylor, Meng Cao, Nicholas Seidl, Simon Wang, Jiaming Hu, Yiping Ma, Mengyu Li, Kieran Liu, Hang Su, Sachin Ravi, Chong Wang, Xin Wang, Kevin Smith, Haoxuan You, Binazir Karimzadeh, Rui Li, Jinhao Lei, Wei Fang, Alec Doane, Sam Wiseman, Ismael Fernandez, Jane Li, Andrew Hansen, Javier Movellan, Christopher Neubauer, Hanzhi Zhou, Chris Chaney, Nazir Kamaldin, Valentin Wolf, Fernando Bermúdez-Medina, Joris Pelemans, Peter Fu, Howard Xing, Xiang Kong, Wayne Shan, Gabriel Jacoby-Cooper, Dongcai Shen, Tom Gunter, Guillaume Seguin, Fangping Shi, Shiyu Li, Yang Xu, Areeba Kamal, Dan Masi, Saptarshi Guha, Qi Zhu, Jenna Thibodeau, Changyuan Zhang, Rebecca Callahan, Charles Maalouf, Wilson Tsao, Boyue Li, Qingqing Cao, Naomy Sabo, Cheng Leong, Yi Wang, Anupama Mann Anupama, Colorado Reed, Kenneth Jung, Zhifeng Chen, Mohana Prasad Sathya Moorthy, Yifei He, Erik Hornberger, Devi Krishna, Senyu Tong, Michael, Lee, David Haldimann, Yang Zhao, Bowen Zhang, Chang Gao, Chris Bartels, Sushma Rao, Nathalie Tran, Simon Lehnerer, Co Giang, Patrick Dong, Junting Pan, Biyao Wang, Dongxu Li, Mehrdad Farajtabar, Dongseong Hwang, Grace Duanmu, Eshan Verma, Sujeeth Reddy, Qi Shan, Hongbin Gao, Nan Du, Pragnya Sridhar, Forrest Huang, Yingbo Wang, Nikhil Bhendawade, Diane Zhu, Sai Aitharaju, Fred Hohman, Lauren Gardiner, Chung-Cheng Chiu, Yinfei Yang, Alper Kokmen, Frank Chu, Ke Ye, Kaan Elgin, Oron Levy, John Park, Donald Zhang, Eldon Schoop, Nina Wenzel, Michael Booker, Hyunjik Kim, Chinguun Erdenebileg, Nan Dun, Eric Liang Yang, Priyal Chhatrapati, Vishaal Mahtani, Haiming Gang, Kohen Chia, Deepa Seshadri, Donghan Yu, Yan Meng, Kelsey Peterson, Zhen Yang, Yongqiang Wang, Carina Peng, Doug Kang, Anuva Agarwal, Albert Antony, Juan Lao Tebar, Albin Madappally Jose, Regan Poston, Andy De Wang, Gerard Casamayor, Elmira Amirloo, Violet Yao, Wojciech Kryscinski, Kun Duan, Lezhi L

**Updated**: 2025-08-27T16:34:47Z

**Summary**: We introduce two multilingual, multimodal foundation language models that power Apple Intelligence features across Apple devices and services: i a 3B-parameter on-device model optimized for Apple silicon through architectural innovations such as KV-cache sharing and 2-bit quantization-aware training; and ii a scalable server model built on a novel Parallel-Track Mixture-of-Experts PT-MoE transformer that combines track parallelism, mixture-of-experts sparse computation, and interleaved global-local attention to deliver high quality with competitive cost on Apple's Private Cloud Compute platform. Both models are trained on large-scale multilingual and multimodal datasets sourced via responsible web crawling, licensed corpora, and high-quality synthetic data, then further refined with supervised fine-tuning and reinforcement learning on a new asynchronous platform. The resulting models support several additional languages while understanding images and executing tool calls. In public benchmarks and human evaluations, both the server model and the on-device model match or surpass comparably sized open baselines.   A new Swift-centric Foundation Models framework exposes guided generation, constrained tool calling, and LoRA adapter fine-tuning, allowing developers to integrate these capabilities with a few lines of code. The latest advancements in Apple Intelligence models are grounded in our Responsible AI approach with safeguards like content filtering and locale-specific evaluation, as well as our commitment to protecting our users' privacy with innovations like Private Cloud Compute.

**Link**: [arxiv](http://arxiv.org/abs/2507.13575v3),  [pdf](http://arxiv.org/pdf/2507.13575v3)

**Tags**: cs.LG cs.AI 



### Re-thinking Memory-Bound Limitations in CGRAs
**Authors**: Xiangfeng Liu, Zhe Jiang, Anzhen Zhu, Xiaomeng Han, Mingsong Lyu, Qingxu Deng, Nan Guan

**Updated**: 2025-08-27T12:13:45Z

**Summary**: Coarse-Grained Reconfigurable Arrays (CGRAs) are specialized accelerators commonly employed to boost performance in workloads with iterative structures. Existing research typically focuses on compiler or architecture optimizations aimed at improving CGRA performance, energy efficiency, flexibility, and area utilization, under the idealistic assumption that kernels can access all data from Scratchpad Memory (SPM). However, certain complex workloads-particularly in fields like graph analytics, irregular database operations, and specialized forms of high-performance computing (e.g., unstructured mesh simulations)-exhibit irregular memory access patterns that hinder CGRA utilization, sometimes dropping below 1.5%, making the CGRA memory-bound. To address this challenge, we conduct a thorough analysis of the underlying causes of performance degradation, then propose a redesigned memory subsystem and refine the memory model. With both microarchitectural and theoretical optimization, our solution can effectively manage irregular memory accesses through CGRA-specific runahead execution mechanism and cache reconfiguration techniques. Our results demonstrate that we can achieve performance comparable to the original SPM-only system while requiring only 1.27% of the storage size. The runahead execution mechanism achieves an average 3.04x speedup (up to 6.91x), with cache reconfiguration technique providing an additional 6.02% improvement, significantly enhancing CGRA performance for irregular memory access patterns.

**Link**: [arxiv](http://arxiv.org/abs/2508.09570v2),  [pdf](http://arxiv.org/pdf/2508.09570v2)

**Tags**: cs.AR B.3.0; B.6.0 



### ERTACache: Error Rectification and Timesteps Adjustment for Efficient   Diffusion
**Authors**: Xurui Peng, Hong Liu, Chenqian Yan, Rui Ma, Fangmin Chen, Xing Wang, Zhihua Wu, Songwei Liu, Mingbao Lin

**Updated**: 2025-08-27T10:37:24Z

**Summary**: Diffusion models suffer from substantial computational overhead due to their inherently iterative inference process. While feature caching offers a promising acceleration strategy by reusing intermediate outputs across timesteps, naive reuse often incurs noticeable quality degradation. In this work, we formally analyze the cumulative error introduced by caching and decompose it into two principal components: feature shift error, caused by inaccuracies in cached outputs, and step amplification error, which arises from error propagation under fixed timestep schedules. To address these issues, we propose ERTACache, a principled caching framework that jointly rectifies both error types. Our method employs an offline residual profiling stage to identify reusable steps, dynamically adjusts integration intervals via a trajectory-aware correction coefficient, and analytically approximates cache-induced errors through a closed-form residual linearization model. Together, these components enable accurate and efficient sampling under aggressive cache reuse. Extensive experiments across standard image and video generation benchmarks show that ERTACache achieves up to 2x inference speedup while consistently preserving or even improving visual quality. Notably, on the state-of-the-art Wan2.1 video diffusion model, ERTACache delivers 2x acceleration with minimal VBench degradation, effectively maintaining baseline fidelity while significantly improving efficiency. The code is available at https://github.com/bytedance/ERTACache.

**Link**: [arxiv](http://arxiv.org/abs/2508.21091v1),  [pdf](http://arxiv.org/pdf/2508.21091v1)

**Tags**: cs.CV 



### Beyond the Bermuda Triangle of Contention: IOMMU Interference in Mixed   Criticality Systems
**Authors**: Diogo Costa, Jose Martins, Sandro Pinto

**Updated**: 2025-08-27T08:30:33Z

**Summary**: As Mixed Criticality Systems (MCSs) evolve, they increasingly integrate heterogeneous computing platforms, combining general-purpose processors with specialized accelerators such as AI engines, GPUs, and high-speed networking interfaces. This heterogeneity introduces challenges, as these accelerators and DMA-capable devices act as independent bus masters, directly accessing memory. Consequently, ensuring both security and timing predictability in such environments becomes critical. To address these concerns, the Input-Output Memory Management Unit (IOMMU) plays a key role in mediating and regulating memory access, preventing unauthorized transactions while enforcing isolation and access control policies. While prior work has explored IOMMU-related side-channel vulnerabilities from a security standpoint, its role in performance interference remains largely unexplored. Moreover, many of the same architectural properties that enable side-channel leakage, such as shared TLBs, caching effects, and translation overheads, can also introduce timing unpredictability. In this work, we analyze the contention effects within IOMMU structures using the Xilinx UltraScale+ ZCU104 platform, demonstrating how their shared nature introduce unpredictable delays. Our findings reveal that IOMMU-induced interference primarily affects small memory transactions, where translation overheads significantly impact execution time. Additionally, we hypothesize that contention effects arising from IOTLBs exhibit similar behavior across architectures due to shared caching principles, such as prefetching and hierarchical TLB structures. Notably, our experiments show that IOMMU interference can delay DMA transactions by up to 1.79x for lower-size transfers on the Arm SMMUv2 implementation.

**Link**: [arxiv](http://arxiv.org/abs/2508.19670v1),  [pdf](http://arxiv.org/pdf/2508.19670v1)

**Tags**: cs.DC cs.SY eess.SY 



### FiRST: Finetuning Router-Selective Transformers for Input-Adaptive   Latency Reduction
**Authors**: Akriti Jain, Saransh Sharma, Koyel Mukherjee, Soumyabrata Pal

**Updated**: 2025-08-27T04:58:58Z

**Summary**: Auto-regressive Large Language Models (LLMs) demonstrate remarkable performance across different domains such as vision and language processing. However, due to sequential processing through a stack of transformer layers, autoregressive decoding faces significant computation/latency challenges, particularly in resource-constrained environments like mobile and edge devices. Existing approaches in literature that aim to improve latency via skipping layers have two distinct flavors - 1) Early exit, and 2) Input-agnostic heuristics where tokens exit at pre-determined layers irrespective of input sequence. Both the above strategies have limitations - the former cannot be applied to handle KV Caching necessary for speed-ups in modern framework and the latter does not capture the variation in layer importance across tasks or more generally, across input sequences. To address both limitations, we propose FiRST, an algorithm that reduces inference latency by using layer-specific routers to select a subset of transformer layers adaptively for each input sequence - the prompt (during the prefill stage) decides which layers will be skipped during decoding. FiRST preserves compatibility with KV caching enabling faster inference while being quality-aware. FiRST is model-agnostic and can be easily enabled on any pre-trained LLM. Our approach reveals that input adaptivity is critical - indeed, different task-specific middle layers play a crucial role in evolving hidden representations depending on tasks. Extensive experiments show that FiRST significantly reduces latency while outperforming other layer selection strategies in quality metics. It retains competitive performance to base model (without layer skipping) and in some cases, even improves upon it. FiRST is thus a promising and efficient solution for LLM deployment in low-resource environments.

**Link**: [arxiv](http://arxiv.org/abs/2410.12513v4),  [pdf](http://arxiv.org/pdf/2410.12513v4)

**Tags**: cs.CL 



### VoxHammer: Training-Free Precise and Coherent 3D Editing in Native 3D   Space
**Authors**: Lin Li, Zehuan Huang, Haoran Feng, Gengxiong Zhuang, Rui Chen, Chunchao Guo, Lu Sheng

**Updated**: 2025-08-26T17:59:47Z

**Summary**: 3D local editing of specified regions is crucial for game industry and robot interaction. Recent methods typically edit rendered multi-view images and then reconstruct 3D models, but they face challenges in precisely preserving unedited regions and overall coherence. Inspired by structured 3D generative models, we propose VoxHammer, a novel training-free approach that performs precise and coherent editing in 3D latent space. Given a 3D model, VoxHammer first predicts its inversion trajectory and obtains its inverted latents and key-value tokens at each timestep. Subsequently, in the denoising and editing phase, we replace the denoising features of preserved regions with the corresponding inverted latents and cached key-value tokens. By retaining these contextual features, this approach ensures consistent reconstruction of preserved areas and coherent integration of edited parts. To evaluate the consistency of preserved regions, we constructed Edit3D-Bench, a human-annotated dataset comprising hundreds of samples, each with carefully labeled 3D editing regions. Experiments demonstrate that VoxHammer significantly outperforms existing methods in terms of both 3D consistency of preserved regions and overall quality. Our method holds promise for synthesizing high-quality edited paired data, thereby laying the data foundation for in-context 3D generation. See our project page at https://huanngzh.github.io/VoxHammer-Page/.

**Link**: [arxiv](http://arxiv.org/abs/2508.19247v1),  [pdf](http://arxiv.org/pdf/2508.19247v1)

**Tags**: cs.CV 



### Enabling MoE on the Edge via Importance-Driven Expert Scheduling
**Authors**: Guoying Zhu, Meng Li, Haipeng Dai, Xuechen Liu, Weijun Wang, Keran Li, Jun xiao, Ligeng Chen, Wei Wang

**Updated**: 2025-08-26T12:32:09Z

**Summary**: The Mixture of Experts (MoE) architecture has emerged as a key technique for scaling Large Language Models by activating only a subset of experts per query. Deploying MoE on consumer-grade edge hardware, however, is constrained by limited device memory, making dynamic expert offloading essential. Unlike prior work that treats offloading purely as a scheduling problem, we leverage expert importance to guide decisions, substituting low-importance activated experts with functionally similar ones already cached in GPU memory, thereby preserving accuracy. As a result, this design reduces memory usage and data transfer, while largely eliminating PCIe overhead. In addition, we introduce a scheduling policy that maximizes the reuse ratio of GPU-cached experts, further boosting efficiency. Extensive evaluations show that our approach delivers 48% lower decoding latency with over 60% expert cache hit rate, while maintaining nearly lossless accuracy.

**Link**: [arxiv](http://arxiv.org/abs/2508.18983v1),  [pdf](http://arxiv.org/pdf/2508.18983v1)

**Tags**: cs.AI 



### Rethinking Caching for LLM Serving Systems: Beyond Traditional   Heuristics
**Authors**: Jungwoo Kim, Minsang Kim, Jaeheon Lee, Chanwoo Moon, Heejin Kim, Taeho Hwang, Woosuk Chung, Yeseong Kim, Sungjin Lee

**Updated**: 2025-08-26T07:09:09Z

**Summary**: Serving Large Language Models (LLMs) at scale requires meeting strict Service Level Objectives (SLOs) under severe computational and memory constraints. Nevertheless, traditional caching strategies fall short: exact-matching and prefix caches neglect query semantics, while state-of-the-art semantic caches remain confined to traditional intuitions, offering little conceptual departure. Building on this, we present SISO, a semantic caching system that redefines efficiency for LLM serving. SISO introduces centroid-based caching to maximize coverage with minimal memory, locality-aware replacement to preserve high-value entries, and dynamic thresholding to balance accuracy and latency under varying workloads. Across diverse datasets, SISO delivers up to 1.71$\times$ higher hit ratios and consistently stronger SLO attainment compared to state-of-the-art systems.

**Link**: [arxiv](http://arxiv.org/abs/2508.18736v1),  [pdf](http://arxiv.org/pdf/2508.18736v1)

**Tags**: cs.DB cs.LG 



### Krul: Efficient State Restoration for Multi-turn Conversations with   Dynamic Cross-layer KV Sharing
**Authors**: Junyi Wen, Junyuan Liang, Zicong Hong, Wuhui Chen, Ting Cai, Zibin Zheng

**Updated**: 2025-08-26T01:55:27Z

**Summary**: Efficient state restoration in multi-turn conversations with large language models (LLMs) remains a critical challenge, primarily due to the overhead of recomputing or loading full key-value (KV) caches for all historical tokens. To address this, existing approaches compress KV caches across adjacent layers with highly similar attention patterns. However, these methods often apply a fixed compression scheme across all conversations, selecting the same layer pairs for compression without considering conversation-specific attention dynamics. This static strategy overlooks variability in attention pattern similarity across different conversations, which can lead to noticeable accuracy degradation.   We present Krul, a multi-turn LLM inference system that enables accurate and efficient KV cache restoration. Krul dynamically selects compression strategies based on attention similarity across layer pairs and uses a recomputation-loading pipeline to restore the KV cache. It introduces three key innovations: 1) a preemptive compression strategy selector to preserve critical context for future conversation turns and selects a customized strategy for the conversation; 2) a token-wise heterogeneous attention similarity estimator to mitigate the attention similarity computation and storage overhead during model generation; 3) a bubble-free restoration scheduler to reduce potential bubbles brought by the imbalance of recomputing and loading stream due to compressed KV caches. Empirical evaluations on real-world tasks demonstrate that Krul achieves a 1.5x-2.68x reduction in time-to-first-token (TTFT) and a 1.33x-2.35x reduction in KV cache storage compared to state-of-the-art methods without compromising generation quality.

**Link**: [arxiv](http://arxiv.org/abs/2507.08045v2),  [pdf](http://arxiv.org/pdf/2507.08045v2)

**Tags**: cs.CL cs.AI 



### AGILE: Lightweight and Efficient Asynchronous GPU-SSD Integration
**Authors**: Zhuoping Yang, Jinming Zhuang, Xingzhen Chen, Alex K. Jones, Peipei Zhou

**Updated**: 2025-08-26T01:45:34Z

**Summary**: GPUs are critical for compute-intensive applications, yet emerging workloads such as recommender systems, graph analytics, and data analytics often exceed GPU memory capacity. Existing solutions allow GPUs to use CPU DRAM or SSDs as external memory, and the GPU-centric approach enables GPU threads to directly issue NVMe requests, further avoiding CPU intervention. However, current GPU-centric approaches adopt synchronous I/O, forcing threads to stall during long communication delays.   We propose AGILE, a lightweight asynchronous GPU-centric I/O library that eliminates deadlock risks and integrates a flexible HBM-based software cache. AGILE overlaps computation and I/O, improving performance by up to 1.88$\times$ across workloads with diverse computation-to-communication ratios. Compared to BaM on DLRM, AGILE achieves up to 1.75$\times$ speedup through efficient design and overlapping; on graph applications, AGILE reduces software cache overhead by up to 3.12$\times$ and NVMe I/O overhead by up to 2.85$\times$; AGILE also lowers per-thread register usage by up to 1.32$\times$.

**Link**: [arxiv](http://arxiv.org/abs/2504.19365v3),  [pdf](http://arxiv.org/pdf/2504.19365v3)

**Tags**: cs.DC 



## Keyword: LLM Inference 
 ### WhisTLE: Deeply Supervised, Text-Only Domain Adaptation for Pretrained   Speech Recognition Transformers
**Authors**: Akshat Pandey, Karun Kumar, Raphael Tang

**Updated**: 2025-09-12T17:59:09Z

**Summary**: Pretrained automatic speech recognition (ASR) models such as Whisper perform well but still need domain adaptation to handle unseen vocabulary and parlance. In many real-world settings, collecting speech data is impractical, necessitating text-only adaptation. We propose WhisTLE, a deeply supervised, text-only adaptation method for pretrained encoder-decoder ASR models. WhisTLE trains a variational autoencoder (VAE) to model encoder outputs from text and fine-tunes the decoder using the learned text-to-latent encoder, optionally combined with text-to-speech (TTS) adaptation. At inference, the original encoder is restored, incurring no extra runtime cost. Across four out-of-domain datasets and four ASR models, WhisTLE with TTS reduces word error rate (WER) by 12.3% relative to TTS-only adaptation and outperforms all non-WhisTLE baselines in 27 of 32 scenarios.

**Link**: [arxiv](http://arxiv.org/abs/2509.10452v1),  [pdf](http://arxiv.org/pdf/2509.10452v1)

**Tags**: cs.CL cs.LG 



### DeepDive: Advancing Deep Search Agents with Knowledge Graphs and   Multi-Turn RL
**Authors**: Rui Lu, Zhenyu Hou, Zihan Wang, Hanchen Zhang, Xiao Liu, Yujiang Li, Shi Feng, Jie Tang, Yuxiao Dong

**Updated**: 2025-09-12T17:52:35Z

**Summary**: Augmenting large language models (LLMs) with browsing tools substantially improves their potential as deep search agents to solve complex, real-world tasks. Yet, open LLMs still perform poorly in such settings due to limited long-horizon reasoning capacity with browsing tools and the lack of sufficiently difficult supervised data. To address these challenges, we present DeepDive to advance deep search agents. First, we propose a strategy to automatically synthesize complex, difficult, and hard-to-find questions from open knowledge graphs. Second, we apply end-to-end multi-turn reinforcement learning (RL) to enhance LLMs' long-horizon reasoning with deep search. Experiments show that DeepDive-32B achieves a new open-source competitive result on BrowseComp, outperforming WebSailor, DeepSeek-R1-Browse, and Search-o1. We demonstrate that multi-turn RL training improves deep search ability and significantly contributes to the performance improvements across multiple benchmarks. We observe that DeepDive enables test-time scaling of tool calls and parallel sampling. All datasets, models, and code are publicly available at https://github.com/THUDM/DeepDive.

**Link**: [arxiv](http://arxiv.org/abs/2509.10446v1),  [pdf](http://arxiv.org/pdf/2509.10446v1)

**Tags**: cs.CL 



### RefactorCoderQA: Benchmarking LLMs for Multi-Domain Coding Question   Solutions in Cloud and Edge Deployment
**Authors**: Shadikur Rahman, Aroosa Hameed, Gautam Srivastava, Syed Muhammad Danish

**Updated**: 2025-09-12T17:44:22Z

**Summary**: To optimize the reasoning and problem-solving capabilities of Large Language Models (LLMs), we propose a novel cloud-edge collaborative architecture that enables a structured, multi-agent prompting framework. This framework comprises three specialized components: GuideLLM, a lightweight model deployed at the edge to provide methodological guidance; SolverLLM, a more powerful model hosted in the cloud responsible for generating code solutions; and JudgeLLM, an automated evaluator for assessing solution correctness and quality. To evaluate and demonstrate the effectiveness of this architecture in realistic settings, we introduce RefactorCoderQA, a comprehensive benchmark designed to evaluate and enhance the performance of Large Language Models (LLMs) across multi-domain coding tasks. Motivated by the limitations of existing benchmarks, RefactorCoderQA systematically covers various technical domains, including Software Engineering, Data Science, Machine Learning, and Natural Language Processing, using authentic coding challenges from Stack Overflow. Extensive experiments reveal that our fine-tuned model, RefactorCoder-MoE, achieves state-of-the-art performance, significantly outperforming leading open-source and commercial baselines with an overall accuracy of 76.84%. Human evaluations further validate the interpretability, accuracy, and practical relevance of the generated solutions. In addition, we evaluate system-level metrics, such as throughput and latency, to gain deeper insights into the performance characteristics and trade-offs of the proposed architecture.

**Link**: [arxiv](http://arxiv.org/abs/2509.10436v1),  [pdf](http://arxiv.org/pdf/2509.10436v1)

**Tags**: cs.CL 



### LMAR: Language Model Augmented Retriever for Domain-specific Knowledge   Indexing
**Authors**: Yao Zhao, Yantian Ding, Zhiyue Zhang, Dapeng Yao, Yanxun Xu

**Updated**: 2025-09-12T17:32:41Z

**Summary**: Retrieval Augmented Generation (RAG) systems often struggle with domain-specific knowledge due to performance deterioration of pre-trained embeddings and prohibitive computational costs of large language model (LLM)-based retrievers. While fine-tuning data augmentation embedding models offers a promising direction, its effectiveness is limited by the need for high-quality training data and reliable chunking strategies that preserve contextual integrity. We propose LMAR (Language Model Augmented Retriever), a model-agnostic framework that addresses these challenges by combining LLM-guided data synthesis with contrastive embedding adaptation and efficient text clustering. LMAR consists of a two-stage pipeline: (1) Triplet sampling and synthetic data augmentation, where LLMs act as both labeler and validator to ensure high-fidelity supervision throughout the pipeline. Experimental results across multiple domain-specific benchmark datasets demonstrate that LMAR outperforms multiple baseline models, while maintaining moderate hardware requirements and low latency. Its model-agnostic nature further enables seamless integration with emerging RAG architectures and text embedding models, ensuring continual improvements without redesigning the pipeline. These results highlight LMAR as a practical and cost-effective solution for scalable domain-specific adaptation.

**Link**: [arxiv](http://arxiv.org/abs/2508.05672v2),  [pdf](http://arxiv.org/pdf/2508.05672v2)

**Tags**: cs.IR cs.AI 



### My Favorite Streamer is an LLM: Discovering, Bonding, and Co-Creating in   AI VTuber Fandom
**Authors**: Jiayi Ye, Chaoran Chen, Yue Huang, Yanfang Ye, Toby Jia-Jun Li, Xiangliang Zhang

**Updated**: 2025-09-12T17:31:40Z

**Summary**: AI VTubers, where the performer is not human but algorithmically generated, introduce a new context for fandom. While human VTubers have been substantially studied for their cultural appeal, parasocial dynamics, and community economies, little is known about how audiences engage with their AI counterparts. To address this gap, we present a qualitative study of Neuro-sama, the most prominent AI VTuber. Our findings show that engagement is anchored in active co-creation: audiences are drawn by the AI's unpredictable yet entertaining interactions, cement loyalty through collective emotional events that trigger anthropomorphic projection, and sustain attachment via the AI's consistent persona. Financial support emerges not as a reward for performance but as a participatory mechanism for shaping livestream content, establishing a resilient fan economy built on ongoing interaction. These dynamics reveal how AI Vtuber fandom reshapes fan-creator relationships and offer implications for designing transparent and sustainable AI-mediated communities.

**Link**: [arxiv](http://arxiv.org/abs/2509.10427v1),  [pdf](http://arxiv.org/pdf/2509.10427v1)

**Tags**: cs.HC 



### Direct Judgement Preference Optimization
**Authors**: Peifeng Wang, Austin Xu, Yilun Zhou, Caiming Xiong, Shafiq Joty

**Updated**: 2025-09-12T17:21:39Z

**Summary**: Auto-evaluation is crucial for assessing response quality and offering feedback for model development. Recent studies have explored training large language models (LLMs) as generative judges to evaluate and critique other models' outputs. In this work, we investigate the idea of learning from both positive and negative data with preference optimization to enhance the evaluation capabilities of LLM judges across an array of different use cases. We achieve this by employing three approaches to collect the preference pairs for different use cases, each aimed at improving our generative judge from a different perspective. Our comprehensive study over a wide range of benchmarks demonstrates the effectiveness of our method. In particular, our generative judge achieves the best performance on 10 out of 13 benchmarks, outperforming strong baselines like GPT-4o and specialized judge models. Further analysis show that our judge model robustly counters inherent biases such as position and length bias, flexibly adapts to any evaluation protocol specified by practitioners, and provides helpful language feedback for improving downstream generator models.

**Link**: [arxiv](http://arxiv.org/abs/2409.14664v3),  [pdf](http://arxiv.org/pdf/2409.14664v3)

**Tags**: cs.CL 



### Testing the nature of compact objects in the lower mass gap using   gravitational wave observations
**Authors**: N. V. Krishnendu, Frank Ohme, K. G. Arun

**Updated**: 2025-09-12T17:18:32Z

**Summary**: As the compact binary catalog continues to grow rapidly, developing and refining tests to probe the nature of compact objects is essential for a comprehensive understanding of both the observed data and the underlying astrophysics of the binary population. We investigate the effectiveness of spin-induced multipole moments (SIQM) and tidal deformability measurements in distinguishing lower mass-gap black hole (BH) binaries from non-BH binaries with different mass and spin configurations. We perform model-agnostic tests on binary BH (BBH) simulations using full Bayesian inference, evaluating the independent and joint measurability of SIQM and tidal parameters across the parameter space. We extend the analysis to simulations of self-interacting spinning boson stars, using synthetic signals that exhibit (a) both SIQM and tidal effects and (b) each effect individually. For case (a), recovery is performed using (i) a BBH model, (ii) a model incorporating both SIQM and tidal effects, and (iii) models including either SIQM or tidal effects. For case (b), we employ (i) a BBH model and (ii) models incorporating either SIQM or tidal effects, consistent with the injection. Simulations employ TaylorF2 waveform model and consider binaries in the low mass gap with varying spin magnitudes. We find that employing an incorrect model to analyze the signal can lead to biases in parameter inference. Notably, when analyzing a simulated binary boson star-like signal with component masses $\rm{(4, 4) \, M_{\odot}}$ using a BBH model, the system is incorrectly identified as having masses $\rm{(8, 2) \, M_{\odot}}$. In contrast, using the correct recovery model that includes both SIQM and tidal deformability effects successfully recovers the true masses, highlighting the significance of waveform model accuracy in performing reliable distinguishability tests for compact objects in the low-mass gap.

**Link**: [arxiv](http://arxiv.org/abs/2509.10420v1),  [pdf](http://arxiv.org/pdf/2509.10420v1)

**Tags**: astro-ph.HE gr-qc 



### Are LLMs Better than Reported? Detecting Label Errors and Mitigating   Their Effect on Model Performance
**Authors**: Omer Nahum, Nitay Calderon, Orgad Keller, Idan Szpektor, Roi Reichart

**Updated**: 2025-09-12T17:18:27Z

**Summary**: NLP benchmarks rely on standardized datasets for training and evaluating models and are crucial for advancing the field. Traditionally, expert annotations ensure high-quality labels; however, the cost of expert annotation does not scale well with the growing demand for larger datasets required by modern models. While crowd-sourcing provides a more scalable solution, it often comes at the expense of annotation precision and consistency. Recent advancements in large language models (LLMs) offer new opportunities to enhance the annotation process, particularly for detecting label errors in existing datasets. In this work, we consider the recent approach of LLM-as-a-judge, leveraging an ensemble of LLMs to flag potentially mislabeled examples. We conduct a case study on four factual consistency datasets from the TRUE benchmark, spanning diverse NLP tasks, and on SummEval, which uses Likert-scale ratings of summary quality across multiple dimensions. We empirically analyze the labeling quality of existing datasets and compare expert, crowd-sourced, and LLM-based annotations in terms of the agreement, label quality, and efficiency, demonstrating the strengths and limitations of each annotation method. Our findings reveal a substantial number of label errors, which, when corrected, induce a significant upward shift in reported model performance. This suggests that many of the LLMs' so-called mistakes are due to label errors rather than genuine model failures. Additionally, we discuss the implications of mislabeled data and propose methods to mitigate them in training to improve performance.

**Link**: [arxiv](http://arxiv.org/abs/2410.18889v2),  [pdf](http://arxiv.org/pdf/2410.18889v2)

**Tags**: cs.CL 



### Parallel-R1: Towards Parallel Thinking via Reinforcement Learning
**Authors**: Tong Zheng, Hongming Zhang, Wenhao Yu, Xiaoyang Wang, Runpeng Dai, Rui Liu, Huiwen Bao, Chengsong Huang, Heng Huang, Dong Yu

**Updated**: 2025-09-12T17:15:56Z

**Summary**: Parallel thinking has emerged as a novel approach for enhancing the reasoning capabilities of large language models (LLMs) by exploring multiple reasoning paths concurrently. However, activating such capabilities through training remains challenging, as existing methods predominantly rely on supervised fine-tuning (SFT) over synthetic data, which encourages teacher-forced imitation rather than exploration and generalization. Different from them, we propose \textbf{Parallel-R1}, the first reinforcement learning (RL) framework that enables parallel thinking behaviors for complex real-world reasoning tasks. Our framework employs a progressive curriculum that explicitly addresses the cold-start problem in training parallel thinking with RL. We first use SFT on prompt-generated trajectories from easier tasks to instill the parallel thinking ability, then transition to RL to explore and generalize this skill on harder problems. Experiments on various math benchmarks, including MATH, AMC23, and AIME, show that Parallel-R1 successfully instills parallel thinking, leading to 8.4% accuracy improvements over the sequential thinking model trained directly on challenging tasks with RL. Further analysis reveals a clear shift in the model's thinking behavior: at an early stage, it uses parallel thinking as an exploration strategy, while in a later stage, it uses the same capability for multi-perspective verification. Most significantly, we validate parallel thinking as a \textbf{mid-training exploration scaffold}, where this temporary exploratory phase unlocks a higher performance ceiling after RL, yielding a 42.9% improvement over the baseline on AIME25. Our model, data, and code will be open-source at https://github.com/zhengkid/Parallel-R1.

**Link**: [arxiv](http://arxiv.org/abs/2509.07980v2),  [pdf](http://arxiv.org/pdf/2509.07980v2)

**Tags**: cs.CL 



### TASC: Task-Aware Shared Control for Teleoperated Manipulation
**Authors**: Ze Fu, Pinhao Song, Yutong Hu, Renaud Detry

**Updated**: 2025-09-12T17:13:18Z

**Summary**: We present TASC, a Task-Aware Shared Control framework for teleoperated manipulation that infers task-level user intent and provides assistance throughout the task. To support everyday tasks without predefined knowledge, TASC constructs an open-vocabulary interaction graph from visual input to represent functional object relationships, and infers user intent accordingly. A shared control policy then provides rotation assistance during both grasping and object interaction, guided by spatial constraints predicted by a vision-language model. Our method addresses two key challenges in general-purpose, long-horizon shared control: (1) understanding and inferring task-level user intent, and (2) generalizing assistance across diverse objects and tasks. Experiments in both simulation and the real world demonstrate that TASC improves task efficiency and reduces user input effort compared to prior methods. To the best of our knowledge, this is the first shared control framework that supports everyday manipulation tasks with zero-shot generalization. The code that supports our experiments is publicly available at https://github.com/fitz0401/tasc.

**Link**: [arxiv](http://arxiv.org/abs/2509.10416v1),  [pdf](http://arxiv.org/pdf/2509.10416v1)

**Tags**: cs.RO 



### Slaves to the Law of Large Numbers: An Asymptotic Equipartition Property   for Perplexity in Generative Language Models
**Authors**: Tyler Bell, Avinash Mudireddy, Ivan Johnson-Eversoll, Soura Dasgupta, Raghu Mudumbai

**Updated**: 2025-09-12T17:03:33Z

**Summary**: We prove a new asymptotic un-equipartition property for the perplexity of long texts generated by a language model and present supporting experimental evidence from open-source models. Specifically we show that the logarithmic perplexity of any large text generated by a language model must asymptotically converge to the average entropy of its token distributions. This defines a ``typical set'' that all long synthetic texts generated by a language model must belong to. We refine the concept of ''typical set'' to include only grammatically correct texts. We then show that this refined typical set is a vanishingly small subset of all possible grammatically correct texts for a very general definition of grammar. This means that language models are strongly constrained in the range of their possible behaviors and outputs. We make no simplifying assumptions (such as stationarity) about the statistics of language model outputs, and therefore our results are directly applicable to practical real-world models without any approximations. We discuss possible applications of the typical set concept to problems such as detecting synthetic texts and membership inference in training datasets.

**Link**: [arxiv](http://arxiv.org/abs/2405.13798v4),  [pdf](http://arxiv.org/pdf/2405.13798v4)

**Tags**: cs.CL cs.AI cs.IT math.IT 



### Self-supervised Learning Of Visual Pose Estimation Without Pose Labels   By Classifying LED States
**Authors**: Nicholas Carlotti, Mirko Nava, Alessandro Giusti

**Updated**: 2025-09-12T16:54:56Z

**Summary**: We introduce a model for monocular RGB relative pose estimation of a ground robot that trains from scratch without pose labels nor prior knowledge about the robot's shape or appearance. At training time, we assume: (i) a robot fitted with multiple LEDs, whose states are independent and known at each frame; (ii) knowledge of the approximate viewing direction of each LED; and (iii) availability of a calibration image with a known target distance, to address the ambiguity of monocular depth estimation. Training data is collected by a pair of robots moving randomly without needing external infrastructure or human supervision. Our model trains on the task of predicting from an image the state of each LED on the robot. In doing so, it learns to predict the position of the robot in the image, its distance, and its relative bearing. At inference time, the state of the LEDs is unknown, can be arbitrary, and does not affect the pose estimation performance. Quantitative experiments indicate that our approach: is competitive with SoA approaches that require supervision from pose labels or a CAD model of the robot; generalizes to different domains; and handles multi-robot pose estimation.

**Link**: [arxiv](http://arxiv.org/abs/2509.10405v1),  [pdf](http://arxiv.org/pdf/2509.10405v1)

**Tags**: cs.RO 



### Developer-LLM Conversations: An Empirical Study of Interactions and   Generated Code Quality
**Authors**: Suzhen Zhong, Ying Zou, Bram Adams

**Updated**: 2025-09-12T16:52:49Z

**Summary**: Large Language Models (LLMs) are becoming integral to modern software development workflows, assisting developers with code generation, API explanation, and iterative problem-solving through natural language conversations. Despite widespread adoption, there is limited understanding of how developers interact with LLMs in practice and how these conversational dynamics influence task outcomes, code quality, and software engineering workflows. To address this, we leverage CodeChat, a large dataset comprising 82,845 real-world developer-LLM conversations, containing 368,506 code snippets generated across over 20 programming languages, derived from the WildChat dataset. We find that LLM responses are substantially longer than developer prompts, with a median token-length ratio of 14:1. Multi-turn conversations account for 68% of the dataset and often evolve due to shifting requirements, incomplete prompts, or clarification requests. Topic analysis identifies web design (9.6% of conversations) and neural network training (8.7% of conversations) as the most frequent LLM-assisted tasks. Evaluation across five languages (i.e., Python, JavaScript, C++, Java, and C#) reveals prevalent and language-specific issues in LLM-generated code: generated Python and JavaScript code often include undefined variables (83.4% and 75.3% of code snippets, respectively); Java code lacks required comments (75.9%); C++ code frequently omits headers (41.1%) and C# code shows unresolved namespaces (49.2%). During a conversation, syntax and import errors persist across turns; however, documentation quality in Java improves by up to 14.7%, and import handling in Python improves by 3.7% over 5 turns. Prompts that point out mistakes in code generated in prior turns and explicitly request a fix are most effective for resolving errors.

**Link**: [arxiv](http://arxiv.org/abs/2509.10402v1),  [pdf](http://arxiv.org/pdf/2509.10402v1)

**Tags**: cs.SE D.2.0; D.2.7 



### Abduct, Act, Predict: Scaffolding Causal Inference for Automated Failure   Attribution in Multi-Agent Systems
**Authors**: Alva West, Yixuan Weng, Minjun Zhu, Zhen Lin, Yue Zhang

**Updated**: 2025-09-12T16:51:15Z

**Summary**: Failure attribution in multi-agent systems -- pinpointing the exact step where a decisive error occurs -- is a critical yet unsolved challenge. Current methods treat this as a pattern recognition task over long conversation logs, leading to critically low step-level accuracy (below 17\%), which renders them impractical for debugging complex systems. Their core weakness is a fundamental inability to perform robust counterfactual reasoning: to determine if correcting a single action would have actually averted the task failure. To bridge this counterfactual inference gap, we introduce Abduct-Act-Predict (A2P) Scaffolding, a novel agent framework that transforms failure attribution from pattern recognition into a structured causal inference task. A2P explicitly guides a large language model through a formal three-step reasoning process within a single inference pass: (1) Abduction, to infer the hidden root causes behind an agent's actions; (2) Action, to define a minimal corrective intervention; and (3) Prediction, to simulate the subsequent trajectory and verify if the intervention resolves the failure. This structured approach leverages the holistic context of the entire conversation while imposing a rigorous causal logic on the model's analysis. Our extensive experiments on the Who\&When benchmark demonstrate its efficacy. On the Algorithm-Generated dataset, A2P achieves 47.46\% step-level accuracy, a 2.85$\times$ improvement over the 16.67\% of the baseline. On the more complex Hand-Crafted dataset, it achieves 29.31\% step accuracy, a 2.43$\times$ improvement over the baseline's 12.07\%. By reframing the problem through a causal lens, A2P Scaffolding provides a robust, verifiable, and significantly more accurate solution for automated failure attribution.

**Link**: [arxiv](http://arxiv.org/abs/2509.10401v1),  [pdf](http://arxiv.org/pdf/2509.10401v1)

**Tags**: cs.AI cs.CL 



### Detecting State Changes in Functional Neuronal Connectivity using   Factorial Switching Linear Dynamical Systems
**Authors**: Yiwei Gong, Susanna B. Mierau, Sinead A. Williamson

**Updated**: 2025-09-12T16:50:26Z

**Summary**: A key question in brain sciences is how to identify time-evolving functional connectivity, such as that obtained from recordings of neuronal activity over time. We wish to explain the observed phenomena in terms of latent states which, in the case of neuronal activity, might correspond to subnetworks of neurons within a brain or organoid. Many existing approaches assume that only one latent state can be active at a time, in contrast to our domain knowledge. We propose a switching dynamical system based on the factorial hidden Markov model. Unlike existing approaches, our model acknowledges that neuronal activity can be caused by multiple subnetworks, which may be activated either jointly or independently. A change in one part of the network does not mean that the entire connectivity pattern will change. We pair our model with scalable variational inference algorithm, using a concrete relaxation of the underlying factorial hidden Markov model, to effectively infer the latent states and model parameters. We show that our algorithm can recover ground-truth structure and yield insights about the maturation of neuronal activity in microelectrode array recordings from in vitro neuronal cultures.

**Link**: [arxiv](http://arxiv.org/abs/2411.04229v2),  [pdf](http://arxiv.org/pdf/2411.04229v2)

**Tags**: stat.ME 37N25, 62M05, 62P10, 62M10 



### RecoWorld: Building Simulated Environments for Agentic Recommender   Systems
**Authors**: Fei Liu, Xinyu Lin, Hanchao Yu, Mingyuan Wu, Jianyu Wang, Qiang Zhang, Zhuokai Zhao, Yinglong Xia, Yao Zhang, Weiwei Li, Mingze Gao, Qifan Wang, Lizhu Zhang, Benyu Zhang, Xiangjun Fan

**Updated**: 2025-09-12T16:44:34Z

**Summary**: We present RecoWorld, a blueprint for building simulated environments tailored to agentic recommender systems. Such environments give agents a proper training space where they can learn from errors without impacting real users. RecoWorld distinguishes itself with a dual-view architecture: a simulated user and an agentic recommender engage in multi-turn interactions aimed at maximizing user retention. The user simulator reviews recommended items, updates its mindset, and when sensing potential user disengagement, generates reflective instructions. The agentic recommender adapts its recommendations by incorporating these user instructions and reasoning traces, creating a dynamic feedback loop that actively engages users. This process leverages the exceptional reasoning capabilities of modern LLMs. We explore diverse content representations within the simulator, including text-based, multimodal, and semantic ID modeling, and discuss how multi-turn RL enables the recommender to refine its strategies through iterative interactions. RecoWorld also supports multi-agent simulations, allowing creators to simulate the responses of targeted user populations. It marks an important first step toward recommender systems where users and agents collaboratively shape personalized information streams. We envision new interaction paradigms where "user instructs, recommender responds," jointly optimizing user retention and engagement.

**Link**: [arxiv](http://arxiv.org/abs/2509.10397v1),  [pdf](http://arxiv.org/pdf/2509.10397v1)

**Tags**: cs.IR 



### Inpainting-Guided Policy Optimization for Diffusion Large Language   Models
**Authors**: Siyan Zhao, Mengchen Liu, Jing Huang, Miao Liu, Chenyu Wang, Bo Liu, Yuandong Tian, Guan Pang, Sean Bell, Aditya Grover, Feiyu Chen

**Updated**: 2025-09-12T16:44:31Z

**Summary**: Masked diffusion large language models (dLLMs) are emerging as promising alternatives to autoregressive LLMs, offering competitive performance while supporting unique generation capabilities such as inpainting. We explore how inpainting can inform RL algorithm design for dLLMs. Aligning LLMs with reinforcement learning faces an exploration challenge: sparse reward signals and sample waste when models fail to discover correct solutions. While this inefficiency affects LLMs broadly, dLLMs offer a distinctive opportunity--their inpainting ability can guide exploration. We introduce IGPO (Inpainting Guided Policy Optimization), an RL framework that strategically inserts partial ground-truth reasoning traces during online sampling. Unlike providing full solutions, inpainting steers exploration toward promising trajectory spaces while preserving self-generated reasoning, bridging supervised fine-tuning and reinforcement learning. We apply IGPO to group-based optimization methods such as GRPO, where exploration failures cause zero advantages and gradients. IGPO restores meaningful gradients while improving sample efficiency. We also propose supervised fine-tuning on synthetically rewritten concise traces that better align with dLLM generation patterns. With additional techniques including entropy-based filtering, our training recipe yields substantial gains across three mathematical benchmarks--GSM8K, Math500, and AMC--achieving new state-of-the-art results for full-attention masked dLLMs.

**Link**: [arxiv](http://arxiv.org/abs/2509.10396v1),  [pdf](http://arxiv.org/pdf/2509.10396v1)

**Tags**: cs.LG 



### Cut Costs, Not Accuracy: LLM-Powered Data Processing with Guarantees
**Authors**: Sepanta Zeighami, Shreya Shankar, Aditya Parameswaran

**Updated**: 2025-09-12T16:30:38Z

**Summary**: Large Language Models (LLMs) are being increasingly used as a building block in data systems to process large text datasets. To do so, LLM model providers offer multiple LLMs with different sizes, spanning various cost-quality trade-offs when processing text at scale. Top-of-the-line LLMs (e.g., GPT-4o, Claude Sonnet) operate with high accuracy but are prohibitively expensive when processing many records. To avoid high costs, more affordable but lower quality LLMs (e.g., GPT-4o-mini, Claude Haiku) can be used to process records, but we need to ensure that the overall accuracy does not deviate substantially from that of the top-of-the-line LLMs. The model cascade framework provides a blueprint to manage this trade-off, by using the confidence of LLMs in their output (e.g., log-probabilities) to decide on which records to use the affordable LLM. However, existing solutions following this framework provide only marginal cost savings and weak theoretical guarantees because of poor estimation of the quality of the affordable LLM's outputs. We present BARGAIN, a method that judiciously uses affordable LLMs in data processing to significantly reduce cost while providing strong theoretical guarantees on the solution quality. BARGAIN employs a novel adaptive sampling strategy and statistical estimation procedure that uses data and task characteristics and builds on recent statistical tools to make accurate estimations with tight theoretical guarantees. Variants of BARGAIN can support guarantees on accuracy, precision, or recall of the output. Experimental results across 8 real-world datasets show that BARGAIN reduces cost, on average, by up to 86% more than state-of-the-art, while providing stronger theoretical guarantees on accuracy of output, with similar gains when guaranteeing a desired level of precision or recall.

**Link**: [arxiv](http://arxiv.org/abs/2509.02896v2),  [pdf](http://arxiv.org/pdf/2509.02896v2)

**Tags**: cs.DB cs.AI 



### Evolving Voices Based on Temporal Poisson Factorisation
**Authors**: Jan Vávra, Bettina Grün, Paul Hofmarcher

**Updated**: 2025-09-12T16:15:25Z

**Summary**: The world is evolving and so is the vocabulary used to discuss topics in speech. Analysing political speech data from more than 30 years requires the use of flexible topic models to uncover the latent topics and their change in prevalence over time as well as the change in the vocabulary of the topics. We propose the temporal Poisson factorisation (TPF) model as an extension to the Poisson factorisation model to model sparse count data matrices obtained based on the bag-of-words assumption from text documents with time stamps. We discuss and empirically compare different model specifications for the time-varying latent variables consisting either of a flexible auto-regressive structure of order one or a random walk. Estimation is based on variational inference where we consider a combination of coordinate ascent updates with automatic differentiation using batching of documents. Suitable variational families are proposed to ease inference. We compare results obtained using independent univariate variational distributions for the time-varying latent variables to those obtained with a multivariate variant. We discuss in detail the results of the TPF model when analysing speeches from 18 sessions in the U.S. Senate (1981-2016).

**Link**: [arxiv](http://arxiv.org/abs/2410.18486v2),  [pdf](http://arxiv.org/pdf/2410.18486v2)

**Tags**: stat.ME cs.LG 62F15 (Primary) 62H99, 68U15 (Secondary) G.3; I.7.m 



### Development of a Compton Imager Setup
**Authors**: Anuraag Arya, Harmanjeet Singh Bilkhu, Sandeep Vishwakarma, Hrishikesh Belatikar, Varun Bhalerao, Abhijeet Ghodgaonkar, Jayprakash G. Koyande, Aditi Marathe, N. P. S. Mithun, Sanjoli Narang, Sudhanshu Nimbalkar, Pranav Page, Sourav Palit, Arpit Patel, Amit Shetye, Siddharth Tallur, Shriharsh Tendulkar, Santosh Vadawale, Gaurav Waratkar

**Updated**: 2025-09-12T16:09:40Z

**Summary**: Hard X-ray photons with energies in the range of hundreds of keV typically undergo Compton scattering when they are incident on a detector. In this process, an incident photon deposits a fraction of its energy at the point of incidence and continues onwards with a change in direction that depends on the amount of energy deposited. By using a pair of detectors to detect the point of incidence and the direction of the scattered photon, we can calculate the scattering direction and angle. The position of a source in the sky can be reconstructed using many Compton photon pairs from a source. We demonstrate this principle in the laboratory by using a pair of Cadmium Zinc Telluride (CZT) detectors sensitive in the energy range of 20-200 keV, similar to those used in $\textit{AstroSat}$/CZT Imager (CZTI). The laboratory setup consists of the two detectors placed perpendicular to each other in a lead-lined box. The detectors are read out by a custom-programmed Xilinx PYNQ-Z2 FPGA board, and data are then transferred to a personal computer (PC)}. There are two key updates from CZTI: the detectors are read concurrently rather than serially, and the time resolution has been improved from $20~\mu$s to $7.5~\mu$s. We irradiated the detectors with a collimated $^{133}\mathrm{Ba}$ source and identified Compton scattering events for the 356 keV line. We run a Compton reconstruction algorithm to correctly infer the location of the source in the detector frame, with a location-dependent angular response measure of $16\deg-30\deg$. This comprises a successful technology demonstration for a Compton imaging camera in the hard X-ray regime. We present the details of our setup, the data acquisition process, and software algorithms, and showcase our results. We also quantify the limitations of this setup and discuss ways of improving the performance in future experiments.

**Link**: [arxiv](http://arxiv.org/abs/2409.08822v2),  [pdf](http://arxiv.org/pdf/2409.08822v2)

**Tags**: astro-ph.IM 



### Dropping Experts, Recombining Neurons: Retraining-Free Pruning for   Sparse Mixture-of-Experts LLMs
**Authors**: Yixiao Zhou, Ziyu Zhao, Dongzhou Cheng, zhiliang wu, Jie Gui, Yi Yang, Fei Wu, Yu Cheng, Hehe Fan

**Updated**: 2025-09-12T16:09:39Z

**Summary**: Sparse Mixture-of-Experts (SMoE) architectures are widely used in large language models (LLMs) due to their computational efficiency. However, though only a few experts are activated for each token, SMoE still requires loading all expert parameters, leading to high memory usage and challenges in deployment. Previous work has tried to reduce the overhead by pruning and merging experts, but primarily focused on expert-level operations, leaving neuron-level structure underexplored. We propose DERN (Dropping Experts, Recombining Neurons), a task-agnostic and retraining-free framework for expert pruning and reconstruction. We observe that experts are often misaligned and contain semantic conflicts at the neuron level, which poses challenges for direct merging. To solve this, DERN works in three steps: it first prunes redundant experts using router statistics; then it decomposes them into neuron-level expert segments, assigning each segment to its most compatible retained expert; and finally, it merges segments within each retained expert to build a compact representation. Experiments on Mixtral, Qwen, and DeepSeek SMoE models show that DERN improves performance by more than 5% on commonsense reasoning and MMLU benchmarks under 50% expert sparsity, without extra training. It also greatly reduces the number of experts and memory usage, making SMoE LLMs easier to deploy in practice.

**Link**: [arxiv](http://arxiv.org/abs/2509.10377v1),  [pdf](http://arxiv.org/pdf/2509.10377v1)

**Tags**: cs.CL 



### MCBP: A Memory-Compute Efficient LLM Inference Accelerator Leveraging   Bit-Slice-enabled Sparsity and Repetitiveness
**Authors**: Huizheng Wang, Zichuan Wang, Zhiheng Yue, Yousheng Long, Taiquan Wei, Jianxun Yang, Yang Wang, Chao Li, Shaojun Wei, Yang Hu, Shouyi Yin

**Updated**: 2025-09-12T16:05:27Z

**Summary**: Large language models (LLMs) face significant inference latency due to inefficiencies in GEMM operations, weight access, and KV cache access, especially in real-time scenarios. This highlights the need for a versatile compute-memory efficient accelerator. Unfortunately, existing Transformer accelerators struggle to address both aspects simultaneously, as they focus on value-level processing, missing fine-grained opportunities to optimize computation and memory collaboratively. This paper introduces MCBP, a bit-grained compute-memory efficient algorithm-hardware co-design that leverages bit-slice (BS) enabled repetitiveness and sparsity to accelerate LLM inference. MCBP features three key innovations: 1) BS-repetitiveness-enabled computation reduction (BRCR), which eliminates redundant GEMM computations via leveraging redundancy hidden among BS vectors; 2) BS-sparsity-enabled two-state coding (BSTC), which reduces weight access via exploiting significant sparsity in high-order bit-slice weight; 3) Bit-grained progressive prediction (BGPP), which reduces KV cache access by leveraging early-termination-based bit-grained prediction. These techniques, supported by custom accelerator designs, effectively alleviate the burden in GEMM, weight access, and KV cache access. Extensive experiments on 26 benchmarks show that MCBP achieves 9.43x speed up and 31.1x higher energy efficiency than Nvidia A100 GPU. Compared to SOTA Transformer accelerators, MCBP achieves 35x, 5.2x and 3.2x energy saving than Spatten, FACT and SOFA, respectively.

**Link**: [arxiv](http://arxiv.org/abs/2509.10372v1),  [pdf](http://arxiv.org/pdf/2509.10372v1)

**Tags**: cs.AR 



### Characterizing the Efficiency of Distributed Training: A Power,   Performance, and Thermal Perspective
**Authors**: Seokjin Go, Joongun Park, Spandan More, Hanjiang Wu, Irene Wang, Aaron Jezghani, Tushar Krishna, Divya Mahajan

**Updated**: 2025-09-12T16:05:07Z

**Summary**: The rapid scaling of Large Language Models (LLMs) has pushed training workloads far beyond the limits of single-node analysis, demanding a deeper understanding of how these models behave across large-scale, multi-GPU systems. In this paper, we present a comprehensive characterization of LLM training across diverse real-world workloads and hardware platforms, including NVIDIA H100/H200 and AMD MI250 GPUs. We analyze dense and sparse models under various parallelism strategies -- tensor, pipeline, data, and expert -- and evaluate their effects on hardware utilization, power consumption, and thermal behavior. We further evaluate the effectiveness of optimizations such as activation recomputation and compute-communication overlap. Our findings show that performance is not determined solely by scaling hardware capacity. Scale-up systems with fewer, higher-memory GPUs can outperform scale-out systems in communication-bound regimes, but only under carefully tuned configurations; in other cases, scale-out deployments achieve superior throughput. We also show that certain parallelism combinations, such as tensor with pipeline, lead to bandwidth underutilization due to inefficient data chunking, while increasing microbatch sizes beyond a certain point induces bursty execution and peak power excursions that worsen thermal throttling. These insights reveal how training performance is shaped by complex interactions between hardware, system topology, and model execution. We conclude by offering recommendations for system and hardware design to improve the scalability and reliability of future LLM systems and workloads. The source code of this project is available at https://github.com/sitar-lab/CharLLM-PPT.

**Link**: [arxiv](http://arxiv.org/abs/2509.10371v1),  [pdf](http://arxiv.org/pdf/2509.10371v1)

**Tags**: cs.DC cs.LG 



### The Language of Approval: Identifying the Drivers of Positive Feedback   Online
**Authors**: Agam Goyal, Charlotte Lambert, Eshwar Chandrasekharan

**Updated**: 2025-09-12T16:03:48Z

**Summary**: Positive feedback via likes and awards is central to online governance, yet which attributes of users' posts elicit rewards -- and how these vary across authors and communities -- remains unclear. To examine this, we combine quasi-experimental causal inference with predictive modeling on 11M posts from 100 subreddits. We identify linguistic patterns and stylistic attributes causally linked to rewards, controlling for author reputation, timing, and community context. For example, overtly complicated language, tentative style, and toxicity reduce rewards. We use our set of curated features to train models that can detect highly-upvoted posts with high AUC. Our audit of community guidelines highlights a ``policy-practice gap'' -- most rules focus primarily on civility and formatting requirements, with little emphasis on the attributes identified to drive positive feedback. These results inform the design of community guidelines, support interfaces that teach users how to craft desirable contributions, and moderation workflows that emphasize positive reinforcement over purely punitive enforcement.

**Link**: [arxiv](http://arxiv.org/abs/2509.10370v1),  [pdf](http://arxiv.org/pdf/2509.10370v1)

**Tags**: cs.HC 



### Constrained Variational Inference via Safe Particle Flow
**Authors**: Yinzhuang Yi, Jorge Cortés, Nikolay Atanasov

**Updated**: 2025-09-12T15:45:10Z

**Summary**: We propose a control barrier function (CBF) formulation for enforcing equality and inequality constraints in variational inference. The key idea is to define a barrier functional on the space of probability density functions that encode the desired constraints imposed on the variational density. By leveraging the Liouville equation, we establish a connection between the time derivative of the variational density and the particle drift, which enables the systematic construction of corresponding CBFs associated to the particle drift. Enforcing these CBFs gives rise to the safe particle flow and ensures that the variational density satisfies the original constraints imposed by the barrier functional. This formulation provides a principled and computationally tractable solution to constrained variational inference, with theoretical guarantees of constraint satisfaction. The effectiveness of the method is demonstrated through numerical simulations.

**Link**: [arxiv](http://arxiv.org/abs/2509.10356v1),  [pdf](http://arxiv.org/pdf/2509.10356v1)

**Tags**: math.OC cs.SY eess.SY 



### UIO-LLMs: Unbiased Incremental Optimization for Long-Context LLMs
**Authors**: Wenhao Li, Mingbao Lin, Yunshan Zhong, Shuicheng Yan, Rongrong Ji

**Updated**: 2025-09-12T15:39:00Z

**Summary**: Managing long texts is challenging for large language models (LLMs) due to limited context window sizes. This study introduces UIO-LLMs, an unbiased incremental optimization approach for memory-enhanced transformers under long-context settings. We initially conceptualize the process as a streamlined encoder-decoder framework where the weights-shared encoder and decoder respectively encapsulate a context segment into memories and leverage these memories to predict outputs of the subsequent segment. Subsequently, by treating our memory-enhanced transformers as fully-connected recurrent neural networks (RNNs), we refine the training process using the Truncated Backpropagation Through Time (TBPTT) algorithm, which incorporates innovative incremental optimization techniques. These techniques not only diminish time complexity but also address the bias in gradient computation through an unbiased optimization process. UIO-LLMs successfully handle long context, such as extending the context window of Llama2-7b-chat from 4K to 100K tokens with minimal 2% additional parameters, while keeping the inference cost nearly linear as context length increases.

**Link**: [arxiv](http://arxiv.org/abs/2406.18173v3),  [pdf](http://arxiv.org/pdf/2406.18173v3)

**Tags**: cs.CL 



### GARD: Gamma-based Anatomical Restoration and Denoising for Retinal OCT
**Authors**: Botond Fazekas, Thomas Pinetz, Guilherme Aresta, Taha Emre, Hrvoje Bogunovic

**Updated**: 2025-09-12T15:24:41Z

**Summary**: Optical Coherence Tomography (OCT) is a vital imaging modality for diagnosing and monitoring retinal diseases. However, OCT images are inherently degraded by speckle noise, which obscures fine details and hinders accurate interpretation. While numerous denoising methods exist, many struggle to balance noise reduction with the preservation of crucial anatomical structures. This paper introduces GARD (Gamma-based Anatomical Restoration and Denoising), a novel deep learning approach for OCT image despeckling that leverages the strengths of diffusion probabilistic models. Unlike conventional diffusion models that assume Gaussian noise, GARD employs a Denoising Diffusion Gamma Model to more accurately reflect the statistical properties of speckle. Furthermore, we introduce a Noise-Reduced Fidelity Term that utilizes a pre-processed, less-noisy image to guide the denoising process. This crucial addition prevents the reintroduction of high-frequency noise. We accelerate the inference process by adapting the Denoising Diffusion Implicit Model framework to our Gamma-based model. Experiments on a dataset with paired noisy and less-noisy OCT B-scans demonstrate that GARD significantly outperforms traditional denoising methods and state-of-the-art deep learning models in terms of PSNR, SSIM, and MSE. Qualitative results confirm that GARD produces sharper edges and better preserves fine anatomical details.

**Link**: [arxiv](http://arxiv.org/abs/2509.10341v1),  [pdf](http://arxiv.org/pdf/2509.10341v1)

**Tags**: cs.CV 



### I-Segmenter: Integer-Only Vision Transformer for Efficient Semantic   Segmentation
**Authors**: Jordan Sassoon, Michal Szczepanski, Martyna Poreba

**Updated**: 2025-09-12T15:14:19Z

**Summary**: Vision Transformers (ViTs) have recently achieved strong results in semantic segmentation, yet their deployment on resource-constrained devices remains limited due to their high memory footprint and computational cost. Quantization offers an effective strategy to improve efficiency, but ViT-based segmentation models are notoriously fragile under low precision, as quantization errors accumulate across deep encoder-decoder pipelines. We introduce I-Segmenter, the first fully integer-only ViT segmentation framework. Building on the Segmenter architecture, I-Segmenter systematically replaces floating-point operations with integer-only counterparts. To further stabilize both training and inference, we propose $\lambda$-ShiftGELU, a novel activation function that mitigates the limitations of uniform quantization in handling long-tailed activation distributions. In addition, we remove the L2 normalization layer and replace bilinear interpolation in the decoder with nearest neighbor upsampling, ensuring integer-only execution throughout the computational graph. Extensive experiments show that I-Segmenter achieves accuracy within a reasonable margin of its FP32 baseline (5.1 % on average), while reducing model size by up to 3.8x and enabling up to 1.2x faster inference with optimized runtimes. Notably, even in one-shot PTQ with a single calibration image, I-Segmenter delivers competitive accuracy, underscoring its practicality for real-world deployment.

**Link**: [arxiv](http://arxiv.org/abs/2509.10334v1),  [pdf](http://arxiv.org/pdf/2509.10334v1)

**Tags**: cs.CV cs.AI cs.LG 



### Revealing Higher-Order Interactions in Complex Networks: A U.S.   Diplomacy Case Study
**Authors**: Arthur Rondeau, Didier Wernli, Roland Bouffanais

**Updated**: 2025-09-12T15:13:12Z

**Summary**: Although diplomatic communication has long been examined in the social sciences, its network structure remains underexplored. Using the U.S. diplomatic cables released by WikiLeaks in 2010 as a case study, we adopt a network-science perspective. We represent diplomatic interactions as a hypergraph and develop a general, random-walk-based pipeline to evaluate this representation against traditional pairwise graphs. We further evaluate the pipeline on legislative co-sponsorship and organizational email data, finding improvements and empirical evidence that clarifies when hypergraph modeling is preferable to pairwise graphs. Overall, hypergraphs paired with appropriately specified random-walk dynamics more faithfully capture higher-order, group-based interactions, yielding a richer structural account of diplomacy and superior performance on interaction-prediction tasks that enables inferring new diplomatic relationships from existing patterns.

**Link**: [arxiv](http://arxiv.org/abs/2509.10333v1),  [pdf](http://arxiv.org/pdf/2509.10333v1)

**Tags**: cs.SI 



### AdaFusion: Prompt-Guided Inference with Adaptive Fusion of Pathology   Foundation Models
**Authors**: Yuxiang Xiao, Yang Hu, Bin Li, Tianyang Zhang, Zexi Li, Huazhu Fu, Jens Rittscher, Kaixiang Yang

**Updated**: 2025-09-12T15:09:41Z

**Summary**: Pathology foundation models (PFMs) have demonstrated strong representational capabilities through self-supervised pre-training on large-scale, unannotated histopathology image datasets. However, their diverse yet opaque pretraining contexts, shaped by both data-related and structural/training factors, introduce latent biases that hinder generalisability and transparency in downstream applications. In this paper, we propose AdaFusion, a novel prompt-guided inference framework that, to our knowledge, is among the very first to dynamically integrate complementary knowledge from multiple PFMs. Our method compresses and aligns tile-level features from diverse models and employs a lightweight attention mechanism to adaptively fuse them based on tissue phenotype context. We evaluate AdaFusion on three real-world benchmarks spanning treatment response prediction, tumour grading, and spatial gene expression inference. Our approach consistently surpasses individual PFMs across both classification and regression tasks, while offering interpretable insights into each model's biosemantic specialisation. These results highlight AdaFusion's ability to bridge heterogeneous PFMs, achieving both enhanced performance and interpretability of model-specific inductive biases.

**Link**: [arxiv](http://arxiv.org/abs/2508.05084v2),  [pdf](http://arxiv.org/pdf/2508.05084v2)

**Tags**: cs.CV 



### Effects of the Strict-Tolerant Approach on Intuitionistic and Minimal   Logic
**Authors**: Victor Barroso-Nascimento, German Mejia

**Updated**: 2025-09-12T15:01:31Z

**Summary**: This paper extends the literature on the strict-tolerant logical approach by applying its methods to intuitionistic and minimal logic. In short, the strict-tolerant approach modifies the usual notion of logical consequence by stipulating that, in order for an inference to be valid, from the truth of the premises must follow the non-falsity of the conclusion. This notion can also be generalized to define strict-tolerant metainferences, metametainferences and so on, which may or may not generate logics distinct from those obtained on the inferential level. It is already known that strict-tolerant definitions can make the notion of inference for non-classical logics collapse into the classical notion, but the strength of this effect is not yet fully known. This paper shows that intuitionistic strict-tolerant inferences also collapse into classical ones, but minimal ones do not. However, minimal strict-tolerant logic has the property that no inferences are valid (which is not carried over to the metainferential level). Additionally, it is shown that the logics obtained from intuitionistic, minimal and classical logic at the metainferential level are distinct from each other.

**Link**: [arxiv](http://arxiv.org/abs/2509.10322v1),  [pdf](http://arxiv.org/pdf/2509.10322v1)

**Tags**: cs.LO 



### Robot guide with multi-agent control and automatic scenario generation   with LLM
**Authors**: Elizaveta D. Moskovskaya, Anton D. Moscowsky

**Updated**: 2025-09-12T14:59:04Z

**Summary**: The work describes the development of a hybrid control architecture for an anthropomorphic tour guide robot, combining a multi-agent resource management system with automatic behavior scenario generation based on large language models. The proposed approach aims to overcome the limitations of traditional systems, which rely on manual tuning of behavior scenarios. These limitations include manual configuration, low flexibility, and lack of naturalness in robot behavior. The process of preparing tour scenarios is implemented through a two-stage generation: first, a stylized narrative is created, then non-verbal action tags are integrated into the text. The multi-agent system ensures coordination and conflict resolution during the execution of parallel actions, as well as maintaining default behavior after the completion of main operations, contributing to more natural robot behavior. The results obtained from the trial demonstrate the potential of the proposed approach for automating and scaling social robot control systems.

**Link**: [arxiv](http://arxiv.org/abs/2509.10317v1),  [pdf](http://arxiv.org/pdf/2509.10317v1)

**Tags**: cs.RO cs.LG 93C85 I.2.9; I.2.7; I.2.11 



### A Modern Theory of Cross-Validation through the Lens of Stability
**Authors**: Jing Lei

**Updated**: 2025-09-12T14:58:31Z

**Summary**: Modern data analysis and statistical learning are marked by complex data structures and black-box algorithms. Data complexity stems from technologies like imaging, remote sensing, wearables, and genomic sequencing. Simultaneously, black-box models -- especially deep neural networks -- have achieved impressive results. This combination raises new challenges for uncertainty quantification and statistical inference, which we term "black-box inference."   Black-box inference is difficult due to the lack of traditional modeling assumptions and the opaque behavior of modern estimators. These make it hard to characterize the distribution of estimation errors. A popular solution is post-hoc randomization, which, under mild assumptions like exchangeability, can yield valid uncertainty quantification. Such methods range from classical techniques like permutation tests, jackknife, and bootstrap, to recent innovations like conformal inference. These approaches typically need little knowledge of data distributions or the internal working of estimators. Many rely on the idea that estimators behave similarly under small data changes -- a concept formalized as stability. Over time, stability has become a key principle in data science, influencing generalization error, privacy, and adaptive inference.   This article investigates cross-validation (CV) -- a widely used resampling method -- through the lens of stability. We first review recent theoretical results on CV for estimating generalization error and model selection under stability. We then examine uncertainty quantification for CV-based risk estimates. Together, these insights yield new theory and tools, which we apply to topics like model selection, selective inference, and conformal prediction.

**Link**: [arxiv](http://arxiv.org/abs/2505.23592v2),  [pdf](http://arxiv.org/pdf/2505.23592v2)

**Tags**: math.ST stat.TH 



### A Stochastic Birth-and-Death Approach for Street Furniture Geolocation   in Urban Environments
**Authors**: Evan Murphy, Marco Viola, Vladimir A. Krylov

**Updated**: 2025-09-12T14:52:42Z

**Summary**: In this paper we address the problem of precise geolocation of street furniture in complex urban environments, which is a critical task for effective monitoring and maintenance of public infrastructure by local authorities and private stakeholders. To this end, we propose a probabilistic framework based on energy maps that encode the spatial likelihood of object locations. Representing the energy in a map-based geopositioned format allows the optimisation process to seamlessly integrate external geospatial information, such as GIS layers, road maps, or placement constraints, which improves contextual awareness and localisation accuracy. A stochastic birth-and-death optimisation algorithm is introduced to infer the most probable configuration of assets. We evaluate our approach using a realistic simulation informed by a geolocated dataset of street lighting infrastructure in Dublin city centre, demonstrating its potential for scalable and accurate urban asset mapping. The implementation of the algorithm will be made available in the GitHub repository https://github.com/EMurphy0108/SBD_Street_Furniture.

**Link**: [arxiv](http://arxiv.org/abs/2509.10310v1),  [pdf](http://arxiv.org/pdf/2509.10310v1)

**Tags**: cs.CV 



### GraphCSVAE: Graph Categorical Structured Variational Autoencoder for   Spatiotemporal Auditing of Physical Vulnerability Towards Sustainable   Post-Disaster Risk Reduction
**Authors**: Joshua Dimasaka, Christian Geiß, Robert Muir-Wood, Emily So

**Updated**: 2025-09-12T14:50:56Z

**Summary**: In the aftermath of disasters, many institutions worldwide face challenges in continually monitoring changes in disaster risk, limiting the ability of key decision-makers to assess progress towards the UN Sendai Framework for Disaster Risk Reduction 2015-2030. While numerous efforts have substantially advanced the large-scale modeling of hazard and exposure through Earth observation and data-driven methods, progress remains limited in modeling another equally important yet challenging element of the risk equation: physical vulnerability. To address this gap, we introduce Graph Categorical Structured Variational Autoencoder (GraphCSVAE), a novel probabilistic data-driven framework for modeling physical vulnerability by integrating deep learning, graph representation, and categorical probabilistic inference, using time-series satellite-derived datasets and prior expert belief systems. We introduce a weakly supervised first-order transition matrix that reflects the changes in the spatiotemporal distribution of physical vulnerability in two disaster-stricken and socioeconomically disadvantaged areas: (1) the cyclone-impacted coastal Khurushkul community in Bangladesh and (2) the mudslide-affected city of Freetown in Sierra Leone. Our work reveals post-disaster regional dynamics in physical vulnerability, offering valuable insights into localized spatiotemporal auditing and sustainable strategies for post-disaster risk reduction.

**Link**: [arxiv](http://arxiv.org/abs/2509.10308v1),  [pdf](http://arxiv.org/pdf/2509.10308v1)

**Tags**: cs.LG 



### Cognitive Effort in the Two-Step Task: An Active Inference   Drift-Diffusion Model Approach
**Authors**: Alvaro Garrido Perez, Viktor Lemoine, Amrapali Pednekar, Yara Khaluf, Pieter Simoens

**Updated**: 2025-09-12T14:42:50Z

**Summary**: High-level theories rooted in the Bayesian Brain Hypothesis often frame cognitive effort as the cost of resolving the conflict between habits and optimal policies. In parallel, evidence accumulator models (EAMs) provide a mechanistic account of how effort arises from competition between the subjective values of available options. Although EAMs have been combined with frameworks like Reinforcement Learning to bridge the gap between high-level theories and process-level mechanisms, relatively less attention has been paid to their implications for a unified notion of cognitive effort. Here, we combine Active Inference (AIF) with the Drift-Diffusion Model (DDM) to investigate whether the resulting AIF-DDM can simultaneously account for effort arising from both habit violation and value discriminability. To our knowledge, this is the first time AIF has been combined with an EAM. We tested the AIF-DDM on a behavioral dataset from the two-step task and compared its predictions to an information-theoretic definition of cognitive effort based on AIF. The model's predictions successfully accounted for second-stage reaction times but failed to capture the dynamics of the first stage. We argue the latter discrepancy likely stems from the experimental design rather than a fundamental flaw in the model's assumptions about cognitive effort. Accordingly, we propose several modifications of the two-step task to better measure and isolate cognitive effort. Finally, we found that integrating the DDM significantly improved parameter recovery, which could help future studies to obtain more reliable parameter estimates.

**Link**: [arxiv](http://arxiv.org/abs/2508.04435v2),  [pdf](http://arxiv.org/pdf/2508.04435v2)

**Tags**: q-bio.NC 



### Toward Open Earth Science as Fast and Accessible as Natural Language
**Authors**: Marquita Ellis, Iksha Gurung, Muthukumaran Ramasubramanian, Rahul Ramachandran

**Updated**: 2025-09-12T14:40:08Z

**Summary**: Is natural-language-driven earth observation data analysis now feasible with the assistance of Large Language Models (LLMs)? For open science in service of public interest, feasibility requires reliably high accuracy, interactive latencies, low (sustainable) costs, open LLMs, and openly maintainable software -- hence, the challenge. What are the techniques and programming system requirements necessary for satisfying these constraints, and what is the corresponding development and maintenance burden in practice? This study lays the groundwork for exploring these questions, introducing an impactful earth science use-case, and providing a software framework with evaluation data and metrics, along with initial results from employing model scaling, prompt-optimization, and inference-time scaling optimization techniques. While we attain high accuracy (near 100%) across 10 of 11 metrics, the analysis further considers cost (token-spend), latency, and maintainability across this space of techniques. Finally, we enumerate opportunities for further research, general programming and evaluation framework development, and ongoing work for a comprehensive, deployable solution. This is a call for collaboration and contribution.

**Link**: [arxiv](http://arxiv.org/abs/2505.15690v2),  [pdf](http://arxiv.org/pdf/2505.15690v2)

**Tags**: cs.CE J.2; H.5.2; H.3.3 



### The Morality of Probability: How Implicit Moral Biases in LLMs May Shape   the Future of Human-AI Symbiosis
**Authors**: Eoin O'Doherty, Nicole Weinrauch, Andrew Talone, Uri Klempner, Xiaoyuan Yi, Xing Xie, Yi Zeng

**Updated**: 2025-09-12T14:37:57Z

**Summary**: Artificial intelligence (AI) is advancing at a pace that raises urgent questions about how to align machine decision-making with human moral values. This working paper investigates how leading AI systems prioritize moral outcomes and what this reveals about the prospects for human-AI symbiosis. We address two central questions: (1) What moral values do state-of-the-art large language models (LLMs) implicitly favour when confronted with dilemmas? (2) How do differences in model architecture, cultural origin, and explainability affect these moral preferences? To explore these questions, we conduct a quantitative experiment with six LLMs, ranking and scoring outcomes across 18 dilemmas representing five moral frameworks. Our findings uncover strikingly consistent value biases. Across all models, Care and Virtue values outcomes were rated most moral, while libertarian choices were consistently penalized. Reasoning-enabled models exhibited greater sensitivity to context and provided richer explanations, whereas non-reasoning models produced more uniform but opaque judgments. This research makes three contributions: (i) Empirically, it delivers a large-scale comparison of moral reasoning across culturally distinct LLMs; (ii) Theoretically, it links probabilistic model behaviour with underlying value encodings; (iii) Practically, it highlights the need for explainability and cultural awareness as critical design principles to guide AI toward a transparent, aligned, and symbiotic future.

**Link**: [arxiv](http://arxiv.org/abs/2509.10297v1),  [pdf](http://arxiv.org/pdf/2509.10297v1)

**Tags**: cs.AI 



### Comparing Apples to Oranges: A Dataset & Analysis of LLM Humour   Understanding from Traditional Puns to Topical Jokes
**Authors**: Tyler Loakman, William Thorne, Chenghua Lin

**Updated**: 2025-09-12T14:23:05Z

**Summary**: Humour, as a complex language form, is derived from myriad aspects of life. Whilst existing work on computational humour has focussed almost exclusively on short pun-based jokes, we investigate whether the ability of Large Language Models (LLMs) to explain humour depends on the particular form. We compare models' joke explanation abilities from simple puns to complex topical humour that requires esoteric knowledge of real-world entities and events. To this end, we curate a dataset of 600 jokes across 4 joke types and manually write high-quality explanations. These jokes include heterographic and homographic puns, contemporary internet humour, and topical jokes. Using this dataset, we compare the zero-shot abilities of a range of LLMs to accurately and comprehensively explain jokes of different types, identifying key research gaps in the task of humour explanation. We find that none of the tested models (including reasoning models) are capable of reliably generating adequate explanations of all joke types, further highlighting the narrow focus of most existing works on overly simple joke forms.

**Link**: [arxiv](http://arxiv.org/abs/2507.13335v2),  [pdf](http://arxiv.org/pdf/2507.13335v2)

**Tags**: cs.CL 



### TORSO: Template-Oriented Reasoning Towards General Tasks
**Authors**: Minhyuk Kim, Seungyoon Lee, Heuiseok Lim

**Updated**: 2025-09-12T14:00:08Z

**Summary**: The approaches that guide Large Language Models (LLMs) to emulate human reasoning during response generation have emerged as an effective method for enabling them to solve complex problems in a step-by-step manner, thereby achieving superior performance. However, most existing approaches using few-shot prompts to generate responses heavily depend on the provided examples, limiting the utilization of the model's inherent reasoning capabilities. Moreover, constructing task-specific few-shot prompts is often costly and may lead to inconsistencies across different tasks. In this work, we introduce Template-Oriented Reasoning (TORSO), which elicits the model to utilize internal reasoning abilities to generate proper responses across various tasks without the need for manually crafted few-shot examples. Our experimental results demonstrate that TORSO achieves strong performance on diverse LLMs benchmarks with reasonable rationales.

**Link**: [arxiv](http://arxiv.org/abs/2509.09448v2),  [pdf](http://arxiv.org/pdf/2509.09448v2)

**Tags**: cs.AI 



### Multi-Turn Human-LLM Interaction Through the Lens of a Two-Way   Intelligibility Protocol
**Authors**: Harshvardhan Mestha, Karan Bania, Shreyas V, Sidong Liu, Ashwin Srinivasan

**Updated**: 2025-09-12T13:52:45Z

**Summary**: Our interest is in the design of software systems involving a human-expert interacting -- using natural language -- with a large language model (LLM) on data analysis tasks. For complex problems, it is possible that LLMs can harness human expertise and creativity to find solutions that were otherwise elusive. On one level, this interaction takes place through multiple turns of prompts from the human and responses from the LLM. Here we investigate a more structured approach based on an abstract protocol described in [3] for interaction between agents. The protocol is motivated by a notion of "two-way intelligibility" and is modelled by a pair of communicating finite-state machines. We provide an implementation of the protocol, and provide empirical evidence of using the implementation to mediate interactions between an LLM and a human-agent in two areas of scientific interest (radiology and drug design). We conduct controlled experiments with a human proxy (a database), and uncontrolled experiments with human subjects. The results provide evidence in support of the protocol's capability of capturing one- and two-way intelligibility in human-LLM interaction; and for the utility of two-way intelligibility in the design of human-machine systems.

**Link**: [arxiv](http://arxiv.org/abs/2410.20600v2),  [pdf](http://arxiv.org/pdf/2410.20600v2)

**Tags**: cs.AI cs.HC cs.LG cs.MA 



### The Impact of Spectroscopic Redshift Errors on Cosmological Measurements
**Authors**: Shengyu He, Jiaxi Yu, Antoine Rocher, Daniel Forero-Sánchez, Jean-Paul Kneib, Cheng Zhao, Etienne Burtin, Jiamin Hou

**Updated**: 2025-09-12T13:52:21Z

**Summary**: Spectroscopic redshift errors, including redshift uncertainty and catastrophic failures, can bias cosmological measurements from galaxy redshift surveys at sub-percent level. In this work, we investigate their impact on full-shape clustering analysis using contaminated mock catalogs. We find that redshift uncertainty introduces a scale-dependent damping effect on the power spectrum, which is absorbed by counterterms in clustering model, keeping parameter biases below $5\%$. Catastrophic failures suppress the power spectrum amplitude by an approximately constant factor that scales with the catastrophic rate~$f_c$. While this effect is negligible for DESI galaxy populations ($f_c=1\%$), the slitless-like errors, combining redshift uncertainty with $f_c=5\%$ catastrophics, introduce significant biases in cosmological constraints. In this case, we observe $6\%$ to $16\%$ shifts ($\sim2.2\sigma$ level) in estimating the fractional growth rate $df\equiv f/f^{\rm{fid}}$ and the log primordial amplitude $\ln(10^{10} A_{s})$. Applying a correction factor $(1-f_c)^2$ on the galaxy power spectrum mitigates the bias but weakens the parameter constraints due to new degeneracies. Alternatively, fixing $f_c$ to its expected value during fitting successfully restores the unbiased posterior without loss of constraint. Our results indicate that for space-based slitless surveys such as \textit{Euclid}, at minimum accurate estimation of $f_c$ and its incorporation into the clustering model are essential to get unbiased cosmological inference. Extending to evolving dark energy and massive neutrino cosmologies, redshift errors do not bias the dark energy properties parametrized by $w_0$ and $w_a$, but can degrade constraints on the summed neutrino mass $\sum m_\nu$ by up to $80\%$ in the worst case.

**Link**: [arxiv](http://arxiv.org/abs/2508.21182v2),  [pdf](http://arxiv.org/pdf/2508.21182v2)

**Tags**: astro-ph.CO 



### Prompt Injection Attacks on LLM Generated Reviews of Scientific   Publications
**Authors**: Janis Keuper

**Updated**: 2025-09-12T13:45:24Z

**Summary**: The ongoing intense discussion on rising LLM usage in the scientific peer-review process has recently been mingled by reports of authors using hidden prompt injections to manipulate review scores. Since the existence of such "attacks" - although seen by some commentators as "self-defense" - would have a great impact on the further debate, this paper investigates the practicability and technical success of the described manipulations. Our systematic evaluation uses 1k reviews of 2024 ICLR papers generated by a wide range of LLMs shows two distinct results: I) very simple prompt injections are indeed highly effective, reaching up to 100% acceptance scores. II) LLM reviews are generally biased toward acceptance (>95% in many models). Both results have great impact on the ongoing discussions on LLM usage in peer-review.

**Link**: [arxiv](http://arxiv.org/abs/2509.10248v1),  [pdf](http://arxiv.org/pdf/2509.10248v1)

**Tags**: cs.LG 



### Compartmentalised Agentic Reasoning for Clinical NLI
**Authors**: Maël Jullien, Lei Xu, Marco Valentino, André Freitas

**Updated**: 2025-09-12T13:14:47Z

**Summary**: A common assumption holds that scaling data and parameters yields increasingly structured, generalisable internal representations. We interrogate this assumption in clinical natural language inference (NLI) by adopting a benchmark decomposed into four reasoning families, Causal Attribution, Compositional Grounding, Epistemic Verification, and Risk State Abstraction, and introducing CARENLI, a Compartmentalised Agentic Reasoning for Clinical NLI that separates knowledge access from principled inference. CARENLI routes each premise, statement pair to a family specific solver and enforces auditable procedures via a planner, verifier, and refiner.   Across four LLMs, CARENLI improves fidelity by up to 42 points, reaching 98.0% in Causal Attribution and 81.2% in Risk State Abstraction. Verifiers flag violations with near-ceiling reliability, while refiners correct a substantial share of epistemic errors. Remaining failures cluster in routing, identifying family classification as the main bottleneck. These results show that LLMs often retain relevant facts but default to heuristics when inference is underspecified, a dissociation CARENLI makes explicit while offering a framework for safer, auditable reasoning.

**Link**: [arxiv](http://arxiv.org/abs/2509.10222v1),  [pdf](http://arxiv.org/pdf/2509.10222v1)

**Tags**: cs.AI 



### Further evidence for natal kick segregation by spectral type in   high-mass X-ray binaries
**Authors**: Pornisara Nuchvanichakul, Poshak Gandhi, Christian Knigge, Yue Zhao, Puji Irawati, Suwicha Wanawichian, Cordelia Dashwood Brown

**Updated**: 2025-09-12T13:12:42Z

**Summary**: High-mass X-ray binaries (HMXBs) are systems in which a neutron star or black hole accretes material from a massive companion. HMXBs are expected to have experienced a supernova in their evolution. The impulsive kick associated with this event should affect the space velocity of the system in a way that depends on the nature and state of the progenitor binary. Here, we test whether the different evolutionary histories of HMXBs have left a detectable imprint on their peculiar velocities ($V_{\rm pec}$). Using data from Gaia Data Release 3 (Gaia DR3), we first calculate the $V_{\rm pec}$ values for 63 well-known HMXBs hosting a black hole or neutron star and estimate the associated uncertainties via Monte Carlo re-sampling. We then analyse their distribution and check for differences between classes. Overall, $V_{\rm pec}$ estimates extend up to 100 km s$^{-1}$, but with Be/X-ray binaries (BeXRBs) favouring $V_{\rm pec}$ $\lesssim 40$ km s$^{-1}$ and supergiant X-ray binaries (SgXRBs) favouring $V_{\rm pec}$ $\gtrsim 40$ km s$^{-1}$. Based on a Kolmogorov-Smirnov (K-S) test, the null hypothesis that the peculiar velocities of both classes are drawn from the same parent distribution can be robustly rejected, irrespective of the background stellar velocity dispersion. Tests with binary population synthesis demonstrate that SgXRBs typically have shorter orbital periods and higher fractional mass loss than BeXRBs at supernova. We argue that the magnitude of $V_{\rm pec}$ could be used as a complementary feature to distinguish between Be and supergiant systems. These findings extend previous inferences based on two-dimensional kinematics from Hipparcos, and may be explained by the differing nature of the respective progenitors systems between the source classes at the instant of supernova.

**Link**: [arxiv](http://arxiv.org/abs/2509.10221v1),  [pdf](http://arxiv.org/pdf/2509.10221v1)

**Tags**: astro-ph.HE 



### MachineLearningLM: Scaling Many-shot In-context Learning via Continued   Pretraining
**Authors**: Haoyu Dong, Pengkun Zhang, Mingzhe Lu, Yanzhen Shen, Guolin Ke

**Updated**: 2025-09-12T13:11:51Z

**Summary**: Large language models (LLMs) possess broad world knowledge and strong general-purpose reasoning ability, yet they struggle to learn from many in-context examples on standard machine learning (ML) tasks, that is, to leverage many-shot demonstrations purely via in-context learning (ICL) without gradient descent. We introduce MachineLearningLM, a portable continued-pretraining framework that equips a general-purpose LLM with robust in-context ML capability while preserving its general knowledge and reasoning for broader chat workflows.   Our pretraining procedure synthesizes ML tasks from millions of structural causal models (SCMs), spanning shot counts up to 1,024. We begin with a random-forest teacher, distilling tree-based decision strategies into the LLM to strengthen robustness in numerical modeling. All tasks are serialized with a token-efficient prompt, enabling 3x to 6x more examples per context window and delivering up to 50x amortized throughput via batch inference.   Despite a modest setup (Qwen-2.5-7B-Instruct with LoRA rank 8), MachineLearningLM outperforms strong LLM baselines (e.g., GPT-5-mini) by an average of about 15% on out-of-distribution tabular classification across finance, physics, biology, and healthcare domains. It exhibits a striking many-shot scaling law: accuracy increases monotonically as in-context demonstrations grow from 8 to 1,024. Without any task-specific training, it attains random-forest-level accuracy across hundreds of shots. General chat capabilities, including knowledge and reasoning, are preserved: it achieves 75.4% on MMLU.

**Link**: [arxiv](http://arxiv.org/abs/2509.06806v4),  [pdf](http://arxiv.org/pdf/2509.06806v4)

**Tags**: cs.CL cs.AI 



### RFSeek and Ye Shall Find
**Authors**: Noga H. Rotman, Tiago Ferreira, Hila Peleg, Mark Silberstein, Alexandra Silva

**Updated**: 2025-09-12T13:08:50Z

**Summary**: Requests for Comments (RFCs) are extensive specification documents for network protocols, but their prose-based format and their considerable length often impede precise operational understanding. We present RFSeek, an interactive tool that automatically extracts visual summaries of protocol logic from RFCs. RFSeek leverages large language models (LLMs) to generate provenance-linked, explorable diagrams, surfacing both official state machines and additional logic found only in the RFC text. Compared to existing RFC visualizations, RFSeek's visual summaries are more transparent and easier to audit against their textual source. We showcase the tool's potential through a series of use cases, including guided knowledge extraction and semantic diffing, applied to protocols such as TCP, QUIC, PPTP, and DCCP.   In practice, RFSeek not only reconstructs the RFC diagrams included in some specifications, but, more interestingly, also uncovers important logic such as nodes or edges described in the text but missing from those diagrams. RFSeek further derives new visualization diagrams for complex RFCs, with QUIC as a representative case. Our approach, which we term \emph{Summary Visualization}, highlights a promising direction: combining LLMs with formal, user-customized visualizations to enhance protocol comprehension and support robust implementations.

**Link**: [arxiv](http://arxiv.org/abs/2509.10216v1),  [pdf](http://arxiv.org/pdf/2509.10216v1)

**Tags**: cs.NI cs.HC cs.LG 



### Towards Fully Automated Molecular Simulations: Multi-Agent Framework for   Simulation Setup and Force Field Extraction
**Authors**: Marko Petković, Vlado Menkovski, Sofía Calero

**Updated**: 2025-09-12T12:56:47Z

**Summary**: Automated characterization of porous materials has the potential to accelerate materials discovery, but it remains limited by the complexity of simulation setup and force field selection. We propose a multi-agent framework in which LLM-based agents can autonomously understand a characterization task, plan appropriate simulations, assemble relevant force fields, execute them and interpret their results to guide subsequent steps. As a first step toward this vision, we present a multi-agent system for literature-informed force field extraction and automated RASPA simulation setup. Initial evaluations demonstrate high correctness and reproducibility, highlighting this approach's potential to enable fully autonomous, scalable materials characterization.

**Link**: [arxiv](http://arxiv.org/abs/2509.10210v1),  [pdf](http://arxiv.org/pdf/2509.10210v1)

**Tags**: cs.AI cs.MA 



### SI-FACT: Mitigating Knowledge Conflict via Self-Improving   Faithfulness-Aware Contrastive Tuning
**Authors**: Shengqiang Fu

**Updated**: 2025-09-12T12:56:14Z

**Summary**: Large Language Models often generate unfaithful responses in knowledge intensive tasks due to knowledge conflict,that is,a preference for relying on internal parametric knowledge rather than the provided context.To address this issue,we propose a novel self improving framework,Self Improving Faithfulness Aware Contrastive Tuning.The framework uses a self instruct mechanism that allows the base LLM to automatically generate high quality,structured contrastive learning data,including anchor samples,semantically equivalent positive samples,and negative samples simulating unfaithful scenarios.This approach significantly reduces the cost of manual annotation.Subsequently,contrastive learning is applied to train the model,enabling it to pull faithful responses closer and push unfaithful responses farther apart in the representation space.Experiments on knowledge conflict evaluation benchmarks ECARE KRE and COSE KRE show that the SI FACT model based on Llama3 8B Instruct improves the Contextual Recall Rate by 6.2% over the best baseline method,while significantly reducing dependence on internal memory.The results indicate that SI FACT provides strong effectiveness and high data efficiency in enhancing the contextual faithfulness of LLMs,offering a practical pathway toward building more proactive and trustworthy language models.

**Link**: [arxiv](http://arxiv.org/abs/2509.10208v1),  [pdf](http://arxiv.org/pdf/2509.10208v1)

**Tags**: cs.CL cs.AI 



### Steering Protein Language Models
**Authors**: Long-Kai Huang, Rongyi Zhu, Bing He, Jianhua Yao

**Updated**: 2025-09-12T12:39:45Z

**Summary**: Protein Language Models (PLMs), pre-trained on extensive evolutionary data from natural proteins, have emerged as indispensable tools for protein design. While powerful, PLMs often struggle to produce proteins with precisely specified functionalities or properties due to inherent challenges in controlling their outputs. In this work, we investigate the potential of Activation Steering, a technique originally developed for controlling text generation in Large Language Models (LLMs), to direct PLMs toward generating protein sequences with targeted properties. We propose a simple yet effective method that employs activation editing to steer PLM outputs, and extend this approach to protein optimization through a novel editing site identification module. Through comprehensive experiments on lysozyme-like sequence generation and optimization, we demonstrate that our methods can be seamlessly integrated into both auto-encoding and autoregressive PLMs without requiring additional training. These results highlight a promising direction for precise protein engineering using foundation models.

**Link**: [arxiv](http://arxiv.org/abs/2509.07983v2),  [pdf](http://arxiv.org/pdf/2509.07983v2)

**Tags**: q-bio.BM cs.LG 



### Incongruent Positivity: When Miscalibrated Positivity Undermines Online   Supportive Conversations
**Authors**: Leen Almajed, Abeer ALdayel

**Updated**: 2025-09-12T12:25:02Z

**Summary**: In emotionally supportive conversations, well-intended positivity can sometimes misfire, leading to responses that feel dismissive, minimizing, or unrealistically optimistic. We examine this phenomenon of incongruent positivity as miscalibrated expressions of positive support in both human and LLM generated responses. To this end, we collected real user-assistant dialogues from Reddit across a range of emotional intensities and generated additional responses using large language models for the same context. We categorize these conversations by intensity into two levels: Mild, which covers relationship tension and general advice, and Severe, which covers grief and anxiety conversations. This level of categorization enables a comparative analysis of how supportive responses vary across lower and higher stakes contexts. Our analysis reveals that LLMs are more prone to unrealistic positivity through dismissive and minimizing tone, particularly in high-stakes contexts. To further study the underlying dimensions of this phenomenon, we finetune LLMs on datasets with strong and weak emotional reactions. Moreover, we developed a weakly supervised multilabel classifier ensemble (DeBERTa and MentalBERT) that shows improved detection of incongruent positivity types across two sorts of concerns (Mild and Severe). Our findings shed light on the need to move beyond merely generating generic positive responses and instead study the congruent support measures to balance positive affect with emotional acknowledgment. This approach offers insights into aligning large language models with affective expectations in the online supportive dialogue, paving the way toward context-aware and trust preserving online conversation systems.

**Link**: [arxiv](http://arxiv.org/abs/2509.10184v1),  [pdf](http://arxiv.org/pdf/2509.10184v1)

**Tags**: cs.CL 



### Zero-inflation in the Multivariate Poisson Lognormal Family
**Authors**: Bastien Batardière, Julien Chiquet, François Gindraud, Mahendra Mariadassou

**Updated**: 2025-09-12T12:17:25Z

**Summary**: Analyzing high-dimensional count data is a challenge and statistical model-based approaches provide an adequate and efficient framework that preserves explainability. The (multivariate) Poisson-Log-Normal (PLN) model is one such model: it assumes count data are driven by an underlying structured latent Gaussian variable, so that the dependencies between counts solely stems from the latent dependencies. However PLN doesn't account for zero-inflation, a feature frequently observed in real-world datasets. Here we introduce the Zero-Inflated PLN (ZIPLN) model, adding a multivariate zero-inflated component to the model, as an additional Bernoulli latent variable. The Zero-Inflation can be fixed, site-specific, feature-specific or depends on covariates. We estimate model parameters using variational inference that scales up to datasets with a few thousands variables and compare two approximations: (i) independent Gaussian and Bernoulli variational distributions or (ii) Gaussian variational distribution conditioned on the Bernoulli one. The method is assessed on synthetic data and the efficiency of ZIPLN is established even when zero-inflation concerns up to 90% of the observed counts. We then apply both ZIPLN and PLN to a cow microbiome dataset, containing 90.6% of zeroes. Accounting for zero-inflation significantly increases log-likelihood and reduces dispersion in the latent space, thus leading to improved group discrimination.

**Link**: [arxiv](http://arxiv.org/abs/2405.14711v2),  [pdf](http://arxiv.org/pdf/2405.14711v2)

**Tags**: stat.ME stat.AP stat.ML 



### Benchmark of stylistic variation in LLM-generated texts
**Authors**: Jiří Milička, Anna Marklová, Václav Cvrček

**Updated**: 2025-09-12T12:12:20Z

**Summary**: This study investigates the register variation in texts written by humans and comparable texts produced by large language models (LLMs). Biber's multidimensional analysis (MDA) is applied to a sample of human-written texts and AI-created texts generated to be their counterparts to find the dimensions of variation in which LLMs differ most significantly and most systematically from humans. As textual material, a new LLM-generated corpus AI-Brown is used, which is comparable to BE-21 (a Brown family corpus representing contemporary British English). Since all languages except English are underrepresented in the training data of frontier LLMs, similar analysis is replicated on Czech using AI-Koditex corpus and Czech multidimensional model. Examined were 16 frontier models in various settings and prompts, with emphasis placed on the difference between base models and instruction-tuned models. Based on this, a benchmark is created through which models can be compared with each other and ranked in interpretable dimensions.

**Link**: [arxiv](http://arxiv.org/abs/2509.10179v1),  [pdf](http://arxiv.org/pdf/2509.10179v1)

**Tags**: cs.CL cs.AI 



### A 2-step Framework for Automated Literary Translation Evaluation: Its   Promises and Pitfalls
**Authors**: Sheikh Shafayat, Dongkeun Yoon, Woori Jang, Jiwoo Choi, Alice Oh, Seohyon Jung

**Updated**: 2025-09-12T12:10:06Z

**Summary**: In this work, we propose and evaluate the feasibility of a two-stage pipeline to evaluate literary machine translation, in a fine-grained manner, from English to Korean. The results show that our framework provides fine-grained, interpretable metrics suited for literary translation and obtains a higher correlation with human judgment than traditional machine translation metrics. Nonetheless, it still fails to match inter-human agreement, especially in metrics like Korean Honorifics. We also observe that LLMs tend to favor translations generated by other LLMs, and we highlight the necessity of developing more sophisticated evaluation methods to ensure accurate and culturally sensitive machine translation of literary works.

**Link**: [arxiv](http://arxiv.org/abs/2412.01340v3),  [pdf](http://arxiv.org/pdf/2412.01340v3)

**Tags**: cs.CL 



### QuantX: A Framework for Hardware-Aware Quantization of Generative AI   Workloads
**Authors**: Muhammad Ahmad, Khurram Mazher, Saqib Akram, Ahmad Tameem, Saad Bin Nasir

**Updated**: 2025-09-12T12:03:22Z

**Summary**: We present QuantX: a tailored suite of recipes for LLM and VLM quantization. It is capable of quantizing down to 3-bit resolutions with minimal loss in performance. The quantization strategies in QuantX take into account hardware-specific constraints to achieve efficient dequantization during inference ensuring flexible trade-off between runtime speed, memory requirement and model accuracy. Our results demonstrate that QuantX achieves performance within 6% of the unquantized model for LlaVa-v1.6 quantized down to 3-bits for multiple end user tasks and outperforms recently published state-of-the-art quantization techniques. We further integrate one particular technique from QuantX into the popular Llama.cpp framework and show its feasibility in terms of runtime compared to the mainstream quantization techniques from Llama.cpp. Lastly, this manuscript provides insights into the LLM quantization process that motivated the range of recipes and options that are incorporated in QuantX.

**Link**: [arxiv](http://arxiv.org/abs/2505.07531v2),  [pdf](http://arxiv.org/pdf/2505.07531v2)

**Tags**: cs.AI eess.SP 



### FGIT: Fault-Guided Fine-Tuning for Code Generation
**Authors**: Lishui Fan, Zhongxin Liu, Haoye Wang, Lingfeng Bao, Xin Xia, Shanping Li

**Updated**: 2025-09-12T11:56:27Z

**Summary**: Modern instruction-tuned large language models (LLMs) have made remarkable progress in code generation. However, these LLMs fine-tuned with standard supervised fine-tuning (SFT) sometimes generate plausible-looking but functionally incorrect code variants. This issue likely stems from the limitation of standard SFT, which treats all tokens equally during optimization and fails to emphasize the error-sensitive segments-specific code differences between correct implementations and similar incorrect variants. To address this problem, we propose Fault-Guided Fine-Tuning (FGIT), a novel fine-tuning technique that enhances LLMs' code generation by (1) extracting multi-granularity (line/token-level) differences between correct and incorrect yet similar implementations to identify error-sensitive segments, and (2) dynamically prioritizing those segments during training via dynamic loss weighting. Through extensive experiments on seven LLMs across three widely-used benchmarks, our method achieves an average relative improvement of 6.9% on pass@1 with some enhanced 6.7B LLMs outperforming closed-source models, e.g., GPT-3.5-Turbo. Furthermore, our fine-tuning technique demonstrates strong generalization with performance improvements ranging from 3.8% to 19.1% across diverse instruction-tuned LLMs, and our ablation studies confirm the contributions of different granularities of differences and hyperparameters.

**Link**: [arxiv](http://arxiv.org/abs/2503.16913v2),  [pdf](http://arxiv.org/pdf/2503.16913v2)

**Tags**: cs.SE 



### Diffusion Buffer: Online Diffusion-based Speech Enhancement with   Sub-Second Latency
**Authors**: Bunlong Lay, Rostislav Makarov, Timo Gerkmann

**Updated**: 2025-09-12T11:49:57Z

**Summary**: Diffusion models are a class of generative models that have been recently used for speech enhancement with remarkable success but are computationally expensive at inference time. Therefore, these models are impractical for processing streaming data in real-time. In this work, we adapt a sliding window diffusion framework to the speech enhancement task. Our approach progressively corrupts speech signals through time, assigning more noise to frames close to the present in a buffer. This approach outputs denoised frames with a delay proportional to the chosen buffer size, enabling a trade-off between performance and latency. Empirical results demonstrate that our method outperforms standard diffusion models and runs efficiently on a GPU, achieving an input-output latency in the order of 0.3 to 1 seconds. This marks the first practical diffusion-based solution for online speech enhancement.

**Link**: [arxiv](http://arxiv.org/abs/2506.02908v2),  [pdf](http://arxiv.org/pdf/2506.02908v2)

**Tags**: eess.AS cs.LG 



### Priors from Envisioned Posterior Judgments: A Novel Elicitation Approach   With Application to Bayesian Clinical Trials
**Authors**: Yongdong Ouyang, Janice J Eng, Denghuang Zhan, Hubert Wong, The WnW Research Team

**Updated**: 2025-09-12T11:28:52Z

**Summary**: Background: The uptake of formalized prior elicitation from experts in Bayesian clinical trials has been limited due to challenges such as complex statistical modeling, lack of practical tools, and the cognitive burden placed on experts arising from needing to quantify their uncertainty probabilistically. Existing methods also fail to address prior-posterior coherence, i.e., how do we ensure that the posterior distribution, obtained mathematically from combining the estimated prior with the trial data, reflects the expert's actual posterior beliefs?   Method: In this study, we propose a new elicitation approach that effectuates prior-posterior coherence and reduces cognitive burden. This is achieved by eliciting expert responses, comprising point estimates only, about envisioned posterior judgments under various data outcomes and inferring the prior distribution by minimizing discrepancies between these responses and expected responses derived from the posterior distribution. Via an iterative process, experts receive feedback on the degree of coherency of their responses, and are invited to revise their responses to achieve greater coherency. The feasibility and potential value of this new approach are illustrated through an application to an ongoing trial.   Results: We involved 10 experts from Walk 'n watch trial research team. Experts were presented with 16 hypothetical outcome scenarios to experts and elicit the priors followed by the developed elicitation framework. Following two rounds of elicitation, experts' judgments showed substantial improvement in coherency, demonstrating the practical applicability of the proposed elicitation approach.   Conclusion: The proposed method provides a practical solution to the challenges of formalized prior elicitation in Bayesian clinical trials by addressing prior-posterior coherence and reducing cognitive demands on experts.

**Link**: [arxiv](http://arxiv.org/abs/2409.05271v3),  [pdf](http://arxiv.org/pdf/2409.05271v3)

**Tags**: stat.ME stat.AP 



### Geometry and Perception Guided Gaussians for Multiview-consistent 3D   Generation from a Single Image
**Authors**: Pufan Li, Bi'an Du, Wei Hu

**Updated**: 2025-09-12T11:26:35Z

**Summary**: Generating realistic 3D objects from single-view images requires natural appearance, 3D consistency, and the ability to capture multiple plausible interpretations of unseen regions. Existing approaches often rely on fine-tuning pretrained 2D diffusion models or directly generating 3D information through fast network inference or 3D Gaussian Splatting, but their results generally suffer from poor multiview consistency and lack geometric detail. To tackle these issues, we present a novel method that seamlessly integrates geometry and perception information without requiring additional model training to reconstruct detailed 3D objects from a single image. Specifically, we incorporate geometry and perception priors to initialize the Gaussian branches and guide their parameter optimization. The geometry prior captures the rough 3D shapes, while the perception prior utilizes the 2D pretrained diffusion model to enhance multiview information. Subsequently, we introduce a stable Score Distillation Sampling for fine-grained prior distillation to ensure effective knowledge transfer. The model is further enhanced by a reprojection-based strategy that enforces depth consistency. Experimental results show that we outperform existing methods on novel view synthesis and 3D reconstruction, demonstrating robust and consistent 3D object generation.

**Link**: [arxiv](http://arxiv.org/abs/2506.21152v2),  [pdf](http://arxiv.org/pdf/2506.21152v2)

**Tags**: cs.CV 68 I.4.0 



### Magnetic effects on fundamental modes in rotating neutron stars with a   purely toroidal magnetic field
**Authors**: Anson Ka Long Yip, Tjonnie Guang Feng Li

**Updated**: 2025-09-12T11:25:29Z

**Summary**: Electromagnetic and gravitational-wave signals from neutron stars are shaped by rapid rotation and strong magnetic fields. Determining these properties is essential to interpret such signals, but current measurements are limited: rotation estimates rely on electromagnetic detections and assume uniform rotation, while inferring interior magnetic fields remains ambiguous due to a lack of direct observations. Measuring the excited fundamental modes of neutron stars in gravitational-wave signals offers a promising solution, as these modes encode information about stellar composition, structure, and dynamics. Previous studies have examined the individual effects of rotation and magnetic fields on these modes, identifying magnetic suppression and establishing linear relations for the frequencies of the fundamental $l=0$ quasi-radial mode $f_F$ and $l=2$ quadrupolar mode $f_{^2f}$. However, few have investigated the combined influence of rotation and magnetic fields. Here, for the first time, we consider both rotation and a toroidal magnetic field to construct linear relations for quantifying $f_F$ and $f_{^2f}$, showing that their combined effects can be constrained by detecting these modes. Using 2D axisymmetric simulations, we demonstrate that quasi-linear relations between $f_F$, $f_{^2f}$, stellar compactness $M/R$, and kinetic-to-binding energy ratio $T/|W|$ persist even with a toroidal magnetic field. The slope of these relations depends on the toroidal magnetization constant $K_\mathrm{m}$. Additionally, measuring the frequency ratio $f_{^2f}/f_F$ enables inference of $T/|W|$ and the maximum magnetic field strength $\mathcal{B}_\mathrm{max}$. Lastly, we show that differential rotation causes only minor deviations from predictions for uniform rotation. Thus, this work demonstrates that rotational and magnetic properties of neutron stars can be inferred from their fundamental modes.

**Link**: [arxiv](http://arxiv.org/abs/2509.10150v1),  [pdf](http://arxiv.org/pdf/2509.10150v1)

**Tags**: astro-ph.HE 



### A Framework for Testing and Adapting REST APIs as LLM Tools
**Authors**: Jayachandu Bandlamudi, Ritwik Chaudhuri, Neelamadhav Gantayat, Sambit Ghosh, Kushal Mukherjee, Prerna Agarwal, Renuka Sindhgatta, Sameep Mehta

**Updated**: 2025-09-12T11:24:08Z

**Summary**: Large Language Models (LLMs) are increasingly used to build autonomous agents that perform complex tasks with external tools, often exposed through APIs in enterprise systems. Direct use of these APIs is difficult due to the complex input schema and verbose responses. Current benchmarks overlook these challenges, leaving a gap in assessing API readiness for agent-driven automation. We present a testing framework that systematically evaluates enterprise APIs when wrapped as Python tools for LLM-based agents. The framework generates data-aware test cases, translates them into natural language instructions, and evaluates whether agents can correctly invoke the tool, handle their inputs, and process its responses. We apply the framework to generate over 2400 test cases across different domains and develop a taxonomy of common errors, including input misinterpretation, output failures, and schema mismatches. We further classify errors to support debugging and tool refinement. Our framework provides a systematic approach to enabling enterprise APIs as reliable tools for agent-based applications.

**Link**: [arxiv](http://arxiv.org/abs/2504.15546v3),  [pdf](http://arxiv.org/pdf/2504.15546v3)

**Tags**: cs.SE cs.AI I.2.7 



### On Syntactical Simplification of Temporal Operators in Negation-free MTL
**Authors**: Mathijs van Noort, Femke Ongenae, Pieter Bonte

**Updated**: 2025-09-12T11:19:41Z

**Summary**: Temporal reasoning in dynamic, data-intensive environments increasingly demands expressive yet tractable logical frameworks. Traditional approaches often rely on negation to express absence or contradiction. In such contexts, Negation-as-Failure is commonly used to infer negative information from the lack of positive evidence. However, open and distributed systems such as IoT networks or the Semantic Web Negation-as-Failure semantics become unreliable due to incomplete and asynchronous data. This has led to a growing interest in negation-free fragments of temporal rule-based systems, which preserve monotonicity and enable scalable reasoning.   This paper investigates the expressive power of negation-free MTL, a temporal logic framework designed for rule-based reasoning over time. We show that the "always" operators of MTL, often treated as syntactic sugar for combinations of other temporal constructs, can be eliminated using "once", "since" and "until" operators. Remarkably, even the "once" operators can be removed, yielding a fragment based solely on "until" and "since". These results challenge the assumption that negation is necessary for expressing universal temporal constraints, and reveal a robust fragment capable of capturing both existential and invariant temporal patterns. Furthermore, the results induce a reduction in the syntax of MTL, which in turn can provide benefits for both theoretical study as well as implementation efforts.

**Link**: [arxiv](http://arxiv.org/abs/2509.10146v1),  [pdf](http://arxiv.org/pdf/2509.10146v1)

**Tags**: cs.LO 



### Cluster Ages to Reconstruct the Milky Way Assembly (CARMA) IV.   Chrono-dynamics of seven old star clusters in the Large Magellanic Cloud and   the peculiar origin of NGC 1841
**Authors**: F. Niederhofer, D. Massari, F. Aguado-Agelet, S. Cassisi, A. Bellini, V. Kozhurina-Platais, M. Libralato, N. Kacharov, A. Mucciarelli, M. Monelli, N. Bastian, I. Cabrera-Ziri, E. Ceccarelli, M. -R. L. Cioni, F. Dresbach, M. Häberle, S. Martocchia, S. Saracino

**Updated**: 2025-09-12T11:15:51Z

**Summary**: In this study, we report conclusive evidence for an ancient star cluster that has been accreted by the Large Magellanic Cloud (LMC). By leveraging observations from the Hubble Space Telescope (HST), we investigate the chrono-dynamical structure of a sample of seven old star clusters within the LMC in a self-consistent way. The multi-epoch nature of the dataset allowed the determination of high-precision proper motions for the clusters. Employing an isochrone-fitting methodology, we additionally infer from the deep high-resolution HST data homogeneous and robust estimates for their distances, ages and metallicities. Supplementing these data with literature line-of-sight velocities, we investigate the full 3-dimensional dynamics of the clusters within the frame of the LMC. With respect to the other clusters in our sample, NGC 1841 depicts a peculiar case. Its position in the age-metallicity plane, that makes it about 1 Gyr younger than the other metal-poor LMC clusters, but also its dynamical properties with a radial orbit almost perpendicular to the LMC disc plane, clearly advocates for a different origin. We thus conclude that NGC 1841 has likely been accreted by the LMC from a smaller galaxy. The other clusters in our sample show disc-like kinematics, with the case of NGC 2210 being peculiar, based on its inclined orbit. Their coherent age-metallicity relation closely resembles that of Gaia-Sausage-Enceladus globular clusters, thus suggesting a similar early evolution for the two dwarf galaxies. We do not find clear-cut chrono-kinematic evidence that NGC 2005 has been accreted by the LMC as suggested by a previous study based on its chemical abundance pattern. Regardless of its nature, its very old age illustrates that peculiar chemical evolutions already emerge at very early times.

**Link**: [arxiv](http://arxiv.org/abs/2509.10144v1),  [pdf](http://arxiv.org/pdf/2509.10144v1)

**Tags**: astro-ph.GA 



### Between a Rock and a Hard Place: Exploiting Ethical Reasoning to   Jailbreak LLMs
**Authors**: Shei Pern Chua, Zhen Leng Thai, Teh Kai Jun, Xiao Li, Xiaolin Hu

**Updated**: 2025-09-12T11:05:08Z

**Summary**: Large language models (LLMs) have undergone safety alignment efforts to mitigate harmful outputs. However, as LLMs become more sophisticated in reasoning, their intelligence may introduce new security risks. While traditional jailbreak attacks relied on singlestep attacks, multi-turn jailbreak strategies that adapt dynamically to context remain underexplored. In this work, we introduce TRIAL (Trolley-problem Reasoning for Interactive Attack Logic), a framework that leverages LLMs ethical reasoning to bypass their safeguards. TRIAL embeds adversarial goals within ethical dilemmas modeled on the trolley problem. TRIAL demonstrates high jailbreak success rates towards both open and close-source models. Our findings underscore a fundamental limitation in AI safety: as models gain advanced reasoning abilities, the nature of their alignment may inadvertently allow for more covert security vulnerabilities to be exploited. TRIAL raises an urgent need in reevaluating safety alignment oversight strategies, as current safeguards may prove insufficient against context-aware adversarial attack.

**Link**: [arxiv](http://arxiv.org/abs/2509.05367v2),  [pdf](http://arxiv.org/pdf/2509.05367v2)

**Tags**: cs.CR cs.AI 



### Cost-Free Personalization via Information-Geometric Projection in   Bayesian Federated Learning
**Authors**: Nour Jamoussi, Giuseppe Serra, Photios A. Stavrou, Marios Kountouris

**Updated**: 2025-09-12T10:46:21Z

**Summary**: Bayesian Federated Learning (BFL) combines uncertainty modeling with decentralized training, enabling the development of personalized and reliable models under data heterogeneity and privacy constraints. Existing approaches typically rely on Markov Chain Monte Carlo (MCMC) sampling or variational inference, often incorporating personalization mechanisms to better adapt to local data distributions. In this work, we propose an information-geometric projection framework for personalization in parametric BFL. By projecting the global model onto a neighborhood of the user's local model, our method enables a tunable trade-off between global generalization and local specialization. Under mild assumptions, we show that this projection step is equivalent to computing a barycenter on the statistical manifold, allowing us to derive closed-form solutions and achieve cost-free personalization. We apply the proposed approach to a variational learning setup using the Improved Variational Online Newton (IVON) optimizer and extend its application to general aggregation schemes in BFL. Empirical evaluations under heterogeneous data distributions confirm that our method effectively balances global and local performance with minimal computational overhead.

**Link**: [arxiv](http://arxiv.org/abs/2509.10132v1),  [pdf](http://arxiv.org/pdf/2509.10132v1)

**Tags**: cs.LG 



### Population-Aligned Persona Generation for LLM-based Social Simulation
**Authors**: Zhengyu Hu, Zheyuan Xiao, Max Xiong, Yuxuan Lei, Tianfu Wang, Jianxun Lian, Kaize Ding, Ziang Xiao, Nicholas Jing Yuan, Xing Xie

**Updated**: 2025-09-12T10:43:47Z

**Summary**: Recent advances in large language models (LLMs) have enabled human-like social simulations at unprecedented scale and fidelity, offering new opportunities for computational social science. A key challenge, however, is the construction of persona sets that authentically represent the diversity and distribution of real-world populations. Most existing LLM-based social simulation studies focus primarily on designing agentic frameworks and simulation environments, often overlooking the complexities of persona generation and the potential biases introduced by unrepresentative persona sets. In this paper, we propose a systematic framework for synthesizing high-quality, population-aligned persona sets for LLM-driven social simulation. Our approach begins by leveraging LLMs to generate narrative personas from long-term social media data, followed by rigorous quality assessment to filter out low-fidelity profiles. We then apply importance sampling to achieve global alignment with reference psychometric distributions, such as the Big Five personality traits. To address the needs of specific simulation contexts, we further introduce a task-specific module that adapts the globally aligned persona set to targeted subpopulations. Extensive experiments demonstrate that our method significantly reduces population-level bias and enables accurate, flexible social simulation for a wide range of research and policy applications.

**Link**: [arxiv](http://arxiv.org/abs/2509.10127v1),  [pdf](http://arxiv.org/pdf/2509.10127v1)

**Tags**: cs.CL cs.AI cs.LG 



### Triplication: an important component of the modern scientific method
**Authors**: Jeremy S. C. Clark, Karina Szczypiór-Piasecka, Kamila Rydzewska, Konrad Podsiadło

**Updated**: 2025-09-12T10:38:58Z

**Summary**: A scientific-study protocol, as defined here, is designed to deliver results from which inductive inference is allowed. In the nineteenth century, triplication was introduced into the plant sciences and Fisher's p<0.05 rule (1925) was incorporated into a triple-result protocol designed to counter random/systematic errors. Aims here were to: (1) classify replication (including non-replicated) protocols; (2) assess their prevalence in plant-science studies published in 2017 for a defined variable construct; and (3) explore the theoretical rationale for the use of triplication. Methods: the plant sciences were surveyed and a protocol-prevalence report produced; association versus experimental proportions analyzed; and real-world-data proxies were used to show confidence-interval-width patterns with increasing replicate number. Results: triplication was found in ~70% of plant-science studies analyzed, with triple-result protocols observed in ~15%. Theoretical considerations showed that, even if systematic errors predominate, "square-root rules" sometimes apply, contributing to the predominance of triplication (real-world-data proxy examples given). Conclusions: Triplication was extensively applied in the studies analyzed and there are strong methodological reasons why (1) triplication, rather than duplication/quadruplication, is the most appropriate standard; (2) triple-result protocols are preferable to global averaging approaches; and (3) plant science methodological standards remain high, despite immense publication pressures.

**Link**: [arxiv](http://arxiv.org/abs/2201.10960v4),  [pdf](http://arxiv.org/pdf/2201.10960v4)

**Tags**: q-bio.QM 



### Gravitational wave signatures from the phase-transition-induced collapse   of a magnetized neutron star
**Authors**: Anson Ka Long Yip, Patrick Chi-Kit Cheong, Tjonnie Guang Feng Li

**Updated**: 2025-09-12T10:35:35Z

**Summary**: Strong magnetic fields make neutron stars potential sources of detectable electromagnetic and gravitational-wave signals. Hence, inferring these magnetic fields is critical to understand the emissions of neutron stars. However, due to the lack of direct observational evidence, the interior magnetic field configuration remains ambiguous. Here, for the first time, we show that the internal magnetic field strength along with the composition of a neutron star can be directly constrained by detecting the gravitational waves from the \emph{phase-transition-induced collapse} of a magnetized neutron star. By dynamically simulating this collapsing event, we first find that the dominant peaks in the gravitational waveform are the fundamental $l=0$ quasi-radial $F$ mode and the fundamental $l=2$ quadrupolar $^2f$ mode. We next show that the maximum gravitational wave amplitude $|h|_\mathrm{max}$ increases with the maximum magnetic field strength of the interior toroidal field $\mathcal{B}_\mathrm{max}$ until the maximum rest-mass density at bounce $\rho_\mathrm{max,b}$ decreases due to the increasing $\mathcal{B}_\mathrm{max}$. We then demonstrated that the magnetic suppression of fundamental modes found in our previous work remains valid for the hybrid stars formed after the phase-transition-induced collapses. We finally show that measuring the frequency ratio between the two fundamental modes $f_{^2f}/f_{F}$ allows one to infer $\mathcal{B}_\mathrm{max}$ and the baryonic mass fraction of matter in the mixed phase $M_\mathrm{mp} / M_{0}$ of the resulting hybrid star. Consequently, taking $\mathcal{B}_\mathrm{max}$ and $M_\mathrm{mp} / M_{0}$ as examples, this work has demonstrated that much information inside neutron stars could be extracted similarly through measuring the oscillation modes of the stars.

**Link**: [arxiv](http://arxiv.org/abs/2305.15181v2),  [pdf](http://arxiv.org/pdf/2305.15181v2)

**Tags**: astro-ph.HE 



### Afford-X: Generalizable and Slim Affordance Reasoning for Task-oriented   Manipulation
**Authors**: Xiaomeng Zhu, Yuyang Li, Leiyao Cui, Pengfei Li, Huan-ang Gao, Yixin Zhu, Hao Zhao

**Updated**: 2025-09-12T10:34:34Z

**Summary**: Object affordance reasoning, the ability to infer object functionalities based on physical properties, is fundamental for task-oriented planning and activities in both humans and Artificial Intelligence (AI). This capability, required for planning and executing daily activities in a task-oriented manner, relies on commonsense knowledge of object physics and functionalities, extending beyond simple object recognition. Current computational models for affordance reasoning from perception lack generalizability, limiting their applicability in novel scenarios. Meanwhile, comprehensive Large Language Models (LLMs) with emerging reasoning capabilities are challenging to deploy on local devices for task-oriented manipulations. Here, we introduce LVIS-Aff, a large-scale dataset comprising 1,496 tasks and 119k images, designed to enhance the generalizability of affordance reasoning from perception. Utilizing this dataset, we develop Afford-X, an end-to-end trainable affordance reasoning model that incorporates Verb Attention and Bi-Fusion modules to improve multi-modal understanding. This model achieves up to a 12.1% performance improvement over the best-reported results from non-LLM methods, while also demonstrating a 1.2% enhancement compared to our previous conference paper. Additionally, it maintains a compact 187M parameter size and infers nearly 50 times faster than the GPT-4V API. Our work demonstrates the potential for efficient, generalizable affordance reasoning models that can be deployed on local devices for task-oriented manipulations. We showcase Afford-X's effectiveness in enabling task-oriented manipulations for robots across various tasks and environments, underscoring its efficiency and broad implications for advancing robotics and AI systems in real-world applications.

**Link**: [arxiv](http://arxiv.org/abs/2503.03556v2),  [pdf](http://arxiv.org/pdf/2503.03556v2)

**Tags**: cs.CV cs.RO 



### Realism Control One-step Diffusion for Real-World Image Super-Resolution
**Authors**: Zongliang Wu, Siming Zheng, Peng-Tao Jiang, Xin Yuan

**Updated**: 2025-09-12T10:32:04Z

**Summary**: Pre-trained diffusion models have shown great potential in real-world image super-resolution (Real-ISR) tasks by enabling high-resolution reconstructions. While one-step diffusion (OSD) methods significantly improve efficiency compared to traditional multi-step approaches, they still have limitations in balancing fidelity and realism across diverse scenarios. Since the OSDs for SR are usually trained or distilled by a single timestep, they lack flexible control mechanisms to adaptively prioritize these competing objectives, which are inherently manageable in multi-step methods through adjusting sampling steps. To address this challenge, we propose a Realism Controlled One-step Diffusion (RCOD) framework for Real-ISR. RCOD provides a latent domain grouping strategy that enables explicit control over fidelity-realism trade-offs during the noise prediction phase with minimal training paradigm modifications and original training data. A degradation-aware sampling strategy is also introduced to align distillation regularization with the grouping strategy and enhance the controlling of trade-offs. Moreover, a visual prompt injection module is used to replace conventional text prompts with degradation-aware visual tokens, enhancing both restoration accuracy and semantic consistency. Our method achieves superior fidelity and perceptual quality while maintaining computational efficiency. Extensive experiments demonstrate that RCOD outperforms state-of-the-art OSD methods in both quantitative metrics and visual qualities, with flexible realism control capabilities in the inference stage. The code will be released.

**Link**: [arxiv](http://arxiv.org/abs/2509.10122v1),  [pdf](http://arxiv.org/pdf/2509.10122v1)

**Tags**: cs.CV cs.AI 



### Impact of stochastic star-formation histories and dust on selecting   quiescent galaxies with JWST photometry
**Authors**: K. Lisiecki, D. Donevski, A. W. S. Man, I. Damjanov, M. Romano, S. Belli, A. Long, G. Lorenzon, K. Małek, Junais, C. C. Lovell, A. Nanni, C. Bertemes, W. Pearson, O. Ryzhov, M. Koprowski, A. Pollo, S. Dey, H. Thuruthipilly

**Updated**: 2025-09-12T10:20:04Z

**Summary**: While the James Webb Space Telescope (JWST) now allows identifying quiescent galaxies (QGs) out to early epochs, the photometric selection of quiescent galaxy candidates (QGCs) and the derivation of key physical quantities are highly sensitive to the assumed star-formation histories (SFHs). We aim to quantify how the inclusion of JWST/MIRI data and different SFH models impacts the selection and characterisation of QGCs. We test the robustness of the physical properties inferred from the spectral energy distribution (SED) fitting, such as M*, age, star formation rate (SFR), and AV, and study how they impact the quiescence criteria of the galaxies across cosmic time. We perform SED fitting for ~13000 galaxies at z<6 from the CEERS/MIRI fields with up to 20 optical-mid infrared (MIR) broadband coverage. We implement three SFH prescriptions: flexible delayed, NonParametric, and extended Regulator. For each model, we compare results obtained with and without MIRI photometry and dust emission models. We evaluate the impact of these configurations on the number of candidate QGCs, selected based on rest UVJ colours, sSFR and main-sequence offset, and on their key physical properties such as M*, AV, and stellar ages. The number of QGCs selected varies significantly with the choice of SFH from 171 to 224 out of 13000 galaxies, depending on the model. This number increases to 222-327 when MIRI data are used (up to ~45% more QGCs). This enhancement is driven by improved constraints on dust attenuation and M*. We find a strong correlation between AV and M*, with massive galaxies (M*~10^11 M\odot) being 1.5-4.2 times more attenuated in magnitude than low-mass systems (M*~10^9 M\odot), depending on SFH. Regardless of the SFH assumption, ~13% of QGCs exhibit significant attenuation (AV > 0.5) in support of recent JWST studies challenging the notion that quiescent galaxies are uniformly dust-free.

**Link**: [arxiv](http://arxiv.org/abs/2509.10117v1),  [pdf](http://arxiv.org/pdf/2509.10117v1)

**Tags**: astro-ph.GA 



### Scaling Arabic Medical Chatbots Using Synthetic Data: Enhancing   Generative AI with Synthetic Patient Records
**Authors**: Abdulrahman Allam, Seif Ahmed, Ali Hamdi, Khaled Shaban

**Updated**: 2025-09-12T09:58:11Z

**Summary**: The development of medical chatbots in Arabic is significantly constrained by the scarcity of large-scale, high-quality annotated datasets. While prior efforts compiled a dataset of 20,000 Arabic patient-doctor interactions from social media to fine-tune large language models (LLMs), model scalability and generalization remained limited. In this study, we propose a scalable synthetic data augmentation strategy to expand the training corpus to 100,000 records. Using advanced generative AI systems ChatGPT-4o and Gemini 2.5 Pro we generated 80,000 contextually relevant and medically coherent synthetic question-answer pairs grounded in the structure of the original dataset. These synthetic samples were semantically filtered, manually validated, and integrated into the training pipeline. We fine-tuned five LLMs, including Mistral-7B and AraGPT2, and evaluated their performance using BERTScore metrics and expert-driven qualitative assessments. To further analyze the effectiveness of synthetic sources, we conducted an ablation study comparing ChatGPT-4o and Gemini-generated data independently. The results showed that ChatGPT-4o data consistently led to higher F1-scores and fewer hallucinations across all models. Overall, our findings demonstrate the viability of synthetic augmentation as a practical solution for enhancing domain-specific language models in-low resource medical NLP, paving the way for more inclusive, scalable, and accurate Arabic healthcare chatbot systems.

**Link**: [arxiv](http://arxiv.org/abs/2509.10108v1),  [pdf](http://arxiv.org/pdf/2509.10108v1)

**Tags**: cs.CL 



### General-relativistic magnetar magnetospheres in 3D with physics-informed   neural networks
**Authors**: Petros Stefanou, Arthur G. Suvorov, José A. Pons

**Updated**: 2025-09-12T09:57:33Z

**Summary**: Magnetar phenomena are likely intertwined with the location and structure of magnetospheric currents. General-relativistic effects are important in shaping the force-free equilibria describing static configurations, though most studies have quantified their impact only in cases of axial symmetry. Using a novel methodology based on physics-informed neural networks, fully three-dimensional configurations of varying stellar compactness are constructed. Realistic profiles for surface currents, qualitatively capturing the geometry of observed hotspots, are applied as boundary conditions to deduce the amount of free energy available to fuel outburst activity. It is found that the lowest-energy solution branches permit only a $\approx 30\%$ excess relative to current-starved solutions in axisymmetric cases with global twists, regardless of compactness, reducing to $\approx 5\%$ in 3D models with localised spots. Accounting for redshift reductions to their inferred dipole moments from timing data, explaining magnetar burst energetics therefore becomes more difficult unless the field hosts non-negligible multipoles. Discussions on other aspects of magnetar phenomena are also provided.

**Link**: [arxiv](http://arxiv.org/abs/2506.13519v2),  [pdf](http://arxiv.org/pdf/2506.13519v2)

**Tags**: astro-ph.HE 



### GROVE: A Generalized Reward for Learning Open-Vocabulary Physical Skill
**Authors**: Jieming Cui, Tengyu Liu, Ziyu Meng, Jiale Yu, Ran Song, Wei Zhang, Yixin Zhu, Siyuan Huang

**Updated**: 2025-09-12T09:55:20Z

**Summary**: Learning open-vocabulary physical skills for simulated agents presents a significant challenge in artificial intelligence. Current reinforcement learning approaches face critical limitations: manually designed rewards lack scalability across diverse tasks, while demonstration-based methods struggle to generalize beyond their training distribution. We introduce GROVE, a generalized reward framework that enables open-vocabulary physical skill learning without manual engineering or task-specific demonstrations. Our key insight is that Large Language Models(LLMs) and Vision Language Models(VLMs) provide complementary guidance -- LLMs generate precise physical constraints capturing task requirements, while VLMs evaluate motion semantics and naturalness. Through an iterative design process, VLM-based feedback continuously refines LLM-generated constraints, creating a self-improving reward system. To bridge the domain gap between simulation and natural images, we develop Pose2CLIP, a lightweight mapper that efficiently projects agent poses directly into semantic feature space without computationally expensive rendering. Extensive experiments across diverse embodiments and learning paradigms demonstrate GROVE's effectiveness, achieving 22.2% higher motion naturalness and 25.7% better task completion scores while training 8.4x faster than previous methods. These results establish a new foundation for scalable physical skill acquisition in simulated environments.

**Link**: [arxiv](http://arxiv.org/abs/2504.04191v2),  [pdf](http://arxiv.org/pdf/2504.04191v2)

**Tags**: cs.CV cs.RO 



### Generalizing thermodynamic efficiency of interactions: inferential,   information-geometric and computational perspectives
**Authors**: Qianyang Chen, Nihat Ay, Mikhail Prokopenko

**Updated**: 2025-09-12T09:51:50Z

**Summary**: Self-organizing systems consume energy to generate internal order. The concept of thermodynamic efficiency, drawing from statistical physics and information theory, has previously been proposed to characterize a change in control parameter by relating the resulting predictability gain to the required amount of work. However, previous studies have taken a system-centric perspective and considered only single control parameters. Here, we generalize thermodynamic efficiency to multi-parameter settings and derive two observer-centric formulations. The first, an inferential form, relates efficiency to fluctuations of macroscopic observables, interpreting thermodynamic efficiency in terms of how well the system parameters can be inferred from observable macroscopic behaviour. The second, an information-geometric form, expresses efficiency in terms of the Fisher information matrix, interpreting it with respect to how difficult it is to navigate the statistical manifold defined by the control protocol. This observer-centric perspective is contrasted with the existing system-centric view, where efficiency is considered an intrinsic property of the system.

**Link**: [arxiv](http://arxiv.org/abs/2509.10102v1),  [pdf](http://arxiv.org/pdf/2509.10102v1)

**Tags**: nlin.AO 68T05, 82B20, 82B27, 94A17 I.2.11 



### DRespNeT: A UAV Dataset and YOLOv8-DRN Model for Aerial Instance   Segmentation of Building Access Points for Post-Earthquake Search-and-Rescue   Missions
**Authors**: Aykut Sirma, Angelos Plastropoulos, Gilbert Tang, Argyrios Zolotas

**Updated**: 2025-09-12T09:50:49Z

**Summary**: Recent advancements in computer vision and deep learning have enhanced disaster-response capabilities, particularly in the rapid assessment of earthquake-affected urban environments. Timely identification of accessible entry points and structural obstacles is essential for effective search-and-rescue (SAR) operations. To address this need, we introduce DRespNeT, a high-resolution dataset specifically developed for aerial instance segmentation of post-earthquake structural environments. Unlike existing datasets, which rely heavily on satellite imagery or coarse semantic labeling, DRespNeT provides detailed polygon-level instance segmentation annotations derived from high-definition (1080p) aerial footage captured in disaster zones, including the 2023 Turkiye earthquake and other impacted regions. The dataset comprises 28 operationally critical classes, including structurally compromised buildings, access points such as doors, windows, and gaps, multiple debris levels, rescue personnel, vehicles, and civilian visibility. A distinctive feature of DRespNeT is its fine-grained annotation detail, enabling differentiation between accessible and obstructed areas, thereby improving operational planning and response efficiency. Performance evaluations using YOLO-based instance segmentation models, specifically YOLOv8-seg, demonstrate significant gains in real-time situational awareness and decision-making. Our optimized YOLOv8-DRN model achieves 92.7% mAP50 with an inference speed of 27 FPS on an RTX-4090 GPU for multi-target detection, meeting real-time operational requirements. The dataset and models support SAR teams and robotic systems, providing a foundation for enhancing human-robot collaboration, streamlining emergency response, and improving survivor outcomes.

**Link**: [arxiv](http://arxiv.org/abs/2508.16016v2),  [pdf](http://arxiv.org/pdf/2508.16016v2)

**Tags**: cs.CV 



### Generating Energy-Efficient Code via Large-Language Models -- Where are   we now?
**Authors**: Radu Apsan, Vincenzo Stoico, Michel Albonico, Rudra Dhar, Karthik Vaidhyanathan, Ivano Malavolta

**Updated**: 2025-09-12T09:49:46Z

**Summary**: Context. The rise of Large Language Models (LLMs) has led to their widespread adoption in development pipelines. Goal. We empirically assess the energy efficiency of Python code generated by LLMs against human-written code and code developed by a Green software expert. Method. We test 363 solutions to 9 coding problems from the EvoEval benchmark using 6 widespread LLMs with 4 prompting techniques, and comparing them to human-developed solutions. Energy consumption is measured on three different hardware platforms: a server, a PC, and a Raspberry Pi for a total of ~881h (36.7 days). Results. Human solutions are 16% more energy-efficient on the server and 3% on the Raspberry Pi, while LLMs outperform human developers by 25% on the PC. Prompting does not consistently lead to energy savings, where the most energy-efficient prompts vary by hardware platform. The code developed by a Green software expert is consistently more energy-efficient by at least 17% to 30% against all LLMs on all hardware platforms. Conclusions. Even though LLMs exhibit relatively good code generation capabilities, no LLM-generated code was more energy-efficient than that of an experienced Green software developer, suggesting that as of today there is still a great need of human expertise for developing energy-efficient Python code.

**Link**: [arxiv](http://arxiv.org/abs/2509.10099v1),  [pdf](http://arxiv.org/pdf/2509.10099v1)

**Tags**: cs.SE cs.AI 



### Arabic Large Language Models for Medical Text Generation
**Authors**: Abdulrahman Allam, Seif Ahmed, Ali Hamdi, Ammar Mohammed

**Updated**: 2025-09-12T09:37:26Z

**Summary**: Efficient hospital management systems (HMS) are critical worldwide to address challenges such as overcrowding, limited resources, and poor availability of urgent health care. Existing methods often lack the ability to provide accurate, real-time medical advice, particularly for irregular inputs and underrepresented languages. To overcome these limitations, this study proposes an approach that fine-tunes large language models (LLMs) for Arabic medical text generation. The system is designed to assist patients by providing accurate medical advice, diagnoses, drug recommendations, and treatment plans based on user input. The research methodology required the collection of a unique dataset from social media platforms, capturing real-world medical conversations between patients and doctors. The dataset, which includes patient complaints together with medical advice, was properly cleaned and preprocessed to account for multiple Arabic dialects. Fine-tuning state-of-the-art generative models, such as Mistral-7B-Instruct-v0.2, LLaMA-2-7B, and GPT-2 Medium, optimized the system's ability to generate reliable medical text. Results from evaluations indicate that the fine-tuned Mistral-7B model outperformed the other models, achieving average BERT (Bidirectional Encoder Representations from Transformers) Score values in precision, recall, and F1-scores of 68.5\%, 69.08\%, and 68.5\%, respectively. Comparative benchmarking and qualitative assessments validate the system's ability to produce coherent and relevant medical replies to informal input. This study highlights the potential of generative artificial intelligence (AI) in advancing HMS, offering a scalable and adaptable solution for global healthcare challenges, especially in linguistically and culturally diverse environments.

**Link**: [arxiv](http://arxiv.org/abs/2509.10095v1),  [pdf](http://arxiv.org/pdf/2509.10095v1)

**Tags**: cs.CL 



### Established Psychometric vs. Ecologically Valid Questionnaires:   Rethinking Psychological Assessments in Large Language Models
**Authors**: Dongmin Choi, Woojung Song, Jongwook Han, Eun-Ju Lee, Yohan Jo

**Updated**: 2025-09-12T09:14:42Z

**Summary**: Researchers have applied established psychometric questionnaires (e.g., BFI, PVQ) to measure the personality traits and values reflected in the responses of Large Language Models (LLMs). However, concerns have been raised about applying these human-designed questionnaires to LLMs. One such concern is their lack of ecological validity--the extent to which survey questions adequately reflect and resemble real-world contexts in which LLMs generate texts in response to user queries. However, it remains unclear how established questionnaires and ecologically valid questionnaires differ in their outcomes, and what insights these differences may provide. In this paper, we conduct a comprehensive comparative analysis of the two types of questionnaires. Our analysis reveals that established questionnaires (1) yield substantially different profiles of LLMs from ecologically valid ones, deviating from the psychological characteristics expressed in the context of user queries, (2) suffer from insufficient items for stable measurement, (3) create misleading impressions that LLMs possess stable constructs, and (4) yield exaggerated profiles for persona-prompted LLMs. Overall, our work cautions against the use of established psychological questionnaires for LLMs. Our code will be released upon publication.

**Link**: [arxiv](http://arxiv.org/abs/2509.10078v1),  [pdf](http://arxiv.org/pdf/2509.10078v1)

**Tags**: cs.CL cs.AI 



### Alignment-Augmented Speculative Decoding with Alignment Sampling and   Conditional Verification
**Authors**: Jikai Wang, Zhenxu Tian, Juntao Li, Qingrong Xia, Xinyu Duan, Zhefeng Wang, Baoxing Huai, Min Zhang

**Updated**: 2025-09-12T09:08:05Z

**Summary**: Recent works have revealed the great potential of speculative decoding in accelerating the autoregressive generation process of large language models. The success of these methods relies on the alignment between draft candidates and the sampled outputs of the target model. Existing methods mainly achieve draft-target alignment with training-based methods, e.g., EAGLE, Medusa, involving considerable training costs. In this paper, we present a training-free alignment-augmented speculative decoding algorithm. We propose alignment sampling, which leverages output distribution obtained in the prefilling phase to provide more aligned draft candidates. To further benefit from high-quality but non-aligned draft candidates, we also introduce a simple yet effective flexible verification strategy. Through an adaptive probability threshold, our approach can improve generation accuracy while further improving inference efficiency. Experiments on 8 datasets (including question answering, summarization and code completion tasks) show that our approach increases the average generation score by 3.3 points for the LLaMA3 model. Our method achieves a mean acceptance length up to 2.39 and speed up generation by 2.23.

**Link**: [arxiv](http://arxiv.org/abs/2505.13204v2),  [pdf](http://arxiv.org/pdf/2505.13204v2)

**Tags**: cs.CL 



### Reframe Your Life Story: Interactive Narrative Therapist and Innovative   Moment Assessment with Large Language Models
**Authors**: Yi Feng, Jiaqi Wang, Wenxuan Zhang, Zhuang Chen, Yutong Shen, Xiyao Xiao, Minlie Huang, Liping Jing, Jian Yu

**Updated**: 2025-09-12T09:08:02Z

**Summary**: Recent progress in large language models (LLMs) has opened new possibilities for mental health support, yet current approaches lack realism in simulating specialized psychotherapy and fail to capture therapeutic progression over time. Narrative therapy, which helps individuals transform problematic life stories into empowering alternatives, remains underutilized due to limited access and social stigma. We address these limitations through a comprehensive framework with two core components. First, INT (Interactive Narrative Therapist) simulates expert narrative therapists by planning therapeutic stages, guiding reflection levels, and generating contextually appropriate expert-like responses. Second, IMA (Innovative Moment Assessment) provides a therapy-centric evaluation method that quantifies effectiveness by tracking "Innovative Moments" (IMs), critical narrative shifts in client speech signaling therapy progress. Experimental results on 260 simulated clients and 230 human participants reveal that INT consistently outperforms standard LLMs in therapeutic quality and depth. We further demonstrate the effectiveness of INT in synthesizing high-quality support conversations to facilitate social applications.

**Link**: [arxiv](http://arxiv.org/abs/2507.20241v2),  [pdf](http://arxiv.org/pdf/2507.20241v2)

**Tags**: cs.CL 



### Task-Oriented Multimodal Token Transmission in Resource-Constrained   Multiuser Networks
**Authors**: Junhe Zhang, Wanli Ni, Pengwei Wang, Dongyu Wang

**Updated**: 2025-09-12T08:58:30Z

**Summary**: Despite the promising paradigm enabled by integrating semantic communication (SemCom) with multimodal large models (MLMs) for transmitting and utilizing multimodal data, efficiently fusing and exploiting cross-modal information still remain challenging. Moreover, widely adopted transformer-based architectures inevitably produce excessively long token embeddings for transmission, which result in higher bandwidth consumption, increased power usage, and greater latency, rendering them impractical in resource-constrained networks. In this letter, we propose a task-oriented multimodal token transmission scheme for efficient multimodal information fusion and utilization. To improve inter-modal consistency and task-relevant token transmission, we design a two-stage training algotithm which involves cross-modal alignment followed by task-oriented fine-tuning. Meanwhile, token compression is performed using a sliding window pooling operation to conserve limited communication resources. To balance the trade-off between latency reduction and performance degradation caused by compression, we formulate a weighted-sum optimization problem over latency and inference performance. We jointly optimizes bandwidth, power allocation, and token length across users by using an alternating optimization method. Simulation results demonstrate that the proposed algorithm outperforms the baseline under different bandwidth and power budgets. Moreover, the two-stage training algorithm achieves higher accuracy across various signal-to-noise ratios than the method without cross-modal alignment.

**Link**: [arxiv](http://arxiv.org/abs/2505.07841v2),  [pdf](http://arxiv.org/pdf/2505.07841v2)

**Tags**: cs.NI cs.LG 



### Weakening assumptions in the evaluation of treatment effects in   longitudinal randomized trials with truncation by death or other intercurrent   events
**Authors**: Georgi Baklicharov, Kelly Van Lancker, Stijn Vansteelandt

**Updated**: 2025-09-12T08:58:18Z

**Summary**: Intercurrent events, such as treatment switching, rescue medication, or truncation by death, can complicate the interpretation of intention-to-treat (ITT) analyses in randomized clinical trials. Recent advances in causal inference address these challenges by targeting alternative estimands, such as hypothetical estimands or principal stratum estimands (e.g., survivor average causal effects). However, such approaches often require strong, unverifiable assumptions, partly due to limited data on time-varying confounders and the difficulty of adjusting for them. Additionally, strict trial protocols frequently lead to (near) violations of the positivity assumption, resulting in limited information for identifying these estimands.   In this paper, we propose a novel approach that sidesteps these difficulties by focusing on testing the null hypothesis of no treatment effect in the presence of arbitrary intercurrent events, including truncation by death, using longitudinal trial data. Our key idea is to compare treated and untreated individuals, matched on baseline covariates, at the most recent time point before either experiences an intercurrent event. We refer to such contrasts as Pairwise Last Observation Time (PLOT) estimands. These estimands can be identified in randomized clinical trials without requiring additional structural assumptions, and even in the presence of the aforementioned positivity violations. However, they may still be susceptible to a form of residual selection bias. We show that this bias vanishes under the conditions typically required by alternative methods, and find it to be more generally small in extensive simulation studies. Building on this, we develop asymptotically efficient, model-free tests using data-adaptive estimation of nuisance parameters. We evaluate the method's performance via simulation studies.

**Link**: [arxiv](http://arxiv.org/abs/2509.10067v1),  [pdf](http://arxiv.org/pdf/2509.10067v1)

**Tags**: stat.ME 



### Color Me Correctly: Bridging Perceptual Color Spaces and Text Embeddings   for Improved Diffusion Generation
**Authors**: Sung-Lin Tsai, Bo-Lun Huang, Yu Ting Shen, Cheng Yu Yeo, Chiang Tseng, Bo-Kai Ruan, Wen-Sheng Lien, Hong-Han Shuai

**Updated**: 2025-09-12T08:44:22Z

**Summary**: Accurate color alignment in text-to-image (T2I) generation is critical for applications such as fashion, product visualization, and interior design, yet current diffusion models struggle with nuanced and compound color terms (e.g., Tiffany blue, lime green, hot pink), often producing images that are misaligned with human intent. Existing approaches rely on cross-attention manipulation, reference images, or fine-tuning but fail to systematically resolve ambiguous color descriptions. To precisely render colors under prompt ambiguity, we propose a training-free framework that enhances color fidelity by leveraging a large language model (LLM) to disambiguate color-related prompts and guiding color blending operations directly in the text embedding space. Our method first employs a large language model (LLM) to resolve ambiguous color terms in the text prompt, and then refines the text embeddings based on the spatial relationships of the resulting color terms in the CIELAB color space. Unlike prior methods, our approach improves color accuracy without requiring additional training or external reference images. Experimental results demonstrate that our framework improves color alignment without compromising image quality, bridging the gap between text semantics and visual generation.

**Link**: [arxiv](http://arxiv.org/abs/2509.10058v1),  [pdf](http://arxiv.org/pdf/2509.10058v1)

**Tags**: cs.CV 



### XAgents: A Unified Framework for Multi-Agent Cooperation via IF-THEN   Rules and Multipolar Task Processing Graph
**Authors**: Hailong Yang, Mingxian Gu, Jianqi Wang, Guanjin Wang, Zhaohong Deng

**Updated**: 2025-09-12T08:40:58Z

**Summary**: The rapid advancement of Large Language Models (LLMs) has significantly enhanced the capabilities of Multi-Agent Systems (MAS) in supporting humans with complex, real-world tasks. However, MAS still face challenges in effective task planning when handling highly complex tasks with uncertainty, often resulting in misleading or incorrect outputs that hinder task execution. To address this, we propose XAgents, a unified multi-agent cooperative framework built on a multipolar task processing graph and IF-THEN rules. XAgents uses the multipolar task processing graph to enable dynamic task planning and handle task uncertainty. During subtask processing, it integrates domain-specific IF-THEN rules to constrain agent behaviors, while global rules enhance inter-agent collaboration. We evaluate the performance of XAgents across three distinct datasets, demonstrating that it consistently surpasses state-of-the-art single-agent and multi-agent approaches in both knowledge-typed and logic-typed question-answering tasks. The codes for XAgents are available at: https://github.com/AGI-FHBC/XAgents.

**Link**: [arxiv](http://arxiv.org/abs/2509.10054v1),  [pdf](http://arxiv.org/pdf/2509.10054v1)

**Tags**: cs.AI 



### Exploring a Gamified Personality Assessment Method through Interaction   with LLM Agents Embodying Different Personalities
**Authors**: Baiqiao Zhang, Xiangxian Li, Chao Zhou, Xinyu Gai, Juan Liu, Xue Yang, Xiaojuan Ma, Yong-jin Liu, Yulong Bian

**Updated**: 2025-09-12T08:36:02Z

**Summary**: The low-intrusion and automated personality assessment is receiving increasing attention in psychology and human-computer interaction fields. This study explores an interactive approach for personality assessment, focusing on the multiplicity of personality representation. We propose a framework of Gamified Personality Assessment through Multi-Personality Representations (Multi-PR GPA). The framework leverages Large Language Models to empower virtual agents with different personalities. These agents elicit multifaceted human personality representations through engaging in interactive games. Drawing upon the multi-type textual data generated throughout the interaction, it achieves two modes of personality assessment (i.e., Direct Assessment and Questionnaire-based Assessment) and provides interpretable insights. Grounded in the classic Big Five personality theory, we developed a prototype system and conducted a user study to evaluate the efficacy of Multi-PR GPA. The results affirm the effectiveness of our approach in personality assessment and demonstrate its superior performance when considering the multiplicity of personality representation.

**Link**: [arxiv](http://arxiv.org/abs/2507.04005v3),  [pdf](http://arxiv.org/pdf/2507.04005v3)

**Tags**: cs.HC cs.CY 



### When Pattern-by-Pattern Works: Theoretical and Empirical Insights for   Logistic Models with Missing Values
**Authors**: Christophe Muller, Erwan Scornet, Julie Josse

**Updated**: 2025-09-12T08:27:21Z

**Summary**: Predicting a response with partially missing inputs remains a challenging task even in parametric models, since parameter estimation in itself is not sufficient to predict on partially observed inputs. Several works study prediction in linear models. In this paper, we focus on logistic models, which present their own difficulties. From a theoretical perspective, we prove that a Pattern-by-Pattern strategy (PbP), which learns one logistic model per missingness pattern, accurately approximates Bayes probabilities in various missing data scenarios (MCAR, MAR and MNAR). Empirically, we thoroughly compare various methods (constant and iterative imputations, complete case analysis, PbP, and an EM algorithm) across classification, probability estimation, calibration, and parameter inference. Our analysis provides a comprehensive view on the logistic regression with missing values. It reveals that mean imputation can be used as baseline for low sample sizes, and improved performance is obtained via nonlinear multiple iterative imputation techniques with the labels (MICE.RF.Y). For large sample sizes, PbP is the best method for Gaussian mixtures, and we recommend MICE.RF.Y in presence of nonlinear features.

**Link**: [arxiv](http://arxiv.org/abs/2507.13024v2),  [pdf](http://arxiv.org/pdf/2507.13024v2)

**Tags**: stat.ML cs.LG 



### GeoJSON Agents:A Multi-Agent LLM Architecture for Geospatial   Analysis-Function Calling vs Code Generation
**Authors**: Qianqian Luo, Liuchang Xu, Qingming Lin, Sensen Wu, Ruichen Mao, Chao Wang, Hailin Feng, Bo Huang, Zhenhong Du

**Updated**: 2025-09-12T08:26:37Z

**Summary**: LLMs have made substantial progress in task automation and natural language understanding. However, without expertise in GIS, they continue to encounter limitations. To address these issues, we propose GeoJSON Agents-a multi-agent LLM architecture. This framework transforms natural language tasks into structured GeoJSON operation commands and processes spatial data using two widely adopted LLM enhancement techniques: Function Calling and Code Generation. The architecture consists of three components-task parsing, agent collaboration, and result integration-aimed at enhancing both the performance and scalability of GIS automation. The Planner agent interprets natural language tasks into structured GeoJSON commands. Then, specialized Worker agents collaborate according to assigned roles to perform spatial data processing and analysis, either by invoking predefined function APIs or by dynamically generating and executing Python-based spatial analysis code. Finally, the system integrates the outputs from multiple execution rounds into reusable, standards-compliant GeoJSON files. To systematically evaluate the performance of the two approaches, we constructed a benchmark dataset of 70 tasks with varying complexity and conducted experiments using OpenAI's GPT-4o as the core model. Results indicate that the Function Calling-based GeoJSON Agent achieved an accuracy of 85.71%, while the Code Generation-based agent reached 97.14%, both significantly outperforming the best-performing general-purpose model (48.57%). Further analysis reveals that the Code Generation provides greater flexibility, whereas the Function Calling approach offers more stable execution. This study is the first to introduce an LLM multi-agent framework for GeoJSON data and to compare the strengths and limitations of two mainstream LLM enhancement methods, offering new perspectives for improving GeoAI system performance.

**Link**: [arxiv](http://arxiv.org/abs/2509.08863v2),  [pdf](http://arxiv.org/pdf/2509.08863v2)

**Tags**: cs.SE 



### A Bayesian Framework for Regularized Estimation in Multivariate Models   Integrating Approximate Computing Concepts
**Authors**: Jan Kalina

**Updated**: 2025-09-12T08:21:59Z

**Summary**: This paper discusses regularized estimators in the multivariate statistical model as tools naturally arising within a Bayesian framework. First, a link is established between Bayesian estimation and inference under parameter rounding (quantization), thereby connecting two distinct paradigms: Bayesian inference and approximate computing. Next, Bayesian estimation of the means from two independent multivariate normal samples is employed to justify shrinkage estimators, i.e., means shrunk toward the pooled mean. Finally, regularized linear discriminant analysis (LDA) is considered. Various shrinkage strategies for the mean are justified from a Bayesian perspective, and novel algorithms for their computation are proposed. The proposed methods are illustrated by numerical experiments on real and simulated data.

**Link**: [arxiv](http://arxiv.org/abs/2509.10045v1),  [pdf](http://arxiv.org/pdf/2509.10045v1)

**Tags**: stat.ME 62F15 I.6.2 



### AReaL: A Large-Scale Asynchronous Reinforcement Learning System for   Language Reasoning
**Authors**: Wei Fu, Jiaxuan Gao, Xujie Shen, Chen Zhu, Zhiyu Mei, Chuyi He, Shusheng Xu, Guo Wei, Jun Mei, Jiashu Wang, Tongkai Yang, Binhang Yuan, Yi Wu

**Updated**: 2025-09-12T07:59:18Z

**Summary**: Reinforcement learning (RL) has become a dominant paradigm for training large language models (LLMs), particularly for reasoning tasks. Effective RL for LLMs requires massive parallelization and poses an urgent need for efficient training systems. Most existing large-scale RL systems for LLMs are synchronous, alternating generation and training in a batch setting where rollouts in each training batch are generated by the same model. This approach stabilizes RL training but suffers from severe system-level inefficiency: generation must wait until the longest output in the batch is completed before model updates, resulting in GPU underutilization. We present AReaL, a fully asynchronous RL system that completely decouples generation from training. Rollout workers in AReaL continuously generate new outputs without waiting, while training workers update the model whenever a batch of data is collected. AReaL also incorporates a collection of system-level optimizations, leading to substantially higher GPU utilization. To stabilize RL training, AReaL balances the workload of rollout and training workers to control data staleness, and adopts a staleness-enhanced PPO variant to better handle outdated training samples. Extensive experiments on math and code reasoning benchmarks show that AReaL achieves up to 2.77$\times$ training speedup compared to synchronous systems with the same number of GPUs and matched or improved final performance. The code of AReaL is available at https://github.com/inclusionAI/AReaL/.

**Link**: [arxiv](http://arxiv.org/abs/2505.24298v3),  [pdf](http://arxiv.org/pdf/2505.24298v3)

**Tags**: cs.LG cs.AI 



### Can Large Language Models Master Complex Card Games?
**Authors**: Wei Wang, Felix Henry, Junzhe Chen, Dan Zhang, Shiyu Huang, Evgeny Kharlamov, Jie Tang

**Updated**: 2025-09-12T07:26:28Z

**Summary**: Complex games have long been an important benchmark for testing the progress of artificial intelligence algorithms. AlphaGo, AlphaZero, and MuZero have defeated top human players in Go and Chess, garnering widespread societal attention towards artificial intelligence. Concurrently, large language models (LLMs) have exhibited remarkable capabilities across various tasks, raising the question of whether LLMs can achieve similar success in complex games. In this paper, we explore the potential of LLMs in mastering complex card games. We systematically assess the learning capabilities of LLMs across eight diverse card games, evaluating the impact of fine-tuning on high-quality gameplay data, and examining the models' ability to retain general capabilities while mastering these games. Our findings indicate that: (1) LLMs can approach the performance of strong game AIs through supervised fine-tuning on high-quality data, (2) LLMs can master multiple complex card games simultaneously, with performance augmentation for games with similar rules and conflicts for dissimilar ones, and (3) LLMs experience a decline in general capabilities when mastering complex games, but this decline can be mitigated by integrating a certain amount of general instruction data. The evaluation results demonstrate strong learning ability and versatility of LLMs.

**Link**: [arxiv](http://arxiv.org/abs/2509.01328v2),  [pdf](http://arxiv.org/pdf/2509.01328v2)

**Tags**: cs.CL 



### GAMA: A General Anonymizing Multi-Agent System for Privacy Preservation   Enhanced by Domain Rules and Disproof Method
**Authors**: Hailong Yang, Renhuo Zhao, Guanjin Wang, Zhaohong Deng

**Updated**: 2025-09-12T07:22:49Z

**Summary**: With the rapid advancement of Large Language Model (LLM), LLM-based agents exhibit exceptional abilities in understanding and generating natural language, facilitating human-like collaboration and information transmission in LLM-based Multi-Agent System (MAS). High-performance LLMs are often hosted on remote servers in public spaces. When tasks involve privacy data, MAS cannot securely utilize these LLMs without implementing privacy-preserving mechanisms. To address this challenge, we propose a General Anonymizing Multi-Agent system (GAMA), which divides the agents' workspace into private and public spaces and protects privacy through the anonymizing mechanism. In the private space, agents handle sensitive data, while in the public space, only anonymized data is utilized. GAMA incorporates two key modules to mitigate semantic loss caused by anonymization: Domain-Rule-based Knowledge Enhancement (DRKE) and Disproof-based Logic Enhancement (DLE). We evaluate GAMA on two public question-answering datasets: Trivia Creative Writing and Logic Grid Puzzle. The results demonstrate that GAMA has superior performance compared to the state-of-the-art models. To further assess its privacy-preserving capabilities, we designed two new datasets: Knowledge Privacy Preservation and Logic Privacy Preservation. The final results highlight GAMA's exceptional effectiveness in both task processing and privacy preservation.

**Link**: [arxiv](http://arxiv.org/abs/2509.10018v1),  [pdf](http://arxiv.org/pdf/2509.10018v1)

**Tags**: cs.AI 



### OneCAT: Decoder-Only Auto-Regressive Model for Unified Understanding and   Generation
**Authors**: Han Li, Xinyu Peng, Yaoming Wang, Zelin Peng, Xin Chen, Rongxiang Weng, Jingang Wang, Xunliang Cai, Wenrui Dai, Hongkai Xiong

**Updated**: 2025-09-12T07:12:41Z

**Summary**: We introduce OneCAT, a unified multimodal model that seamlessly integrates understanding, generation, and editing within a novel, pure decoder-only transformer architecture. Our framework uniquely eliminates the need for external components such as Vision Transformers (ViT) or vision tokenizer during inference, leading to significant efficiency gains, especially for high-resolution inputs. This is achieved through a modality-specific Mixture-of-Experts (MoE) structure trained with a single autoregressive (AR) objective, which also natively supports dynamic resolutions. Furthermore, we pioneer a multi-scale visual autoregressive mechanism within the Large Language Model (LLM) that drastically reduces decoding steps compared to diffusion-based methods while maintaining state-of-the-art performance. Our findings demonstrate the powerful potential of pure autoregressive modeling as a sufficient and elegant foundation for unified multimodal intelligence. As a result, OneCAT sets a new performance standard, outperforming existing open-source unified multimodal models across benchmarks for multimodal generation, editing, and understanding.

**Link**: [arxiv](http://arxiv.org/abs/2509.03498v2),  [pdf](http://arxiv.org/pdf/2509.03498v2)

**Tags**: cs.CV 



### Multi-Intent Recognition in Dialogue Understanding: A Comparison Between   Smaller Open-Source LLMs
**Authors**: Adnan Ahmad, Philine Kowol, Stefan Hillmann, Sebastian Möller

**Updated**: 2025-09-12T07:10:55Z

**Summary**: In this paper, we provide an extensive analysis of multi-label intent classification using Large Language Models (LLMs) that are open-source, publicly available, and can be run in consumer hardware. We use the MultiWOZ 2.1 dataset, a benchmark in the dialogue system domain, to investigate the efficacy of three popular open-source pre-trained LLMs, namely LLama2-7B-hf, Mistral-7B-v0.1, and Yi-6B. We perform the classification task in a few-shot setup, giving 20 examples in the prompt with some instructions. Our approach focuses on the differences in performance of these models across several performance metrics by methodically assessing these models on multi-label intent classification tasks. Additionally, we compare the performance of the instruction-based fine-tuning approach with supervised learning using the smaller transformer model BertForSequenceClassification as a baseline. To evaluate the performance of the models, we use evaluation metrics like accuracy, precision, and recall as well as micro, macro, and weighted F1 score. We also report the inference time, VRAM requirements, etc. The Mistral-7B-v0.1 outperforms two other generative models on 11 intent classes out of 14 in terms of F-Score, with a weighted average of 0.50. It also has relatively lower Humming Loss and higher Jaccard Similarity, making it the winning model in the few-shot setting. We find BERT based supervised classifier having superior performance compared to the best performing few-shot generative LLM. The study provides a framework for small open-source LLMs in detecting complex multi-intent dialogues, enhancing the Natural Language Understanding aspect of task-oriented chatbots.

**Link**: [arxiv](http://arxiv.org/abs/2509.10010v1),  [pdf](http://arxiv.org/pdf/2509.10010v1)

**Tags**: cs.CL cs.HC 



### Input-Time Scaling
**Authors**: Rapheal Huang, Weilong Guo

**Updated**: 2025-09-12T07:04:59Z

**Summary**: Current Large Language Models (LLMs) are usually post-trained on large-scale carefully curated datasets (data & training scaling) and doing reasoning in test time (inference time scaling). In this work, we present a new scaling paradigm, Input-Time Scaling, to complement previous scaling methods by putting resources on queries (input time). During training and testing, we utilize meta-knowledge from LLMs to refine inputs with different strategies. We also discover a new phenomenon, train-test co-design. It requires us to apply query strategies during training and testing as a whole. Only applying strategies on training or testing would seriously degrade the performance gained. We are also surprised to find that seemingly low data quality datasets can perform better. We can get the best performance even by adding irrelevant information to the queries, with randomly selected 1k examples from a minimally filtered dataset. These findings contradict the widely held inductive bias, "garbage in, garbage out". Curating datasets with seemingly high-quality data can even potentially limit the performance ceiling. In addition, models trained on more data with similar quality (15k VS 1k) perform worse, the intuition of simply scaling the size should also be carefully inspected. The good news is that our findings are compatible with the Less is More phenomenon. 1K examples are enough to invoke high-level reasoning ability. With experiments on Qwen2.5-32B-Instruct, we are able to reach SOTA performance among 32B models on AIME24(76.7%) and AIME25(76.7%) pass@1. We can further achieve AIME24(76.7%) and AIME25(80%) with a majority vote of three models. Starting from DeepSeek-R1-Distill-Qwen-32B, the result would be 90.0% on AIME24 and 80.0% on AIME25. To facilitate reproducibility and further research, we are working on open-source our datasets, data pipelines, evaluation results, and checkpoints.

**Link**: [arxiv](http://arxiv.org/abs/2508.13654v4),  [pdf](http://arxiv.org/pdf/2508.13654v4)

**Tags**: cs.LG cs.AI cs.CL 



### TUNI: Real-time RGB-T Semantic Segmentation with Unified Multi-Modal   Feature Extraction and Cross-Modal Feature Fusion
**Authors**: Xiaodong Guo, Tong Liu, Yike Li, Zi'ang Lin, Zhihong Deng

**Updated**: 2025-09-12T07:02:45Z

**Summary**: RGB-thermal (RGB-T) semantic segmentation improves the environmental perception of autonomous platforms in challenging conditions. Prevailing models employ encoders pre-trained on RGB images to extract features from both RGB and infrared inputs, and design additional modules to achieve cross-modal feature fusion. This results in limited thermal feature extraction and suboptimal cross-modal fusion, while the redundant encoders further compromises the model's real-time efficiency. To address the above issues, we propose TUNI, with an RGB-T encoder consisting of multiple stacked blocks that simultaneously perform multi-modal feature extraction and cross-modal fusion. By leveraging large-scale pre-training with RGB and pseudo-thermal data, the RGB-T encoder learns to integrate feature extraction and fusion in a unified manner. By slimming down the thermal branch, the encoder achieves a more compact architecture. Moreover, we introduce an RGB-T local module to strengthen the encoder's capacity for cross-modal local feature fusion. The RGB-T local module employs adaptive cosine similarity to selectively emphasize salient consistent and distinct local features across RGB-T modalities. Experimental results show that TUNI achieves competitive performance with state-of-the-art models on FMB, PST900 and CART, with fewer parameters and lower computational cost. Meanwhile, it achieves an inference speed of 27 FPS on a Jetson Orin NX, demonstrating its real-time capability in deployment. Codes are available at https://github.com/xiaodonguo/TUNI.

**Link**: [arxiv](http://arxiv.org/abs/2509.10005v1),  [pdf](http://arxiv.org/pdf/2509.10005v1)

**Tags**: cs.CV 



### Unsupervised Hallucination Detection by Inspecting Reasoning Processes
**Authors**: Ponhvoan Srey, Xiaobao Wu, Anh Tuan Luu

**Updated**: 2025-09-12T06:58:17Z

**Summary**: Unsupervised hallucination detection aims to identify hallucinated content generated by large language models (LLMs) without relying on labeled data. While unsupervised methods have gained popularity by eliminating labor-intensive human annotations, they frequently rely on proxy signals unrelated to factual correctness. This misalignment biases detection probes toward superficial or non-truth-related aspects, limiting generalizability across datasets and scenarios. To overcome these limitations, we propose IRIS, an unsupervised hallucination detection framework, leveraging internal representations intrinsic to factual correctness. IRIS prompts the LLM to carefully verify the truthfulness of a given statement, and obtain its contextualized embedding as informative features for training. Meanwhile, the uncertainty of each response is considered a soft pseudolabel for truthfulness. Experimental results demonstrate that IRIS consistently outperforms existing unsupervised methods. Our approach is fully unsupervised, computationally low cost, and works well even with few training data, making it suitable for real-time detection.

**Link**: [arxiv](http://arxiv.org/abs/2509.10004v1),  [pdf](http://arxiv.org/pdf/2509.10004v1)

**Tags**: cs.CL cs.AI 



### Service Function Chaining Architecture for Multi-hop Split Inference and   Learning
**Authors**: Takanori Hara, Masahiro Sasabe

**Updated**: 2025-09-12T06:52:39Z

**Summary**: Service Function Chaining (SFC) is a networking technique that ensures traffic traverses a predefined sequence of service functions, realizing arbitrary network services through dynamic and efficient communication paths. Inspired by this concept, we propose an SFC-based architecture for Multi-hop Split Inference (MSI), where split sub-models are interpreted as service functions and their composition forms a service chain representing the global model. By leveraging SFC, the proposed architecture dynamically establishes communication paths for split sub-models, ensuring efficient and adaptive execution. Furthermore, we extend this architecture to Multi-hop Split Learning (MSL) by applying SFC to the bidirectional communication required for training tasks. To realize the proposed architecture, we design Neural Service Functions (NSFs) to execute split sub-models as transparent TCP proxies and integrate them with Segment Routing over IPv6 (SRv6) and the extended Berkeley Packet Filter (eBPF)-based SFC proxy. This integration ensures efficient ML processing over dynamic routing while maintaining compatibility with existing applications. Evaluation results demonstrate that (1) the proposed architecture is feasible for both MSI and MSL; (2) it is particularly suitable for real-time inference in MSI scenarios with small mini-batch sizes; (3) it supports dynamic path reconfiguration, enabling adaptive responses to changing network conditions while minimizing the impact of control mechanisms on inference and learning processes.

**Link**: [arxiv](http://arxiv.org/abs/2509.10001v1),  [pdf](http://arxiv.org/pdf/2509.10001v1)

**Tags**: cs.NI 



### Polish-English medical knowledge transfer: A new benchmark and results
**Authors**: Łukasz Grzybowski, Jakub Pokrywka, Michał Ciesiółka, Jeremi I. Kaczmarek, Marek Kubis

**Updated**: 2025-09-12T06:49:21Z

**Summary**: Large Language Models (LLMs) have demonstrated significant potential in handling specialized tasks, including medical problem-solving. However, most studies predominantly focus on English-language contexts. This study introduces a novel benchmark dataset based on Polish medical licensing and specialization exams (LEK, LDEK, PES) taken by medical doctor candidates and practicing doctors pursuing specialization. The dataset was web-scraped from publicly available resources provided by the Medical Examination Center and the Chief Medical Chamber. It comprises over 24,000 exam questions, including a subset of parallel Polish-English corpora, where the English portion was professionally translated by the examination center for foreign candidates. By creating a structured benchmark from these existing exam questions, we systematically evaluate state-of-the-art LLMs, including general-purpose, domain-specific, and Polish-specific models, and compare their performance against human medical students. Our analysis reveals that while models like GPT-4o achieve near-human performance, significant challenges persist in cross-lingual translation and domain-specific understanding. These findings underscore disparities in model performance across languages and medical specialties, highlighting the limitations and ethical considerations of deploying LLMs in clinical practice.

**Link**: [arxiv](http://arxiv.org/abs/2412.00559v2),  [pdf](http://arxiv.org/pdf/2412.00559v2)

**Tags**: cs.CL cs.AI 



### Finite Scalar Quantization Enables Redundant and Transmission-Robust   Neural Audio Compression at Low Bit-rates
**Authors**: Harry Julian, Rachel Beeson, Lohith Konathala, Johanna Ulin, Jiameng Gao

**Updated**: 2025-09-12T06:43:25Z

**Summary**: Neural Audio Codecs (NACs) have become increasingly adopted in speech processing tasks due to their excellent rate-distortion performance and compatibility with Large Language Models (LLMs) as discrete feature representations for audio generation. While most existing codecs rely on Residual Vector Quantization (RVQ), Finite Scalar Quantization (FSQ) has recently emerged as a compelling alternative that simplifies training and natively supports single codebooks. We introduce NeuCodec, an FSQ-based NAC, and show that FSQ encodes baked-in redundancy which produces an encoding which is robust when transmitted through noisy channels. First, through an encoder distillation experiment, we show that two different encoders can learn to encode identical audio into vastly different code sequences whilst maintaining comparable reconstruction quality with the same quantizer and decoder. Second, we demonstrate that FSQ has vastly superior bit-level perturbation robustness by comparing the performance of RVQ and FSQ codecs when simulating the transmission of code sequences through a noisy channel.

**Link**: [arxiv](http://arxiv.org/abs/2509.09550v2),  [pdf](http://arxiv.org/pdf/2509.09550v2)

**Tags**: cs.SD cs.LG 



## Keyword: LLM Deployment 
 ### DeepDive: Advancing Deep Search Agents with Knowledge Graphs and   Multi-Turn RL
**Authors**: Rui Lu, Zhenyu Hou, Zihan Wang, Hanchen Zhang, Xiao Liu, Yujiang Li, Shi Feng, Jie Tang, Yuxiao Dong

**Updated**: 2025-09-12T17:52:35Z

**Summary**: Augmenting large language models (LLMs) with browsing tools substantially improves their potential as deep search agents to solve complex, real-world tasks. Yet, open LLMs still perform poorly in such settings due to limited long-horizon reasoning capacity with browsing tools and the lack of sufficiently difficult supervised data. To address these challenges, we present DeepDive to advance deep search agents. First, we propose a strategy to automatically synthesize complex, difficult, and hard-to-find questions from open knowledge graphs. Second, we apply end-to-end multi-turn reinforcement learning (RL) to enhance LLMs' long-horizon reasoning with deep search. Experiments show that DeepDive-32B achieves a new open-source competitive result on BrowseComp, outperforming WebSailor, DeepSeek-R1-Browse, and Search-o1. We demonstrate that multi-turn RL training improves deep search ability and significantly contributes to the performance improvements across multiple benchmarks. We observe that DeepDive enables test-time scaling of tool calls and parallel sampling. All datasets, models, and code are publicly available at https://github.com/THUDM/DeepDive.

**Link**: [arxiv](http://arxiv.org/abs/2509.10446v1),  [pdf](http://arxiv.org/pdf/2509.10446v1)

**Tags**: cs.CL 



### RefactorCoderQA: Benchmarking LLMs for Multi-Domain Coding Question   Solutions in Cloud and Edge Deployment
**Authors**: Shadikur Rahman, Aroosa Hameed, Gautam Srivastava, Syed Muhammad Danish

**Updated**: 2025-09-12T17:44:22Z

**Summary**: To optimize the reasoning and problem-solving capabilities of Large Language Models (LLMs), we propose a novel cloud-edge collaborative architecture that enables a structured, multi-agent prompting framework. This framework comprises three specialized components: GuideLLM, a lightweight model deployed at the edge to provide methodological guidance; SolverLLM, a more powerful model hosted in the cloud responsible for generating code solutions; and JudgeLLM, an automated evaluator for assessing solution correctness and quality. To evaluate and demonstrate the effectiveness of this architecture in realistic settings, we introduce RefactorCoderQA, a comprehensive benchmark designed to evaluate and enhance the performance of Large Language Models (LLMs) across multi-domain coding tasks. Motivated by the limitations of existing benchmarks, RefactorCoderQA systematically covers various technical domains, including Software Engineering, Data Science, Machine Learning, and Natural Language Processing, using authentic coding challenges from Stack Overflow. Extensive experiments reveal that our fine-tuned model, RefactorCoder-MoE, achieves state-of-the-art performance, significantly outperforming leading open-source and commercial baselines with an overall accuracy of 76.84%. Human evaluations further validate the interpretability, accuracy, and practical relevance of the generated solutions. In addition, we evaluate system-level metrics, such as throughput and latency, to gain deeper insights into the performance characteristics and trade-offs of the proposed architecture.

**Link**: [arxiv](http://arxiv.org/abs/2509.10436v1),  [pdf](http://arxiv.org/pdf/2509.10436v1)

**Tags**: cs.CL 



### LMAR: Language Model Augmented Retriever for Domain-specific Knowledge   Indexing
**Authors**: Yao Zhao, Yantian Ding, Zhiyue Zhang, Dapeng Yao, Yanxun Xu

**Updated**: 2025-09-12T17:32:41Z

**Summary**: Retrieval Augmented Generation (RAG) systems often struggle with domain-specific knowledge due to performance deterioration of pre-trained embeddings and prohibitive computational costs of large language model (LLM)-based retrievers. While fine-tuning data augmentation embedding models offers a promising direction, its effectiveness is limited by the need for high-quality training data and reliable chunking strategies that preserve contextual integrity. We propose LMAR (Language Model Augmented Retriever), a model-agnostic framework that addresses these challenges by combining LLM-guided data synthesis with contrastive embedding adaptation and efficient text clustering. LMAR consists of a two-stage pipeline: (1) Triplet sampling and synthetic data augmentation, where LLMs act as both labeler and validator to ensure high-fidelity supervision throughout the pipeline. Experimental results across multiple domain-specific benchmark datasets demonstrate that LMAR outperforms multiple baseline models, while maintaining moderate hardware requirements and low latency. Its model-agnostic nature further enables seamless integration with emerging RAG architectures and text embedding models, ensuring continual improvements without redesigning the pipeline. These results highlight LMAR as a practical and cost-effective solution for scalable domain-specific adaptation.

**Link**: [arxiv](http://arxiv.org/abs/2508.05672v2),  [pdf](http://arxiv.org/pdf/2508.05672v2)

**Tags**: cs.IR cs.AI 



### My Favorite Streamer is an LLM: Discovering, Bonding, and Co-Creating in   AI VTuber Fandom
**Authors**: Jiayi Ye, Chaoran Chen, Yue Huang, Yanfang Ye, Toby Jia-Jun Li, Xiangliang Zhang

**Updated**: 2025-09-12T17:31:40Z

**Summary**: AI VTubers, where the performer is not human but algorithmically generated, introduce a new context for fandom. While human VTubers have been substantially studied for their cultural appeal, parasocial dynamics, and community economies, little is known about how audiences engage with their AI counterparts. To address this gap, we present a qualitative study of Neuro-sama, the most prominent AI VTuber. Our findings show that engagement is anchored in active co-creation: audiences are drawn by the AI's unpredictable yet entertaining interactions, cement loyalty through collective emotional events that trigger anthropomorphic projection, and sustain attachment via the AI's consistent persona. Financial support emerges not as a reward for performance but as a participatory mechanism for shaping livestream content, establishing a resilient fan economy built on ongoing interaction. These dynamics reveal how AI Vtuber fandom reshapes fan-creator relationships and offer implications for designing transparent and sustainable AI-mediated communities.

**Link**: [arxiv](http://arxiv.org/abs/2509.10427v1),  [pdf](http://arxiv.org/pdf/2509.10427v1)

**Tags**: cs.HC 



### Bridging the Gap: A Framework for Real-World Video Deepfake Detection   via Social Network Compression Emulation
**Authors**: Andrea Montibeller, Dasara Shullani, Daniele Baracchi, Alessandro Piva, Giulia Boato

**Updated**: 2025-09-12T17:29:48Z

**Summary**: The growing presence of AI-generated videos on social networks poses new challenges for deepfake detection, as detectors trained under controlled conditions often fail to generalize to real-world scenarios. A key factor behind this gap is the aggressive, proprietary compression applied by platforms like YouTube and Facebook, which launder low-level forensic cues. However, replicating these transformations at scale is difficult due to API limitations and data-sharing constraints. For these reasons, we propose a first framework that emulates the video sharing pipelines of social networks by estimating compression and resizing parameters from a small set of uploaded videos. These parameters enable a local emulator capable of reproducing platform-specific artifacts on large datasets without direct API access. Experiments on FaceForensics++ videos shared via social networks demonstrate that our emulated data closely matches the degradation patterns of real uploads. Furthermore, detectors fine-tuned on emulated videos achieve comparable performance to those trained on actual shared media. Our approach offers a scalable and practical solution for bridging the gap between lab-based training and real-world deployment of deepfake detectors, particularly in the underexplored domain of compressed video content.

**Link**: [arxiv](http://arxiv.org/abs/2508.08765v2),  [pdf](http://arxiv.org/pdf/2508.08765v2)

**Tags**: cs.CV cs.AI 



### Mutual Information Tracks Policy Coherence in Reinforcement Learning
**Authors**: Cameron Reid, Wael Hafez, Amirhossein Nazeri

**Updated**: 2025-09-12T17:24:20Z

**Summary**: Reinforcement Learning (RL) agents deployed in real-world environments face degradation from sensor faults, actuator wear, and environmental shifts, yet lack intrinsic mechanisms to detect and diagnose these failures. We present an information-theoretic framework that reveals both the fundamental dynamics of RL and provides practical methods for diagnosing deployment-time anomalies. Through analysis of state-action mutual information patterns in a robotic control task, we first demonstrate that successful learning exhibits characteristic information signatures: mutual information between states and actions steadily increases from 0.84 to 2.83 bits (238% growth) despite growing state entropy, indicating that agents develop increasingly selective attention to task-relevant patterns. Intriguingly, states, actions and next states joint mutual information, MI(S,A;S'), follows an inverted U-curve, peaking during early learning before declining as the agent specializes suggesting a transition from broad exploration to efficient exploitation. More immediately actionable, we show that information metrics can differentially diagnose system failures: observation-space, i.e., states noise (sensor faults) produces broad collapses across all information channels with pronounced drops in state-action coupling, while action-space noise (actuator faults) selectively disrupts action-outcome predictability while preserving state-action relationships. This differential diagnostic capability demonstrated through controlled perturbation experiments enables precise fault localization without architectural modifications or performance degradation. By establishing information patterns as both signatures of learning and diagnostic for system health, we provide the foundation for adaptive RL systems capable of autonomous fault detection and policy adjustment based on information-theoretic principles.

**Link**: [arxiv](http://arxiv.org/abs/2509.10423v1),  [pdf](http://arxiv.org/pdf/2509.10423v1)

**Tags**: cs.AI cs.LG cs.RO 



### Direct Judgement Preference Optimization
**Authors**: Peifeng Wang, Austin Xu, Yilun Zhou, Caiming Xiong, Shafiq Joty

**Updated**: 2025-09-12T17:21:39Z

**Summary**: Auto-evaluation is crucial for assessing response quality and offering feedback for model development. Recent studies have explored training large language models (LLMs) as generative judges to evaluate and critique other models' outputs. In this work, we investigate the idea of learning from both positive and negative data with preference optimization to enhance the evaluation capabilities of LLM judges across an array of different use cases. We achieve this by employing three approaches to collect the preference pairs for different use cases, each aimed at improving our generative judge from a different perspective. Our comprehensive study over a wide range of benchmarks demonstrates the effectiveness of our method. In particular, our generative judge achieves the best performance on 10 out of 13 benchmarks, outperforming strong baselines like GPT-4o and specialized judge models. Further analysis show that our judge model robustly counters inherent biases such as position and length bias, flexibly adapts to any evaluation protocol specified by practitioners, and provides helpful language feedback for improving downstream generator models.

**Link**: [arxiv](http://arxiv.org/abs/2409.14664v3),  [pdf](http://arxiv.org/pdf/2409.14664v3)

**Tags**: cs.CL 



### Are LLMs Better than Reported? Detecting Label Errors and Mitigating   Their Effect on Model Performance
**Authors**: Omer Nahum, Nitay Calderon, Orgad Keller, Idan Szpektor, Roi Reichart

**Updated**: 2025-09-12T17:18:27Z

**Summary**: NLP benchmarks rely on standardized datasets for training and evaluating models and are crucial for advancing the field. Traditionally, expert annotations ensure high-quality labels; however, the cost of expert annotation does not scale well with the growing demand for larger datasets required by modern models. While crowd-sourcing provides a more scalable solution, it often comes at the expense of annotation precision and consistency. Recent advancements in large language models (LLMs) offer new opportunities to enhance the annotation process, particularly for detecting label errors in existing datasets. In this work, we consider the recent approach of LLM-as-a-judge, leveraging an ensemble of LLMs to flag potentially mislabeled examples. We conduct a case study on four factual consistency datasets from the TRUE benchmark, spanning diverse NLP tasks, and on SummEval, which uses Likert-scale ratings of summary quality across multiple dimensions. We empirically analyze the labeling quality of existing datasets and compare expert, crowd-sourced, and LLM-based annotations in terms of the agreement, label quality, and efficiency, demonstrating the strengths and limitations of each annotation method. Our findings reveal a substantial number of label errors, which, when corrected, induce a significant upward shift in reported model performance. This suggests that many of the LLMs' so-called mistakes are due to label errors rather than genuine model failures. Additionally, we discuss the implications of mislabeled data and propose methods to mitigate them in training to improve performance.

**Link**: [arxiv](http://arxiv.org/abs/2410.18889v2),  [pdf](http://arxiv.org/pdf/2410.18889v2)

**Tags**: cs.CL 



### Parallel-R1: Towards Parallel Thinking via Reinforcement Learning
**Authors**: Tong Zheng, Hongming Zhang, Wenhao Yu, Xiaoyang Wang, Runpeng Dai, Rui Liu, Huiwen Bao, Chengsong Huang, Heng Huang, Dong Yu

**Updated**: 2025-09-12T17:15:56Z

**Summary**: Parallel thinking has emerged as a novel approach for enhancing the reasoning capabilities of large language models (LLMs) by exploring multiple reasoning paths concurrently. However, activating such capabilities through training remains challenging, as existing methods predominantly rely on supervised fine-tuning (SFT) over synthetic data, which encourages teacher-forced imitation rather than exploration and generalization. Different from them, we propose \textbf{Parallel-R1}, the first reinforcement learning (RL) framework that enables parallel thinking behaviors for complex real-world reasoning tasks. Our framework employs a progressive curriculum that explicitly addresses the cold-start problem in training parallel thinking with RL. We first use SFT on prompt-generated trajectories from easier tasks to instill the parallel thinking ability, then transition to RL to explore and generalize this skill on harder problems. Experiments on various math benchmarks, including MATH, AMC23, and AIME, show that Parallel-R1 successfully instills parallel thinking, leading to 8.4% accuracy improvements over the sequential thinking model trained directly on challenging tasks with RL. Further analysis reveals a clear shift in the model's thinking behavior: at an early stage, it uses parallel thinking as an exploration strategy, while in a later stage, it uses the same capability for multi-perspective verification. Most significantly, we validate parallel thinking as a \textbf{mid-training exploration scaffold}, where this temporary exploratory phase unlocks a higher performance ceiling after RL, yielding a 42.9% improvement over the baseline on AIME25. Our model, data, and code will be open-source at https://github.com/zhengkid/Parallel-R1.

**Link**: [arxiv](http://arxiv.org/abs/2509.07980v2),  [pdf](http://arxiv.org/pdf/2509.07980v2)

**Tags**: cs.CL 



### Compressed Video Quality Enhancement: Classifying and Benchmarking over   Standards
**Authors**: Xiem HoangVan, Dang BuiDinh, Sang NguyenQuang, Wen-Hsiao Peng

**Updated**: 2025-09-12T16:58:20Z

**Summary**: Compressed video quality enhancement (CVQE) is crucial for improving user experience with lossy video codecs like H.264/AVC, H.265/HEVC, and H.266/VVC. While deep learning based CVQE has driven significant progress, existing surveys still suffer from limitations: lack of systematic classification linking methods to specific standards and artifacts, insufficient comparative analysis of architectural paradigms across coding types, and underdeveloped benchmarking practices. To address these gaps, this paper presents three key contributions. First, it introduces a novel taxonomy classifying CVQE methods across architectural paradigms, coding standards, and compressed-domain feature utilization. Second, it proposes a unified benchmarking framework integrating modern compression protocols and standard test sequences for fair multi-criteria evaluation. Third, it provides a systematic analysis of the critical trade-offs between reconstruction performance and computational complexity observed in state-of-the-art methods and highlighting promising directions for future research. This comprehensive review aims to establish a foundation for consistent assessment and informed model selection in CVQE research and deployment.

**Link**: [arxiv](http://arxiv.org/abs/2509.10407v1),  [pdf](http://arxiv.org/pdf/2509.10407v1)

**Tags**: cs.CV 



### Developer-LLM Conversations: An Empirical Study of Interactions and   Generated Code Quality
**Authors**: Suzhen Zhong, Ying Zou, Bram Adams

**Updated**: 2025-09-12T16:52:49Z

**Summary**: Large Language Models (LLMs) are becoming integral to modern software development workflows, assisting developers with code generation, API explanation, and iterative problem-solving through natural language conversations. Despite widespread adoption, there is limited understanding of how developers interact with LLMs in practice and how these conversational dynamics influence task outcomes, code quality, and software engineering workflows. To address this, we leverage CodeChat, a large dataset comprising 82,845 real-world developer-LLM conversations, containing 368,506 code snippets generated across over 20 programming languages, derived from the WildChat dataset. We find that LLM responses are substantially longer than developer prompts, with a median token-length ratio of 14:1. Multi-turn conversations account for 68% of the dataset and often evolve due to shifting requirements, incomplete prompts, or clarification requests. Topic analysis identifies web design (9.6% of conversations) and neural network training (8.7% of conversations) as the most frequent LLM-assisted tasks. Evaluation across five languages (i.e., Python, JavaScript, C++, Java, and C#) reveals prevalent and language-specific issues in LLM-generated code: generated Python and JavaScript code often include undefined variables (83.4% and 75.3% of code snippets, respectively); Java code lacks required comments (75.9%); C++ code frequently omits headers (41.1%) and C# code shows unresolved namespaces (49.2%). During a conversation, syntax and import errors persist across turns; however, documentation quality in Java improves by up to 14.7%, and import handling in Python improves by 3.7% over 5 turns. Prompts that point out mistakes in code generated in prior turns and explicitly request a fix are most effective for resolving errors.

**Link**: [arxiv](http://arxiv.org/abs/2509.10402v1),  [pdf](http://arxiv.org/pdf/2509.10402v1)

**Tags**: cs.SE D.2.0; D.2.7 



### RecoWorld: Building Simulated Environments for Agentic Recommender   Systems
**Authors**: Fei Liu, Xinyu Lin, Hanchao Yu, Mingyuan Wu, Jianyu Wang, Qiang Zhang, Zhuokai Zhao, Yinglong Xia, Yao Zhang, Weiwei Li, Mingze Gao, Qifan Wang, Lizhu Zhang, Benyu Zhang, Xiangjun Fan

**Updated**: 2025-09-12T16:44:34Z

**Summary**: We present RecoWorld, a blueprint for building simulated environments tailored to agentic recommender systems. Such environments give agents a proper training space where they can learn from errors without impacting real users. RecoWorld distinguishes itself with a dual-view architecture: a simulated user and an agentic recommender engage in multi-turn interactions aimed at maximizing user retention. The user simulator reviews recommended items, updates its mindset, and when sensing potential user disengagement, generates reflective instructions. The agentic recommender adapts its recommendations by incorporating these user instructions and reasoning traces, creating a dynamic feedback loop that actively engages users. This process leverages the exceptional reasoning capabilities of modern LLMs. We explore diverse content representations within the simulator, including text-based, multimodal, and semantic ID modeling, and discuss how multi-turn RL enables the recommender to refine its strategies through iterative interactions. RecoWorld also supports multi-agent simulations, allowing creators to simulate the responses of targeted user populations. It marks an important first step toward recommender systems where users and agents collaboratively shape personalized information streams. We envision new interaction paradigms where "user instructs, recommender responds," jointly optimizing user retention and engagement.

**Link**: [arxiv](http://arxiv.org/abs/2509.10397v1),  [pdf](http://arxiv.org/pdf/2509.10397v1)

**Tags**: cs.IR 



### Inpainting-Guided Policy Optimization for Diffusion Large Language   Models
**Authors**: Siyan Zhao, Mengchen Liu, Jing Huang, Miao Liu, Chenyu Wang, Bo Liu, Yuandong Tian, Guan Pang, Sean Bell, Aditya Grover, Feiyu Chen

**Updated**: 2025-09-12T16:44:31Z

**Summary**: Masked diffusion large language models (dLLMs) are emerging as promising alternatives to autoregressive LLMs, offering competitive performance while supporting unique generation capabilities such as inpainting. We explore how inpainting can inform RL algorithm design for dLLMs. Aligning LLMs with reinforcement learning faces an exploration challenge: sparse reward signals and sample waste when models fail to discover correct solutions. While this inefficiency affects LLMs broadly, dLLMs offer a distinctive opportunity--their inpainting ability can guide exploration. We introduce IGPO (Inpainting Guided Policy Optimization), an RL framework that strategically inserts partial ground-truth reasoning traces during online sampling. Unlike providing full solutions, inpainting steers exploration toward promising trajectory spaces while preserving self-generated reasoning, bridging supervised fine-tuning and reinforcement learning. We apply IGPO to group-based optimization methods such as GRPO, where exploration failures cause zero advantages and gradients. IGPO restores meaningful gradients while improving sample efficiency. We also propose supervised fine-tuning on synthetically rewritten concise traces that better align with dLLM generation patterns. With additional techniques including entropy-based filtering, our training recipe yields substantial gains across three mathematical benchmarks--GSM8K, Math500, and AMC--achieving new state-of-the-art results for full-attention masked dLLMs.

**Link**: [arxiv](http://arxiv.org/abs/2509.10396v1),  [pdf](http://arxiv.org/pdf/2509.10396v1)

**Tags**: cs.LG 



### Cut Costs, Not Accuracy: LLM-Powered Data Processing with Guarantees
**Authors**: Sepanta Zeighami, Shreya Shankar, Aditya Parameswaran

**Updated**: 2025-09-12T16:30:38Z

**Summary**: Large Language Models (LLMs) are being increasingly used as a building block in data systems to process large text datasets. To do so, LLM model providers offer multiple LLMs with different sizes, spanning various cost-quality trade-offs when processing text at scale. Top-of-the-line LLMs (e.g., GPT-4o, Claude Sonnet) operate with high accuracy but are prohibitively expensive when processing many records. To avoid high costs, more affordable but lower quality LLMs (e.g., GPT-4o-mini, Claude Haiku) can be used to process records, but we need to ensure that the overall accuracy does not deviate substantially from that of the top-of-the-line LLMs. The model cascade framework provides a blueprint to manage this trade-off, by using the confidence of LLMs in their output (e.g., log-probabilities) to decide on which records to use the affordable LLM. However, existing solutions following this framework provide only marginal cost savings and weak theoretical guarantees because of poor estimation of the quality of the affordable LLM's outputs. We present BARGAIN, a method that judiciously uses affordable LLMs in data processing to significantly reduce cost while providing strong theoretical guarantees on the solution quality. BARGAIN employs a novel adaptive sampling strategy and statistical estimation procedure that uses data and task characteristics and builds on recent statistical tools to make accurate estimations with tight theoretical guarantees. Variants of BARGAIN can support guarantees on accuracy, precision, or recall of the output. Experimental results across 8 real-world datasets show that BARGAIN reduces cost, on average, by up to 86% more than state-of-the-art, while providing stronger theoretical guarantees on accuracy of output, with similar gains when guaranteeing a desired level of precision or recall.

**Link**: [arxiv](http://arxiv.org/abs/2509.02896v2),  [pdf](http://arxiv.org/pdf/2509.02896v2)

**Tags**: cs.DB cs.AI 



### Dropping Experts, Recombining Neurons: Retraining-Free Pruning for   Sparse Mixture-of-Experts LLMs
**Authors**: Yixiao Zhou, Ziyu Zhao, Dongzhou Cheng, zhiliang wu, Jie Gui, Yi Yang, Fei Wu, Yu Cheng, Hehe Fan

**Updated**: 2025-09-12T16:09:39Z

**Summary**: Sparse Mixture-of-Experts (SMoE) architectures are widely used in large language models (LLMs) due to their computational efficiency. However, though only a few experts are activated for each token, SMoE still requires loading all expert parameters, leading to high memory usage and challenges in deployment. Previous work has tried to reduce the overhead by pruning and merging experts, but primarily focused on expert-level operations, leaving neuron-level structure underexplored. We propose DERN (Dropping Experts, Recombining Neurons), a task-agnostic and retraining-free framework for expert pruning and reconstruction. We observe that experts are often misaligned and contain semantic conflicts at the neuron level, which poses challenges for direct merging. To solve this, DERN works in three steps: it first prunes redundant experts using router statistics; then it decomposes them into neuron-level expert segments, assigning each segment to its most compatible retained expert; and finally, it merges segments within each retained expert to build a compact representation. Experiments on Mixtral, Qwen, and DeepSeek SMoE models show that DERN improves performance by more than 5% on commonsense reasoning and MMLU benchmarks under 50% expert sparsity, without extra training. It also greatly reduces the number of experts and memory usage, making SMoE LLMs easier to deploy in practice.

**Link**: [arxiv](http://arxiv.org/abs/2509.10377v1),  [pdf](http://arxiv.org/pdf/2509.10377v1)

**Tags**: cs.CL 



### MCBP: A Memory-Compute Efficient LLM Inference Accelerator Leveraging   Bit-Slice-enabled Sparsity and Repetitiveness
**Authors**: Huizheng Wang, Zichuan Wang, Zhiheng Yue, Yousheng Long, Taiquan Wei, Jianxun Yang, Yang Wang, Chao Li, Shaojun Wei, Yang Hu, Shouyi Yin

**Updated**: 2025-09-12T16:05:27Z

**Summary**: Large language models (LLMs) face significant inference latency due to inefficiencies in GEMM operations, weight access, and KV cache access, especially in real-time scenarios. This highlights the need for a versatile compute-memory efficient accelerator. Unfortunately, existing Transformer accelerators struggle to address both aspects simultaneously, as they focus on value-level processing, missing fine-grained opportunities to optimize computation and memory collaboratively. This paper introduces MCBP, a bit-grained compute-memory efficient algorithm-hardware co-design that leverages bit-slice (BS) enabled repetitiveness and sparsity to accelerate LLM inference. MCBP features three key innovations: 1) BS-repetitiveness-enabled computation reduction (BRCR), which eliminates redundant GEMM computations via leveraging redundancy hidden among BS vectors; 2) BS-sparsity-enabled two-state coding (BSTC), which reduces weight access via exploiting significant sparsity in high-order bit-slice weight; 3) Bit-grained progressive prediction (BGPP), which reduces KV cache access by leveraging early-termination-based bit-grained prediction. These techniques, supported by custom accelerator designs, effectively alleviate the burden in GEMM, weight access, and KV cache access. Extensive experiments on 26 benchmarks show that MCBP achieves 9.43x speed up and 31.1x higher energy efficiency than Nvidia A100 GPU. Compared to SOTA Transformer accelerators, MCBP achieves 35x, 5.2x and 3.2x energy saving than Spatten, FACT and SOFA, respectively.

**Link**: [arxiv](http://arxiv.org/abs/2509.10372v1),  [pdf](http://arxiv.org/pdf/2509.10372v1)

**Tags**: cs.AR 



### Characterizing the Efficiency of Distributed Training: A Power,   Performance, and Thermal Perspective
**Authors**: Seokjin Go, Joongun Park, Spandan More, Hanjiang Wu, Irene Wang, Aaron Jezghani, Tushar Krishna, Divya Mahajan

**Updated**: 2025-09-12T16:05:07Z

**Summary**: The rapid scaling of Large Language Models (LLMs) has pushed training workloads far beyond the limits of single-node analysis, demanding a deeper understanding of how these models behave across large-scale, multi-GPU systems. In this paper, we present a comprehensive characterization of LLM training across diverse real-world workloads and hardware platforms, including NVIDIA H100/H200 and AMD MI250 GPUs. We analyze dense and sparse models under various parallelism strategies -- tensor, pipeline, data, and expert -- and evaluate their effects on hardware utilization, power consumption, and thermal behavior. We further evaluate the effectiveness of optimizations such as activation recomputation and compute-communication overlap. Our findings show that performance is not determined solely by scaling hardware capacity. Scale-up systems with fewer, higher-memory GPUs can outperform scale-out systems in communication-bound regimes, but only under carefully tuned configurations; in other cases, scale-out deployments achieve superior throughput. We also show that certain parallelism combinations, such as tensor with pipeline, lead to bandwidth underutilization due to inefficient data chunking, while increasing microbatch sizes beyond a certain point induces bursty execution and peak power excursions that worsen thermal throttling. These insights reveal how training performance is shaped by complex interactions between hardware, system topology, and model execution. We conclude by offering recommendations for system and hardware design to improve the scalability and reliability of future LLM systems and workloads. The source code of this project is available at https://github.com/sitar-lab/CharLLM-PPT.

**Link**: [arxiv](http://arxiv.org/abs/2509.10371v1),  [pdf](http://arxiv.org/pdf/2509.10371v1)

**Tags**: cs.DC cs.LG 



### Efficient Learned Image Compression Through Knowledge Distillation
**Authors**: Fabien Allemand, Attilio Fiandrotti, Sumanta Chaudhuri, Alaa Eddine Mazouz

**Updated**: 2025-09-12T15:59:55Z

**Summary**: Learned image compression sits at the intersection of machine learning and image processing. With advances in deep learning, neural network-based compression methods have emerged. In this process, an encoder maps the image to a low-dimensional latent space, which is then quantized, entropy-coded into a binary bitstream, and transmitted to the receiver. At the receiver end, the bitstream is entropy-decoded, and a decoder reconstructs an approximation of the original image. Recent research suggests that these models consistently outperform conventional codecs. However, they require significant processing power, making them unsuitable for real-time use on resource-constrained platforms, which hinders their deployment in mainstream applications. This study aims to reduce the resource requirements of neural networks used for image compression by leveraging knowledge distillation, a training paradigm where smaller neural networks, partially trained on the outputs of larger, more complex models, can achieve better performance than when trained independently. Our work demonstrates that knowledge distillation can be effectively applied to image compression tasks: i) across various architecture sizes, ii) to achieve different image quality/bit rate tradeoffs, and iii) to save processing and energy resources. This approach introduces new settings and hyperparameters, and future research could explore the impact of different teacher models, as well as alternative loss functions. Knowledge distillation could also be extended to transformer-based models. The code is publicly available at: https://github.com/FABallemand/PRIM .

**Link**: [arxiv](http://arxiv.org/abs/2509.10366v1),  [pdf](http://arxiv.org/pdf/2509.10366v1)

**Tags**: cs.CV 



### UIO-LLMs: Unbiased Incremental Optimization for Long-Context LLMs
**Authors**: Wenhao Li, Mingbao Lin, Yunshan Zhong, Shuicheng Yan, Rongrong Ji

**Updated**: 2025-09-12T15:39:00Z

**Summary**: Managing long texts is challenging for large language models (LLMs) due to limited context window sizes. This study introduces UIO-LLMs, an unbiased incremental optimization approach for memory-enhanced transformers under long-context settings. We initially conceptualize the process as a streamlined encoder-decoder framework where the weights-shared encoder and decoder respectively encapsulate a context segment into memories and leverage these memories to predict outputs of the subsequent segment. Subsequently, by treating our memory-enhanced transformers as fully-connected recurrent neural networks (RNNs), we refine the training process using the Truncated Backpropagation Through Time (TBPTT) algorithm, which incorporates innovative incremental optimization techniques. These techniques not only diminish time complexity but also address the bias in gradient computation through an unbiased optimization process. UIO-LLMs successfully handle long context, such as extending the context window of Llama2-7b-chat from 4K to 100K tokens with minimal 2% additional parameters, while keeping the inference cost nearly linear as context length increases.

**Link**: [arxiv](http://arxiv.org/abs/2406.18173v3),  [pdf](http://arxiv.org/pdf/2406.18173v3)

**Tags**: cs.CL 



### Multi-pathology Chest X-ray Classification with Rejection Mechanisms
**Authors**: Yehudit Aperstein, Amit Tzahar, Alon Gottlib, Tal Verber, Ravit Shagan Damti, Alexander Apartsin

**Updated**: 2025-09-12T15:36:26Z

**Summary**: Overconfidence in deep learning models poses a significant risk in high-stakes medical imaging tasks, particularly in multi-label classification of chest X-rays, where multiple co-occurring pathologies must be detected simultaneously. This study introduces an uncertainty-aware framework for chest X-ray diagnosis based on a DenseNet-121 backbone, enhanced with two selective prediction mechanisms: entropy-based rejection and confidence interval-based rejection. Both methods enable the model to abstain from uncertain predictions, improving reliability by deferring ambiguous cases to clinical experts. A quantile-based calibration procedure is employed to tune rejection thresholds using either global or class-specific strategies. Experiments conducted on three large public datasets (PadChest, NIH ChestX-ray14, and MIMIC-CXR) demonstrate that selective rejection improves the trade-off between diagnostic accuracy and coverage, with entropy-based rejection yielding the highest average AUC across all pathologies. These results support the integration of selective prediction into AI-assisted diagnostic workflows, providing a practical step toward safer, uncertainty-aware deployment of deep learning in clinical settings.

**Link**: [arxiv](http://arxiv.org/abs/2509.10348v1),  [pdf](http://arxiv.org/pdf/2509.10348v1)

**Tags**: eess.IV cs.CV cs.LG 



### Trusted Repeater Placement in QKD-enabled Optical Networks
**Authors**: Arup Kumar Marik, Basabdatta Palit, Sadananda Behera

**Updated**: 2025-09-12T15:19:44Z

**Summary**: Quantum Key Distribution (QKD) provides information-theoretic security, but is limited by distance in optical networks, thereby requiring repeater nodes to extend coverage. Existing works usually assume all repeater nodes and associated Key Management Servers (KMSs) to be Trusted Repeater Nodes (TRNs), while ignoring risks from software exploits and insider threats. In this paper, we propose a reliability-aware TRN placement framework for metro optical networks, which assigns each node a trust score and integrates it into the Dijkstra algorithm via weighted links. We then rank the nodes using a composite score, which is a weighted combination of betweenness centrality and eigenvector centrality to enable a secure and scalable TRN deployment. Simulation results on a reference topology show that our method covers 10.77% more shortest paths compared to traditional metrics like degree centrality, using the same number (around eight) of TRNs, making it suitable for TRN selection to maximize secure connectivity.

**Link**: [arxiv](http://arxiv.org/abs/2509.10338v1),  [pdf](http://arxiv.org/pdf/2509.10338v1)

**Tags**: cs.NI 



### I-Segmenter: Integer-Only Vision Transformer for Efficient Semantic   Segmentation
**Authors**: Jordan Sassoon, Michal Szczepanski, Martyna Poreba

**Updated**: 2025-09-12T15:14:19Z

**Summary**: Vision Transformers (ViTs) have recently achieved strong results in semantic segmentation, yet their deployment on resource-constrained devices remains limited due to their high memory footprint and computational cost. Quantization offers an effective strategy to improve efficiency, but ViT-based segmentation models are notoriously fragile under low precision, as quantization errors accumulate across deep encoder-decoder pipelines. We introduce I-Segmenter, the first fully integer-only ViT segmentation framework. Building on the Segmenter architecture, I-Segmenter systematically replaces floating-point operations with integer-only counterparts. To further stabilize both training and inference, we propose $\lambda$-ShiftGELU, a novel activation function that mitigates the limitations of uniform quantization in handling long-tailed activation distributions. In addition, we remove the L2 normalization layer and replace bilinear interpolation in the decoder with nearest neighbor upsampling, ensuring integer-only execution throughout the computational graph. Extensive experiments show that I-Segmenter achieves accuracy within a reasonable margin of its FP32 baseline (5.1 % on average), while reducing model size by up to 3.8x and enabling up to 1.2x faster inference with optimized runtimes. Notably, even in one-shot PTQ with a single calibration image, I-Segmenter delivers competitive accuracy, underscoring its practicality for real-world deployment.

**Link**: [arxiv](http://arxiv.org/abs/2509.10334v1),  [pdf](http://arxiv.org/pdf/2509.10334v1)

**Tags**: cs.CV cs.AI cs.LG 



### Deep Survival Analysis from Adult and Pediatric Electrocardiograms: A   Multi-center Benchmark Study
**Authors**: Platon Lukyanenko, Joshua Mayourian, Mingxuan Liu, John K. Triedman, Sunil J. Ghelani, William G. La Cava

**Updated**: 2025-09-12T15:07:26Z

**Summary**: Artificial intelligence applied to electrocardiography (AI-ECG) shows potential for mortality prediction, but heterogeneous approaches and private datasets have limited generalizable insights. To address this, we systematically evaluated model design choices across three large cohorts: Beth Israel Deaconess (MIMIC-IV: n = 795,546 ECGs, United States), Telehealth Network of Minas Gerais (Code-15: n = 345,779, Brazil), and Boston Children's Hospital (BCH: n = 255,379, United States). We evaluated models predicting all-cause mortality, comparing horizon-based classification and deep survival methods with neural architectures including convolutional networks and transformers, benchmarking against demographic-only and gradient boosting baselines. Top models performed well (median concordance: Code-15, 0.83; MIMIC-IV, 0.78; BCH, 0.81). Incorporating age and sex improved performance across all datasets. Classifier-Cox models showed site-dependent sensitivity to horizon choice (median Pearson's R: Code-15, 0.35; MIMIC-IV, -0.71; BCH, 0.37). External validation reduced concordance, and in some cases demographic-only models outperformed externally trained AI-ECG models on Code-15. However, models trained on multi-site data outperformed site-specific models by 5-22%. Findings highlight factors for robust AI-ECG deployment: deep survival methods outperformed horizon-based classifiers, demographic covariates improved predictive performance, classifier-based models required site-specific calibration, and cross-cohort training, even between adult and pediatric cohorts, substantially improved performance. These results emphasize the importance of model type, demographics, and training diversity in developing AI-ECG models reliably applicable across populations.

**Link**: [arxiv](http://arxiv.org/abs/2406.17002v4),  [pdf](http://arxiv.org/pdf/2406.17002v4)

**Tags**: eess.SP cs.LG cs.NE stat.AP 



### Robot guide with multi-agent control and automatic scenario generation   with LLM
**Authors**: Elizaveta D. Moskovskaya, Anton D. Moscowsky

**Updated**: 2025-09-12T14:59:04Z

**Summary**: The work describes the development of a hybrid control architecture for an anthropomorphic tour guide robot, combining a multi-agent resource management system with automatic behavior scenario generation based on large language models. The proposed approach aims to overcome the limitations of traditional systems, which rely on manual tuning of behavior scenarios. These limitations include manual configuration, low flexibility, and lack of naturalness in robot behavior. The process of preparing tour scenarios is implemented through a two-stage generation: first, a stylized narrative is created, then non-verbal action tags are integrated into the text. The multi-agent system ensures coordination and conflict resolution during the execution of parallel actions, as well as maintaining default behavior after the completion of main operations, contributing to more natural robot behavior. The results obtained from the trial demonstrate the potential of the proposed approach for automating and scaling social robot control systems.

**Link**: [arxiv](http://arxiv.org/abs/2509.10317v1),  [pdf](http://arxiv.org/pdf/2509.10317v1)

**Tags**: cs.RO cs.LG 93C85 I.2.9; I.2.7; I.2.11 



### Toward Open Earth Science as Fast and Accessible as Natural Language
**Authors**: Marquita Ellis, Iksha Gurung, Muthukumaran Ramasubramanian, Rahul Ramachandran

**Updated**: 2025-09-12T14:40:08Z

**Summary**: Is natural-language-driven earth observation data analysis now feasible with the assistance of Large Language Models (LLMs)? For open science in service of public interest, feasibility requires reliably high accuracy, interactive latencies, low (sustainable) costs, open LLMs, and openly maintainable software -- hence, the challenge. What are the techniques and programming system requirements necessary for satisfying these constraints, and what is the corresponding development and maintenance burden in practice? This study lays the groundwork for exploring these questions, introducing an impactful earth science use-case, and providing a software framework with evaluation data and metrics, along with initial results from employing model scaling, prompt-optimization, and inference-time scaling optimization techniques. While we attain high accuracy (near 100%) across 10 of 11 metrics, the analysis further considers cost (token-spend), latency, and maintainability across this space of techniques. Finally, we enumerate opportunities for further research, general programming and evaluation framework development, and ongoing work for a comprehensive, deployable solution. This is a call for collaboration and contribution.

**Link**: [arxiv](http://arxiv.org/abs/2505.15690v2),  [pdf](http://arxiv.org/pdf/2505.15690v2)

**Tags**: cs.CE J.2; H.5.2; H.3.3 



### The Morality of Probability: How Implicit Moral Biases in LLMs May Shape   the Future of Human-AI Symbiosis
**Authors**: Eoin O'Doherty, Nicole Weinrauch, Andrew Talone, Uri Klempner, Xiaoyuan Yi, Xing Xie, Yi Zeng

**Updated**: 2025-09-12T14:37:57Z

**Summary**: Artificial intelligence (AI) is advancing at a pace that raises urgent questions about how to align machine decision-making with human moral values. This working paper investigates how leading AI systems prioritize moral outcomes and what this reveals about the prospects for human-AI symbiosis. We address two central questions: (1) What moral values do state-of-the-art large language models (LLMs) implicitly favour when confronted with dilemmas? (2) How do differences in model architecture, cultural origin, and explainability affect these moral preferences? To explore these questions, we conduct a quantitative experiment with six LLMs, ranking and scoring outcomes across 18 dilemmas representing five moral frameworks. Our findings uncover strikingly consistent value biases. Across all models, Care and Virtue values outcomes were rated most moral, while libertarian choices were consistently penalized. Reasoning-enabled models exhibited greater sensitivity to context and provided richer explanations, whereas non-reasoning models produced more uniform but opaque judgments. This research makes three contributions: (i) Empirically, it delivers a large-scale comparison of moral reasoning across culturally distinct LLMs; (ii) Theoretically, it links probabilistic model behaviour with underlying value encodings; (iii) Practically, it highlights the need for explainability and cultural awareness as critical design principles to guide AI toward a transparent, aligned, and symbiotic future.

**Link**: [arxiv](http://arxiv.org/abs/2509.10297v1),  [pdf](http://arxiv.org/pdf/2509.10297v1)

**Tags**: cs.AI 



### We Need a New Ethics for a World of AI Agents
**Authors**: Iason Gabriel, Geoff Keeling, Arianna Manzini, James Evans

**Updated**: 2025-09-12T14:29:14Z

**Summary**: The deployment of capable AI agents raises fresh questions about safety, human-machine relationships and social coordination. We argue for greater engagement by scientists, scholars, engineers and policymakers with the implications of a world increasingly populated by AI agents. We explore key challenges that must be addressed to ensure that interactions between humans and agents, and among agents themselves, remain broadly beneficial.

**Link**: [arxiv](http://arxiv.org/abs/2509.10289v1),  [pdf](http://arxiv.org/pdf/2509.10289v1)

**Tags**: cs.CY cs.AI I.2.0; K.4.1 



### Integrated Sensing and Communications Over the Years: An Evolution   Perspective
**Authors**: Di Zhang, Yuanhao Cui, Xiaowen Cao, Nanchi Su, Yi Gong, Fan Liu, Weijie Yuan, Xiaojun Jing, J. Andrew Zhang, Jie Xu, Christos Masouros, Dusit Niyato, Marco Di Renzo

**Updated**: 2025-09-12T14:28:27Z

**Summary**: Integrated Sensing and Communications (ISAC) enables efficient spectrum utilization and reduces hardware costs for beyond 5G (B5G) and 6G networks, facilitating intelligent applications that require both high-performance communication and precise sensing capabilities. This survey provides a comprehensive review of the evolution of ISAC over the years. We examine the expansion of the spectrum across RF and optical ISAC, highlighting the role of advanced technologies, along with key challenges and synergies. We further discuss the advancements in network architecture from single-cell to multi-cell systems, emphasizing the integration of collaborative sensing and interference mitigation strategies. Moreover, we analyze the progress from single-modal to multi-modal sensing, with a focus on the integration of edge intelligence to enable real-time data processing, reduce latency, and enhance decision-making. Finally, we extensively review standardization efforts by 3GPP, IEEE, and ITU, examining the transition of ISAC-related technologies and their implications for the deployment of 6G networks.

**Link**: [arxiv](http://arxiv.org/abs/2504.06830v2),  [pdf](http://arxiv.org/pdf/2504.06830v2)

**Tags**: eess.SP 



### Comparing Apples to Oranges: A Dataset & Analysis of LLM Humour   Understanding from Traditional Puns to Topical Jokes
**Authors**: Tyler Loakman, William Thorne, Chenghua Lin

**Updated**: 2025-09-12T14:23:05Z

**Summary**: Humour, as a complex language form, is derived from myriad aspects of life. Whilst existing work on computational humour has focussed almost exclusively on short pun-based jokes, we investigate whether the ability of Large Language Models (LLMs) to explain humour depends on the particular form. We compare models' joke explanation abilities from simple puns to complex topical humour that requires esoteric knowledge of real-world entities and events. To this end, we curate a dataset of 600 jokes across 4 joke types and manually write high-quality explanations. These jokes include heterographic and homographic puns, contemporary internet humour, and topical jokes. Using this dataset, we compare the zero-shot abilities of a range of LLMs to accurately and comprehensively explain jokes of different types, identifying key research gaps in the task of humour explanation. We find that none of the tested models (including reasoning models) are capable of reliably generating adequate explanations of all joke types, further highlighting the narrow focus of most existing works on overly simple joke forms.

**Link**: [arxiv](http://arxiv.org/abs/2507.13335v2),  [pdf](http://arxiv.org/pdf/2507.13335v2)

**Tags**: cs.CL 



### Large-scale Aerial Reconfigurable Intelligent Surface-aided Robust   Anti-jamming Transmission
**Authors**: Junshan Luo, Shilian Wang, Boxiang He

**Updated**: 2025-09-12T14:20:55Z

**Summary**: Aerial reconfigurable intelligent surfaces (ARIS), deployed on unmanned aerial vehicles (UAVs), could enhance anti-jamming communication performance by dynamically configuring channel conditions and establishing reliable air-ground links. However, large-scale ARIS faces critical deployment challenges due to the prohibitive computational complexity of conventional discrete optimization methods and sophisticated jamming threats. In this paper, we introduce a mean field modeling approach to design the spatial configuration of ARIS by a continuous density function, thus bypassing high-dimensional combinatorial optimization. We consider an adaptive jammer which adjusts its position and beamforming to minimize the sum-rate. A key finding reveals that the jammer's optimal strategy is governed by a proximity-directivity trade-off between reducing path loss and enhancing spatial focusing. To combat the jamming, we propose a robust anti-jamming transmission framework that jointly optimizes the BS beamforming, the ARIS reflection, and the ARIS spatial distribution to maximize the worst-case sum-rate. By leveraging variational optimization and Riemannian manifold methods, we efficiently solve the functional optimization problems. Our analysis further unveils that the optimal ARIS deployment follows a spatial water-filling principle, concentrating resources in high-gain regions while avoiding interference-prone areas. Simulation results demonstrate that the proposed framework remarkably improves the sum-rate. Furthermore, the computational complexity of the proposed algorithm is independent of the number of UAVs, validating its effectiveness for scalable ARIS-assisted anti-jamming communications.

**Link**: [arxiv](http://arxiv.org/abs/2509.10280v1),  [pdf](http://arxiv.org/pdf/2509.10280v1)

**Tags**: cs.IT math.IT 



### TORSO: Template-Oriented Reasoning Towards General Tasks
**Authors**: Minhyuk Kim, Seungyoon Lee, Heuiseok Lim

**Updated**: 2025-09-12T14:00:08Z

**Summary**: The approaches that guide Large Language Models (LLMs) to emulate human reasoning during response generation have emerged as an effective method for enabling them to solve complex problems in a step-by-step manner, thereby achieving superior performance. However, most existing approaches using few-shot prompts to generate responses heavily depend on the provided examples, limiting the utilization of the model's inherent reasoning capabilities. Moreover, constructing task-specific few-shot prompts is often costly and may lead to inconsistencies across different tasks. In this work, we introduce Template-Oriented Reasoning (TORSO), which elicits the model to utilize internal reasoning abilities to generate proper responses across various tasks without the need for manually crafted few-shot examples. Our experimental results demonstrate that TORSO achieves strong performance on diverse LLMs benchmarks with reasonable rationales.

**Link**: [arxiv](http://arxiv.org/abs/2509.09448v2),  [pdf](http://arxiv.org/pdf/2509.09448v2)

**Tags**: cs.AI 



### Multi-Turn Human-LLM Interaction Through the Lens of a Two-Way   Intelligibility Protocol
**Authors**: Harshvardhan Mestha, Karan Bania, Shreyas V, Sidong Liu, Ashwin Srinivasan

**Updated**: 2025-09-12T13:52:45Z

**Summary**: Our interest is in the design of software systems involving a human-expert interacting -- using natural language -- with a large language model (LLM) on data analysis tasks. For complex problems, it is possible that LLMs can harness human expertise and creativity to find solutions that were otherwise elusive. On one level, this interaction takes place through multiple turns of prompts from the human and responses from the LLM. Here we investigate a more structured approach based on an abstract protocol described in [3] for interaction between agents. The protocol is motivated by a notion of "two-way intelligibility" and is modelled by a pair of communicating finite-state machines. We provide an implementation of the protocol, and provide empirical evidence of using the implementation to mediate interactions between an LLM and a human-agent in two areas of scientific interest (radiology and drug design). We conduct controlled experiments with a human proxy (a database), and uncontrolled experiments with human subjects. The results provide evidence in support of the protocol's capability of capturing one- and two-way intelligibility in human-LLM interaction; and for the utility of two-way intelligibility in the design of human-machine systems.

**Link**: [arxiv](http://arxiv.org/abs/2410.20600v2),  [pdf](http://arxiv.org/pdf/2410.20600v2)

**Tags**: cs.AI cs.HC cs.LG cs.MA 



### Hybrid Swin Attention Networks for Simultaneously Low-Dose PET and CT   Denoising
**Authors**: Yichao Liu, Hengzhi Xue, YueYang Teng

**Updated**: 2025-09-12T13:48:25Z

**Summary**: Low-dose computed tomography (LDCT) and positron emission tomography (PET) have emerged as safer alternatives to conventional imaging modalities by significantly reducing radiation exposure. However, this reduction often results in increased noise and artifacts, which can compromise diagnostic accuracy. Consequently, denoising for LDCT/PET has become a vital area of research aimed at enhancing image quality while maintaining radiation safety. In this study, we introduce a novel Hybrid Swin Attention Network (HSANet), which incorporates Efficient Global Attention (EGA) modules and a hybrid upsampling module. The EGA modules enhance both spatial and channel-wise interaction, improving the network's capacity to capture relevant features, while the hybrid upsampling module mitigates the risk of overfitting to noise. We validate the proposed approach using a publicly available LDCT/PET dataset. Experimental results demonstrate that HSANet achieves superior denoising performance compared to existing methods, while maintaining a lightweight model size suitable for deployment on GPUs with standard memory configurations. This makes our approach highly practical for real-world clinical applications.

**Link**: [arxiv](http://arxiv.org/abs/2509.06591v4),  [pdf](http://arxiv.org/pdf/2509.06591v4)

**Tags**: cs.CV 



### Prompt Injection Attacks on LLM Generated Reviews of Scientific   Publications
**Authors**: Janis Keuper

**Updated**: 2025-09-12T13:45:24Z

**Summary**: The ongoing intense discussion on rising LLM usage in the scientific peer-review process has recently been mingled by reports of authors using hidden prompt injections to manipulate review scores. Since the existence of such "attacks" - although seen by some commentators as "self-defense" - would have a great impact on the further debate, this paper investigates the practicability and technical success of the described manipulations. Our systematic evaluation uses 1k reviews of 2024 ICLR papers generated by a wide range of LLMs shows two distinct results: I) very simple prompt injections are indeed highly effective, reaching up to 100% acceptance scores. II) LLM reviews are generally biased toward acceptance (>95% in many models). Both results have great impact on the ongoing discussions on LLM usage in peer-review.

**Link**: [arxiv](http://arxiv.org/abs/2509.10248v1),  [pdf](http://arxiv.org/pdf/2509.10248v1)

**Tags**: cs.LG 



### Compartmentalised Agentic Reasoning for Clinical NLI
**Authors**: Maël Jullien, Lei Xu, Marco Valentino, André Freitas

**Updated**: 2025-09-12T13:14:47Z

**Summary**: A common assumption holds that scaling data and parameters yields increasingly structured, generalisable internal representations. We interrogate this assumption in clinical natural language inference (NLI) by adopting a benchmark decomposed into four reasoning families, Causal Attribution, Compositional Grounding, Epistemic Verification, and Risk State Abstraction, and introducing CARENLI, a Compartmentalised Agentic Reasoning for Clinical NLI that separates knowledge access from principled inference. CARENLI routes each premise, statement pair to a family specific solver and enforces auditable procedures via a planner, verifier, and refiner.   Across four LLMs, CARENLI improves fidelity by up to 42 points, reaching 98.0% in Causal Attribution and 81.2% in Risk State Abstraction. Verifiers flag violations with near-ceiling reliability, while refiners correct a substantial share of epistemic errors. Remaining failures cluster in routing, identifying family classification as the main bottleneck. These results show that LLMs often retain relevant facts but default to heuristics when inference is underspecified, a dissociation CARENLI makes explicit while offering a framework for safer, auditable reasoning.

**Link**: [arxiv](http://arxiv.org/abs/2509.10222v1),  [pdf](http://arxiv.org/pdf/2509.10222v1)

**Tags**: cs.AI 



### MachineLearningLM: Scaling Many-shot In-context Learning via Continued   Pretraining
**Authors**: Haoyu Dong, Pengkun Zhang, Mingzhe Lu, Yanzhen Shen, Guolin Ke

**Updated**: 2025-09-12T13:11:51Z

**Summary**: Large language models (LLMs) possess broad world knowledge and strong general-purpose reasoning ability, yet they struggle to learn from many in-context examples on standard machine learning (ML) tasks, that is, to leverage many-shot demonstrations purely via in-context learning (ICL) without gradient descent. We introduce MachineLearningLM, a portable continued-pretraining framework that equips a general-purpose LLM with robust in-context ML capability while preserving its general knowledge and reasoning for broader chat workflows.   Our pretraining procedure synthesizes ML tasks from millions of structural causal models (SCMs), spanning shot counts up to 1,024. We begin with a random-forest teacher, distilling tree-based decision strategies into the LLM to strengthen robustness in numerical modeling. All tasks are serialized with a token-efficient prompt, enabling 3x to 6x more examples per context window and delivering up to 50x amortized throughput via batch inference.   Despite a modest setup (Qwen-2.5-7B-Instruct with LoRA rank 8), MachineLearningLM outperforms strong LLM baselines (e.g., GPT-5-mini) by an average of about 15% on out-of-distribution tabular classification across finance, physics, biology, and healthcare domains. It exhibits a striking many-shot scaling law: accuracy increases monotonically as in-context demonstrations grow from 8 to 1,024. Without any task-specific training, it attains random-forest-level accuracy across hundreds of shots. General chat capabilities, including knowledge and reasoning, are preserved: it achieves 75.4% on MMLU.

**Link**: [arxiv](http://arxiv.org/abs/2509.06806v4),  [pdf](http://arxiv.org/pdf/2509.06806v4)

**Tags**: cs.CL cs.AI 



### RFSeek and Ye Shall Find
**Authors**: Noga H. Rotman, Tiago Ferreira, Hila Peleg, Mark Silberstein, Alexandra Silva

**Updated**: 2025-09-12T13:08:50Z

**Summary**: Requests for Comments (RFCs) are extensive specification documents for network protocols, but their prose-based format and their considerable length often impede precise operational understanding. We present RFSeek, an interactive tool that automatically extracts visual summaries of protocol logic from RFCs. RFSeek leverages large language models (LLMs) to generate provenance-linked, explorable diagrams, surfacing both official state machines and additional logic found only in the RFC text. Compared to existing RFC visualizations, RFSeek's visual summaries are more transparent and easier to audit against their textual source. We showcase the tool's potential through a series of use cases, including guided knowledge extraction and semantic diffing, applied to protocols such as TCP, QUIC, PPTP, and DCCP.   In practice, RFSeek not only reconstructs the RFC diagrams included in some specifications, but, more interestingly, also uncovers important logic such as nodes or edges described in the text but missing from those diagrams. RFSeek further derives new visualization diagrams for complex RFCs, with QUIC as a representative case. Our approach, which we term \emph{Summary Visualization}, highlights a promising direction: combining LLMs with formal, user-customized visualizations to enhance protocol comprehension and support robust implementations.

**Link**: [arxiv](http://arxiv.org/abs/2509.10216v1),  [pdf](http://arxiv.org/pdf/2509.10216v1)

**Tags**: cs.NI cs.HC cs.LG 



### Towards Fully Automated Molecular Simulations: Multi-Agent Framework for   Simulation Setup and Force Field Extraction
**Authors**: Marko Petković, Vlado Menkovski, Sofía Calero

**Updated**: 2025-09-12T12:56:47Z

**Summary**: Automated characterization of porous materials has the potential to accelerate materials discovery, but it remains limited by the complexity of simulation setup and force field selection. We propose a multi-agent framework in which LLM-based agents can autonomously understand a characterization task, plan appropriate simulations, assemble relevant force fields, execute them and interpret their results to guide subsequent steps. As a first step toward this vision, we present a multi-agent system for literature-informed force field extraction and automated RASPA simulation setup. Initial evaluations demonstrate high correctness and reproducibility, highlighting this approach's potential to enable fully autonomous, scalable materials characterization.

**Link**: [arxiv](http://arxiv.org/abs/2509.10210v1),  [pdf](http://arxiv.org/pdf/2509.10210v1)

**Tags**: cs.AI cs.MA 



### SI-FACT: Mitigating Knowledge Conflict via Self-Improving   Faithfulness-Aware Contrastive Tuning
**Authors**: Shengqiang Fu

**Updated**: 2025-09-12T12:56:14Z

**Summary**: Large Language Models often generate unfaithful responses in knowledge intensive tasks due to knowledge conflict,that is,a preference for relying on internal parametric knowledge rather than the provided context.To address this issue,we propose a novel self improving framework,Self Improving Faithfulness Aware Contrastive Tuning.The framework uses a self instruct mechanism that allows the base LLM to automatically generate high quality,structured contrastive learning data,including anchor samples,semantically equivalent positive samples,and negative samples simulating unfaithful scenarios.This approach significantly reduces the cost of manual annotation.Subsequently,contrastive learning is applied to train the model,enabling it to pull faithful responses closer and push unfaithful responses farther apart in the representation space.Experiments on knowledge conflict evaluation benchmarks ECARE KRE and COSE KRE show that the SI FACT model based on Llama3 8B Instruct improves the Contextual Recall Rate by 6.2% over the best baseline method,while significantly reducing dependence on internal memory.The results indicate that SI FACT provides strong effectiveness and high data efficiency in enhancing the contextual faithfulness of LLMs,offering a practical pathway toward building more proactive and trustworthy language models.

**Link**: [arxiv](http://arxiv.org/abs/2509.10208v1),  [pdf](http://arxiv.org/pdf/2509.10208v1)

**Tags**: cs.CL cs.AI 



### Steering Protein Language Models
**Authors**: Long-Kai Huang, Rongyi Zhu, Bing He, Jianhua Yao

**Updated**: 2025-09-12T12:39:45Z

**Summary**: Protein Language Models (PLMs), pre-trained on extensive evolutionary data from natural proteins, have emerged as indispensable tools for protein design. While powerful, PLMs often struggle to produce proteins with precisely specified functionalities or properties due to inherent challenges in controlling their outputs. In this work, we investigate the potential of Activation Steering, a technique originally developed for controlling text generation in Large Language Models (LLMs), to direct PLMs toward generating protein sequences with targeted properties. We propose a simple yet effective method that employs activation editing to steer PLM outputs, and extend this approach to protein optimization through a novel editing site identification module. Through comprehensive experiments on lysozyme-like sequence generation and optimization, we demonstrate that our methods can be seamlessly integrated into both auto-encoding and autoregressive PLMs without requiring additional training. These results highlight a promising direction for precise protein engineering using foundation models.

**Link**: [arxiv](http://arxiv.org/abs/2509.07983v2),  [pdf](http://arxiv.org/pdf/2509.07983v2)

**Tags**: q-bio.BM cs.LG 



### Incongruent Positivity: When Miscalibrated Positivity Undermines Online   Supportive Conversations
**Authors**: Leen Almajed, Abeer ALdayel

**Updated**: 2025-09-12T12:25:02Z

**Summary**: In emotionally supportive conversations, well-intended positivity can sometimes misfire, leading to responses that feel dismissive, minimizing, or unrealistically optimistic. We examine this phenomenon of incongruent positivity as miscalibrated expressions of positive support in both human and LLM generated responses. To this end, we collected real user-assistant dialogues from Reddit across a range of emotional intensities and generated additional responses using large language models for the same context. We categorize these conversations by intensity into two levels: Mild, which covers relationship tension and general advice, and Severe, which covers grief and anxiety conversations. This level of categorization enables a comparative analysis of how supportive responses vary across lower and higher stakes contexts. Our analysis reveals that LLMs are more prone to unrealistic positivity through dismissive and minimizing tone, particularly in high-stakes contexts. To further study the underlying dimensions of this phenomenon, we finetune LLMs on datasets with strong and weak emotional reactions. Moreover, we developed a weakly supervised multilabel classifier ensemble (DeBERTa and MentalBERT) that shows improved detection of incongruent positivity types across two sorts of concerns (Mild and Severe). Our findings shed light on the need to move beyond merely generating generic positive responses and instead study the congruent support measures to balance positive affect with emotional acknowledgment. This approach offers insights into aligning large language models with affective expectations in the online supportive dialogue, paving the way toward context-aware and trust preserving online conversation systems.

**Link**: [arxiv](http://arxiv.org/abs/2509.10184v1),  [pdf](http://arxiv.org/pdf/2509.10184v1)

**Tags**: cs.CL 



### Benchmark of stylistic variation in LLM-generated texts
**Authors**: Jiří Milička, Anna Marklová, Václav Cvrček

**Updated**: 2025-09-12T12:12:20Z

**Summary**: This study investigates the register variation in texts written by humans and comparable texts produced by large language models (LLMs). Biber's multidimensional analysis (MDA) is applied to a sample of human-written texts and AI-created texts generated to be their counterparts to find the dimensions of variation in which LLMs differ most significantly and most systematically from humans. As textual material, a new LLM-generated corpus AI-Brown is used, which is comparable to BE-21 (a Brown family corpus representing contemporary British English). Since all languages except English are underrepresented in the training data of frontier LLMs, similar analysis is replicated on Czech using AI-Koditex corpus and Czech multidimensional model. Examined were 16 frontier models in various settings and prompts, with emphasis placed on the difference between base models and instruction-tuned models. Based on this, a benchmark is created through which models can be compared with each other and ranked in interpretable dimensions.

**Link**: [arxiv](http://arxiv.org/abs/2509.10179v1),  [pdf](http://arxiv.org/pdf/2509.10179v1)

**Tags**: cs.CL cs.AI 



### A 2-step Framework for Automated Literary Translation Evaluation: Its   Promises and Pitfalls
**Authors**: Sheikh Shafayat, Dongkeun Yoon, Woori Jang, Jiwoo Choi, Alice Oh, Seohyon Jung

**Updated**: 2025-09-12T12:10:06Z

**Summary**: In this work, we propose and evaluate the feasibility of a two-stage pipeline to evaluate literary machine translation, in a fine-grained manner, from English to Korean. The results show that our framework provides fine-grained, interpretable metrics suited for literary translation and obtains a higher correlation with human judgment than traditional machine translation metrics. Nonetheless, it still fails to match inter-human agreement, especially in metrics like Korean Honorifics. We also observe that LLMs tend to favor translations generated by other LLMs, and we highlight the necessity of developing more sophisticated evaluation methods to ensure accurate and culturally sensitive machine translation of literary works.

**Link**: [arxiv](http://arxiv.org/abs/2412.01340v3),  [pdf](http://arxiv.org/pdf/2412.01340v3)

**Tags**: cs.CL 



### QuantX: A Framework for Hardware-Aware Quantization of Generative AI   Workloads
**Authors**: Muhammad Ahmad, Khurram Mazher, Saqib Akram, Ahmad Tameem, Saad Bin Nasir

**Updated**: 2025-09-12T12:03:22Z

**Summary**: We present QuantX: a tailored suite of recipes for LLM and VLM quantization. It is capable of quantizing down to 3-bit resolutions with minimal loss in performance. The quantization strategies in QuantX take into account hardware-specific constraints to achieve efficient dequantization during inference ensuring flexible trade-off between runtime speed, memory requirement and model accuracy. Our results demonstrate that QuantX achieves performance within 6% of the unquantized model for LlaVa-v1.6 quantized down to 3-bits for multiple end user tasks and outperforms recently published state-of-the-art quantization techniques. We further integrate one particular technique from QuantX into the popular Llama.cpp framework and show its feasibility in terms of runtime compared to the mainstream quantization techniques from Llama.cpp. Lastly, this manuscript provides insights into the LLM quantization process that motivated the range of recipes and options that are incorporated in QuantX.

**Link**: [arxiv](http://arxiv.org/abs/2505.07531v2),  [pdf](http://arxiv.org/pdf/2505.07531v2)

**Tags**: cs.AI eess.SP 



### B*: Efficient and Optimal Base Placement for Fixed-Base Manipulators
**Authors**: Zihang Zhao, Leiyao Cui, Sirui Xie, Saiyao Zhang, Zhi Han, Lecheng Ruan, Yixin Zhu

**Updated**: 2025-09-12T11:57:49Z

**Summary**: B* is a novel optimization framework that addresses a critical challenge in fixed-base manipulator robotics: optimal base placement. Current methods rely on pre-computed kinematics databases generated through sampling to search for solutions. However, they face an inherent trade-off between solution optimality and computational efficiency when determining sampling resolution. To address these limitations, B* unifies multiple objectives without database dependence. The framework employs a two-layer hierarchical approach. The outer layer systematically manages terminal constraints through progressive tightening, particularly for base mobility, enabling feasible initialization and broad solution exploration. The inner layer addresses non-convexities in each outer-layer subproblem through sequential local linearization, converting the original problem into tractable sequential linear programming (SLP). Testing across multiple robot platforms demonstrates B*'s effectiveness. The framework achieves solution optimality five orders of magnitude better than sampling-based approaches while maintaining perfect success rates and reduced computational overhead. Operating directly in configuration space, B* enables simultaneous path planning with customizable optimization criteria. B* serves as a crucial initialization tool that bridges the gap between theoretical motion planning and practical deployment, where feasible trajectory existence is fundamental.

**Link**: [arxiv](http://arxiv.org/abs/2504.12719v3),  [pdf](http://arxiv.org/pdf/2504.12719v3)

**Tags**: cs.RO 



### FGIT: Fault-Guided Fine-Tuning for Code Generation
**Authors**: Lishui Fan, Zhongxin Liu, Haoye Wang, Lingfeng Bao, Xin Xia, Shanping Li

**Updated**: 2025-09-12T11:56:27Z

**Summary**: Modern instruction-tuned large language models (LLMs) have made remarkable progress in code generation. However, these LLMs fine-tuned with standard supervised fine-tuning (SFT) sometimes generate plausible-looking but functionally incorrect code variants. This issue likely stems from the limitation of standard SFT, which treats all tokens equally during optimization and fails to emphasize the error-sensitive segments-specific code differences between correct implementations and similar incorrect variants. To address this problem, we propose Fault-Guided Fine-Tuning (FGIT), a novel fine-tuning technique that enhances LLMs' code generation by (1) extracting multi-granularity (line/token-level) differences between correct and incorrect yet similar implementations to identify error-sensitive segments, and (2) dynamically prioritizing those segments during training via dynamic loss weighting. Through extensive experiments on seven LLMs across three widely-used benchmarks, our method achieves an average relative improvement of 6.9% on pass@1 with some enhanced 6.7B LLMs outperforming closed-source models, e.g., GPT-3.5-Turbo. Furthermore, our fine-tuning technique demonstrates strong generalization with performance improvements ranging from 3.8% to 19.1% across diverse instruction-tuned LLMs, and our ablation studies confirm the contributions of different granularities of differences and hyperparameters.

**Link**: [arxiv](http://arxiv.org/abs/2503.16913v2),  [pdf](http://arxiv.org/pdf/2503.16913v2)

**Tags**: cs.SE 



### A Framework for Testing and Adapting REST APIs as LLM Tools
**Authors**: Jayachandu Bandlamudi, Ritwik Chaudhuri, Neelamadhav Gantayat, Sambit Ghosh, Kushal Mukherjee, Prerna Agarwal, Renuka Sindhgatta, Sameep Mehta

**Updated**: 2025-09-12T11:24:08Z

**Summary**: Large Language Models (LLMs) are increasingly used to build autonomous agents that perform complex tasks with external tools, often exposed through APIs in enterprise systems. Direct use of these APIs is difficult due to the complex input schema and verbose responses. Current benchmarks overlook these challenges, leaving a gap in assessing API readiness for agent-driven automation. We present a testing framework that systematically evaluates enterprise APIs when wrapped as Python tools for LLM-based agents. The framework generates data-aware test cases, translates them into natural language instructions, and evaluates whether agents can correctly invoke the tool, handle their inputs, and process its responses. We apply the framework to generate over 2400 test cases across different domains and develop a taxonomy of common errors, including input misinterpretation, output failures, and schema mismatches. We further classify errors to support debugging and tool refinement. Our framework provides a systematic approach to enabling enterprise APIs as reliable tools for agent-based applications.

**Link**: [arxiv](http://arxiv.org/abs/2504.15546v3),  [pdf](http://arxiv.org/pdf/2504.15546v3)

**Tags**: cs.SE cs.AI I.2.7 



### Survivability of Backdoor Attacks on Unconstrained Face Recognition   Systems
**Authors**: Quentin Le Roux, Yannick Teglia, Teddy Furon, Philippe Loubet-Moundi, Eric Bourbao

**Updated**: 2025-09-12T11:19:56Z

**Summary**: The widespread deployment of Deep Learning-based Face Recognition Systems raises multiple security concerns. While prior research has identified backdoor vulnerabilities on isolated components, Backdoor Attacks on real-world, unconstrained pipelines remain underexplored. This paper presents the first comprehensive system-level analysis of Backdoor Attacks targeting Face Recognition Systems and provides three contributions. We first show that face feature extractors trained with large margin metric learning losses are susceptible to Backdoor Attacks. By analyzing 20 pipeline configurations and 15 attack scenarios, we then reveal that a single backdoor can compromise an entire Face Recognition System. Finally, we propose effective best practices and countermeasures for stakeholders.

**Link**: [arxiv](http://arxiv.org/abs/2507.01607v3),  [pdf](http://arxiv.org/pdf/2507.01607v3)

**Tags**: cs.CV cs.AI cs.CR cs.LG 



### Between a Rock and a Hard Place: Exploiting Ethical Reasoning to   Jailbreak LLMs
**Authors**: Shei Pern Chua, Zhen Leng Thai, Teh Kai Jun, Xiao Li, Xiaolin Hu

**Updated**: 2025-09-12T11:05:08Z

**Summary**: Large language models (LLMs) have undergone safety alignment efforts to mitigate harmful outputs. However, as LLMs become more sophisticated in reasoning, their intelligence may introduce new security risks. While traditional jailbreak attacks relied on singlestep attacks, multi-turn jailbreak strategies that adapt dynamically to context remain underexplored. In this work, we introduce TRIAL (Trolley-problem Reasoning for Interactive Attack Logic), a framework that leverages LLMs ethical reasoning to bypass their safeguards. TRIAL embeds adversarial goals within ethical dilemmas modeled on the trolley problem. TRIAL demonstrates high jailbreak success rates towards both open and close-source models. Our findings underscore a fundamental limitation in AI safety: as models gain advanced reasoning abilities, the nature of their alignment may inadvertently allow for more covert security vulnerabilities to be exploited. TRIAL raises an urgent need in reevaluating safety alignment oversight strategies, as current safeguards may prove insufficient against context-aware adversarial attack.

**Link**: [arxiv](http://arxiv.org/abs/2509.05367v2),  [pdf](http://arxiv.org/pdf/2509.05367v2)

**Tags**: cs.CR cs.AI 



### MAESTRO: Multi-modal Adaptive Estimation for Temporal Respiratory   Disease Outbreak
**Authors**: Hong Liu, Kerui Cen, Yanxing Chen, Zige Liu, Dong Chen, Zifeng Yang, Chitin Hon

**Updated**: 2025-09-12T11:02:37Z

**Summary**: Timely and robust influenza incidence forecasting is critical for public health decision-making. This paper presents MAESTRO (Multi-modal Adaptive Estimation for Temporal Respiratory Disease Outbreak), a novel, unified framework that synergistically integrates advanced spectro-temporal modeling with multi-modal data fusion, including surveillance, web search trends, and meteorological data. By adaptively weighting heterogeneous data sources and decomposing complex time series patterns, the model achieves robust and accurate forecasts. Evaluated on over 11 years of Hong Kong influenza data (excluding the COVID-19 period), MAESTRO demonstrates state-of-the-art performance, achieving a superior model fit with an R-square of 0.956. Extensive ablations confirm the significant contributions of its multi-modal and spectro-temporal components. The modular and reproducible pipeline is made publicly available to facilitate deployment and extension to other regions and pathogens, presenting a powerful tool for epidemiological forecasting.

**Link**: [arxiv](http://arxiv.org/abs/2509.08578v2),  [pdf](http://arxiv.org/pdf/2509.08578v2)

**Tags**: cs.LG q-bio.PE q-bio.QM 



### The Auth Shim: A Lightweight Architectural Pattern for Integrating   Enterprise SSO with Standalone Open-Source Applications
**Authors**: Yuvraj Agrawal

**Updated**: 2025-09-12T10:44:36Z

**Summary**: Open-source software OSS is widely adopted in enterprise settings, but standalone tools often lack native support for protocols like SAML or OIDC, creating a critical security integration gap. This paper introduces and formalizes the Auth Shim, a lightweight architectural pattern designed to solve this problem. The Auth Shim is a minimal, external proxy service that acts as a compatibility layer, translating requests from an enterprise Identity Provider IdP into the native session management mechanism of a target application. A key prerequisite for this pattern is that the target application must expose a programmatic, secure administrative API. We present a case study of the pattern's implementation at Adobe to integrate a popular OSS BI tool with Okta SAML, which enabled automated Role-Based Access Control RBAC via IAM group mapping and eliminated manual user provisioning. By defining its components, interactions, and production deployment considerations, this paper provides a reusable, secure, and cost-effective blueprint for integrating any standalone OSS tool into an enterprise SSO ecosystem, thereby enabling organizations to embrace open-source innovation without compromising on security governance.

**Link**: [arxiv](http://arxiv.org/abs/2509.03900v2),  [pdf](http://arxiv.org/pdf/2509.03900v2)

**Tags**: cs.SE cs.CR 



### Population-Aligned Persona Generation for LLM-based Social Simulation
**Authors**: Zhengyu Hu, Zheyuan Xiao, Max Xiong, Yuxuan Lei, Tianfu Wang, Jianxun Lian, Kaize Ding, Ziang Xiao, Nicholas Jing Yuan, Xing Xie

**Updated**: 2025-09-12T10:43:47Z

**Summary**: Recent advances in large language models (LLMs) have enabled human-like social simulations at unprecedented scale and fidelity, offering new opportunities for computational social science. A key challenge, however, is the construction of persona sets that authentically represent the diversity and distribution of real-world populations. Most existing LLM-based social simulation studies focus primarily on designing agentic frameworks and simulation environments, often overlooking the complexities of persona generation and the potential biases introduced by unrepresentative persona sets. In this paper, we propose a systematic framework for synthesizing high-quality, population-aligned persona sets for LLM-driven social simulation. Our approach begins by leveraging LLMs to generate narrative personas from long-term social media data, followed by rigorous quality assessment to filter out low-fidelity profiles. We then apply importance sampling to achieve global alignment with reference psychometric distributions, such as the Big Five personality traits. To address the needs of specific simulation contexts, we further introduce a task-specific module that adapts the globally aligned persona set to targeted subpopulations. Extensive experiments demonstrate that our method significantly reduces population-level bias and enables accurate, flexible social simulation for a wide range of research and policy applications.

**Link**: [arxiv](http://arxiv.org/abs/2509.10127v1),  [pdf](http://arxiv.org/pdf/2509.10127v1)

**Tags**: cs.CL cs.AI cs.LG 



### Afford-X: Generalizable and Slim Affordance Reasoning for Task-oriented   Manipulation
**Authors**: Xiaomeng Zhu, Yuyang Li, Leiyao Cui, Pengfei Li, Huan-ang Gao, Yixin Zhu, Hao Zhao

**Updated**: 2025-09-12T10:34:34Z

**Summary**: Object affordance reasoning, the ability to infer object functionalities based on physical properties, is fundamental for task-oriented planning and activities in both humans and Artificial Intelligence (AI). This capability, required for planning and executing daily activities in a task-oriented manner, relies on commonsense knowledge of object physics and functionalities, extending beyond simple object recognition. Current computational models for affordance reasoning from perception lack generalizability, limiting their applicability in novel scenarios. Meanwhile, comprehensive Large Language Models (LLMs) with emerging reasoning capabilities are challenging to deploy on local devices for task-oriented manipulations. Here, we introduce LVIS-Aff, a large-scale dataset comprising 1,496 tasks and 119k images, designed to enhance the generalizability of affordance reasoning from perception. Utilizing this dataset, we develop Afford-X, an end-to-end trainable affordance reasoning model that incorporates Verb Attention and Bi-Fusion modules to improve multi-modal understanding. This model achieves up to a 12.1% performance improvement over the best-reported results from non-LLM methods, while also demonstrating a 1.2% enhancement compared to our previous conference paper. Additionally, it maintains a compact 187M parameter size and infers nearly 50 times faster than the GPT-4V API. Our work demonstrates the potential for efficient, generalizable affordance reasoning models that can be deployed on local devices for task-oriented manipulations. We showcase Afford-X's effectiveness in enabling task-oriented manipulations for robots across various tasks and environments, underscoring its efficiency and broad implications for advancing robotics and AI systems in real-world applications.

**Link**: [arxiv](http://arxiv.org/abs/2503.03556v2),  [pdf](http://arxiv.org/pdf/2503.03556v2)

**Tags**: cs.CV cs.RO 



### A Lightweight Ensemble-Based Face Image Quality Assessment Method with   Correlation-Aware Loss
**Authors**: MohammadAli Hamidi, Hadi Amirpour, Luigi Atzori, Christian Timmerer

**Updated**: 2025-09-12T10:13:38Z

**Summary**: Face image quality assessment (FIQA) plays a critical role in face recognition and verification systems, especially in uncontrolled, real-world environments. Although several methods have been proposed, general-purpose no-reference image quality assessment techniques often fail to capture face-specific degradations. Meanwhile, state-of-the-art FIQA models tend to be computationally intensive, limiting their practical applicability. We propose a lightweight and efficient method for FIQA, designed for the perceptual evaluation of face images in the wild. Our approach integrates an ensemble of two compact convolutional neural networks, MobileNetV3-Small and ShuffleNetV2, with prediction-level fusion via simple averaging. To enhance alignment with human perceptual judgments, we employ a correlation-aware loss (MSECorrLoss), combining mean squared error (MSE) with a Pearson correlation regularizer. Our method achieves a strong balance between accuracy and computational cost, making it suitable for real-world deployment. Experiments on the VQualA FIQA benchmark demonstrate that our model achieves a Spearman rank correlation coefficient (SRCC) of 0.9829 and a Pearson linear correlation coefficient (PLCC) of 0.9894, remaining within competition efficiency constraints.

**Link**: [arxiv](http://arxiv.org/abs/2509.10114v1),  [pdf](http://arxiv.org/pdf/2509.10114v1)

**Tags**: cs.CV 



### Scaling Arabic Medical Chatbots Using Synthetic Data: Enhancing   Generative AI with Synthetic Patient Records
**Authors**: Abdulrahman Allam, Seif Ahmed, Ali Hamdi, Khaled Shaban

**Updated**: 2025-09-12T09:58:11Z

**Summary**: The development of medical chatbots in Arabic is significantly constrained by the scarcity of large-scale, high-quality annotated datasets. While prior efforts compiled a dataset of 20,000 Arabic patient-doctor interactions from social media to fine-tune large language models (LLMs), model scalability and generalization remained limited. In this study, we propose a scalable synthetic data augmentation strategy to expand the training corpus to 100,000 records. Using advanced generative AI systems ChatGPT-4o and Gemini 2.5 Pro we generated 80,000 contextually relevant and medically coherent synthetic question-answer pairs grounded in the structure of the original dataset. These synthetic samples were semantically filtered, manually validated, and integrated into the training pipeline. We fine-tuned five LLMs, including Mistral-7B and AraGPT2, and evaluated their performance using BERTScore metrics and expert-driven qualitative assessments. To further analyze the effectiveness of synthetic sources, we conducted an ablation study comparing ChatGPT-4o and Gemini-generated data independently. The results showed that ChatGPT-4o data consistently led to higher F1-scores and fewer hallucinations across all models. Overall, our findings demonstrate the viability of synthetic augmentation as a practical solution for enhancing domain-specific language models in-low resource medical NLP, paving the way for more inclusive, scalable, and accurate Arabic healthcare chatbot systems.

**Link**: [arxiv](http://arxiv.org/abs/2509.10108v1),  [pdf](http://arxiv.org/pdf/2509.10108v1)

**Tags**: cs.CL 



### VARCO-VISION-2.0 Technical Report
**Authors**: Young-rok Cha, Jeongho Ju, SunYoung Park, Jong-Hyeon Lee, Younghyun Yu, Youngjune Kim

**Updated**: 2025-09-12T09:55:56Z

**Summary**: We introduce VARCO-VISION-2.0, an open-weight bilingual vision-language model (VLM) for Korean and English with improved capabilities compared to the previous model VARCO-VISION-14B. The model supports multi-image understanding for complex inputs such as documents, charts, and tables, and delivers layoutaware OCR by predicting both textual content and its spatial location. Trained with a four-stage curriculum with memory-efficient techniques, the model achieves enhanced multimodal alignment, while preserving core language abilities and improving safety via preference optimization. Extensive benchmark evaluations demonstrate strong spatial grounding and competitive results for both languages, with the 14B model achieving 8th place on the OpenCompass VLM leaderboard among models of comparable scale. Alongside the 14B-scale model, we release a 1.7B version optimized for on-device deployment. We believe these models advance the development of bilingual VLMs and their practical applications. Two variants of VARCO-VISION-2.0 are available at Hugging Face: a full-scale 14B model and a lightweight 1.7B model.

**Link**: [arxiv](http://arxiv.org/abs/2509.10105v1),  [pdf](http://arxiv.org/pdf/2509.10105v1)

**Tags**: cs.CV cs.CL 



### GROVE: A Generalized Reward for Learning Open-Vocabulary Physical Skill
**Authors**: Jieming Cui, Tengyu Liu, Ziyu Meng, Jiale Yu, Ran Song, Wei Zhang, Yixin Zhu, Siyuan Huang

**Updated**: 2025-09-12T09:55:20Z

**Summary**: Learning open-vocabulary physical skills for simulated agents presents a significant challenge in artificial intelligence. Current reinforcement learning approaches face critical limitations: manually designed rewards lack scalability across diverse tasks, while demonstration-based methods struggle to generalize beyond their training distribution. We introduce GROVE, a generalized reward framework that enables open-vocabulary physical skill learning without manual engineering or task-specific demonstrations. Our key insight is that Large Language Models(LLMs) and Vision Language Models(VLMs) provide complementary guidance -- LLMs generate precise physical constraints capturing task requirements, while VLMs evaluate motion semantics and naturalness. Through an iterative design process, VLM-based feedback continuously refines LLM-generated constraints, creating a self-improving reward system. To bridge the domain gap between simulation and natural images, we develop Pose2CLIP, a lightweight mapper that efficiently projects agent poses directly into semantic feature space without computationally expensive rendering. Extensive experiments across diverse embodiments and learning paradigms demonstrate GROVE's effectiveness, achieving 22.2% higher motion naturalness and 25.7% better task completion scores while training 8.4x faster than previous methods. These results establish a new foundation for scalable physical skill acquisition in simulated environments.

**Link**: [arxiv](http://arxiv.org/abs/2504.04191v2),  [pdf](http://arxiv.org/pdf/2504.04191v2)

**Tags**: cs.CV cs.RO 



### Generating Energy-Efficient Code via Large-Language Models -- Where are   we now?
**Authors**: Radu Apsan, Vincenzo Stoico, Michel Albonico, Rudra Dhar, Karthik Vaidhyanathan, Ivano Malavolta

**Updated**: 2025-09-12T09:49:46Z

**Summary**: Context. The rise of Large Language Models (LLMs) has led to their widespread adoption in development pipelines. Goal. We empirically assess the energy efficiency of Python code generated by LLMs against human-written code and code developed by a Green software expert. Method. We test 363 solutions to 9 coding problems from the EvoEval benchmark using 6 widespread LLMs with 4 prompting techniques, and comparing them to human-developed solutions. Energy consumption is measured on three different hardware platforms: a server, a PC, and a Raspberry Pi for a total of ~881h (36.7 days). Results. Human solutions are 16% more energy-efficient on the server and 3% on the Raspberry Pi, while LLMs outperform human developers by 25% on the PC. Prompting does not consistently lead to energy savings, where the most energy-efficient prompts vary by hardware platform. The code developed by a Green software expert is consistently more energy-efficient by at least 17% to 30% against all LLMs on all hardware platforms. Conclusions. Even though LLMs exhibit relatively good code generation capabilities, no LLM-generated code was more energy-efficient than that of an experienced Green software developer, suggesting that as of today there is still a great need of human expertise for developing energy-efficient Python code.

**Link**: [arxiv](http://arxiv.org/abs/2509.10099v1),  [pdf](http://arxiv.org/pdf/2509.10099v1)

**Tags**: cs.SE cs.AI 



### Maximising Energy Efficiency in Large-Scale Open RAN: Hybrid xApps and   Digital Twin Integration
**Authors**: Ahmed Al-Tahmeesschi, Yi Chu, Gurdeep Singh, Charles Turyagyenda, Dritan Kaleshi, David Grace, Hamed Ahmadi

**Updated**: 2025-09-12T09:39:15Z

**Summary**: The growing demand for high-speed, ultra-reliable, and low-latency communications in 5G and beyond networks has significantly driven up power consumption, particularly within the Radio Access Network (RAN). This surge in energy demand poses critical operational and sustainability challenges for mobile network operators, necessitating innovative solutions that enhance energy efficiency without compromising Quality of Service (QoS). Open Radio Access Network (O-RAN), spearheaded by the O-RAN Alliance, offers disaggregated, programmable, and intelligent architectures, promoting flexibility, interoperability, and cost-effectiveness. However, this disaggregated approach adds complexity, particularly in managing power consumption across diverse network components such as Open Radio Units (RUs). In this paper, we propose a hybrid xApp leveraging heuristic methods and unsupervised machine learning, integrated with digital twin technology through the TeraVM AI RAN Scenario Generator (AI-RSG). This approach dynamically manages RU sleep modes to effectively reduce energy consumption. Our experimental evaluation in a realistic, large-scale emulated Open RAN scenario demonstrates that the hybrid xApp achieves approximately 13% energy savings, highlighting its practicality and significant potential for real-world deployments without compromising user QoS.

**Link**: [arxiv](http://arxiv.org/abs/2509.10097v1),  [pdf](http://arxiv.org/pdf/2509.10097v1)

**Tags**: cs.NI eess.SP 



### Arabic Large Language Models for Medical Text Generation
**Authors**: Abdulrahman Allam, Seif Ahmed, Ali Hamdi, Ammar Mohammed

**Updated**: 2025-09-12T09:37:26Z

**Summary**: Efficient hospital management systems (HMS) are critical worldwide to address challenges such as overcrowding, limited resources, and poor availability of urgent health care. Existing methods often lack the ability to provide accurate, real-time medical advice, particularly for irregular inputs and underrepresented languages. To overcome these limitations, this study proposes an approach that fine-tunes large language models (LLMs) for Arabic medical text generation. The system is designed to assist patients by providing accurate medical advice, diagnoses, drug recommendations, and treatment plans based on user input. The research methodology required the collection of a unique dataset from social media platforms, capturing real-world medical conversations between patients and doctors. The dataset, which includes patient complaints together with medical advice, was properly cleaned and preprocessed to account for multiple Arabic dialects. Fine-tuning state-of-the-art generative models, such as Mistral-7B-Instruct-v0.2, LLaMA-2-7B, and GPT-2 Medium, optimized the system's ability to generate reliable medical text. Results from evaluations indicate that the fine-tuned Mistral-7B model outperformed the other models, achieving average BERT (Bidirectional Encoder Representations from Transformers) Score values in precision, recall, and F1-scores of 68.5\%, 69.08\%, and 68.5\%, respectively. Comparative benchmarking and qualitative assessments validate the system's ability to produce coherent and relevant medical replies to informal input. This study highlights the potential of generative artificial intelligence (AI) in advancing HMS, offering a scalable and adaptable solution for global healthcare challenges, especially in linguistically and culturally diverse environments.

**Link**: [arxiv](http://arxiv.org/abs/2509.10095v1),  [pdf](http://arxiv.org/pdf/2509.10095v1)

**Tags**: cs.CL 



### FetalSleepNet: A Transfer Learning Framework with Spectral Equalisation   Domain Adaptation for Fetal Sleep Stage Classification
**Authors**: Weitao Tang, Johann Vargas-Calixto, Nasim Katebi, Nhi Tran, Sharmony B. Kelly, Gari D. Clifford, Robert Galinsky, Faezeh Marzbanrad

**Updated**: 2025-09-12T09:19:04Z

**Summary**: Introduction: This study presents FetalSleepNet, the first published deep learning approach to classifying sleep states from the ovine electroencephalogram (EEG). Fetal EEG is complex to acquire and difficult and laborious to interpret consistently. However, accurate sleep stage classification may aid in the early detection of abnormal brain maturation associated with pregnancy complications (e.g. hypoxia or intrauterine growth restriction).   Methods: EEG electrodes were secured onto the ovine dura over the parietal cortices of 24 late gestation fetal sheep. A lightweight deep neural network originally developed for adult EEG sleep staging was trained on the ovine EEG using transfer learning from adult EEG. A spectral equalisation-based domain adaptation strategy was used to reduce cross-domain mismatch.   Results: We demonstrated that while direct transfer performed poorly, full fine tuning combined with spectral equalisation achieved the best overall performance (accuracy: 86.6 percent, macro F1-score: 62.5), outperforming baseline models.   Conclusions: To the best of our knowledge, FetalSleepNet is the first deep learning framework specifically developed for automated sleep staging from the fetal EEG. Beyond the laboratory, the EEG-based sleep stage classifier functions as a label engine, enabling large scale weak/semi supervised labeling and distillation to facilitate training on less invasive signals that can be acquired in the clinic, such as Doppler Ultrasound or electrocardiogram data. FetalSleepNet's lightweight design makes it well suited for deployment in low power, real time, and wearable fetal monitoring systems.

**Link**: [arxiv](http://arxiv.org/abs/2509.10082v1),  [pdf](http://arxiv.org/pdf/2509.10082v1)

**Tags**: eess.SP cs.LG 



### Established Psychometric vs. Ecologically Valid Questionnaires:   Rethinking Psychological Assessments in Large Language Models
**Authors**: Dongmin Choi, Woojung Song, Jongwook Han, Eun-Ju Lee, Yohan Jo

**Updated**: 2025-09-12T09:14:42Z

**Summary**: Researchers have applied established psychometric questionnaires (e.g., BFI, PVQ) to measure the personality traits and values reflected in the responses of Large Language Models (LLMs). However, concerns have been raised about applying these human-designed questionnaires to LLMs. One such concern is their lack of ecological validity--the extent to which survey questions adequately reflect and resemble real-world contexts in which LLMs generate texts in response to user queries. However, it remains unclear how established questionnaires and ecologically valid questionnaires differ in their outcomes, and what insights these differences may provide. In this paper, we conduct a comprehensive comparative analysis of the two types of questionnaires. Our analysis reveals that established questionnaires (1) yield substantially different profiles of LLMs from ecologically valid ones, deviating from the psychological characteristics expressed in the context of user queries, (2) suffer from insufficient items for stable measurement, (3) create misleading impressions that LLMs possess stable constructs, and (4) yield exaggerated profiles for persona-prompted LLMs. Overall, our work cautions against the use of established psychological questionnaires for LLMs. Our code will be released upon publication.

**Link**: [arxiv](http://arxiv.org/abs/2509.10078v1),  [pdf](http://arxiv.org/pdf/2509.10078v1)

**Tags**: cs.CL cs.AI 



### Reframe Your Life Story: Interactive Narrative Therapist and Innovative   Moment Assessment with Large Language Models
**Authors**: Yi Feng, Jiaqi Wang, Wenxuan Zhang, Zhuang Chen, Yutong Shen, Xiyao Xiao, Minlie Huang, Liping Jing, Jian Yu

**Updated**: 2025-09-12T09:08:02Z

**Summary**: Recent progress in large language models (LLMs) has opened new possibilities for mental health support, yet current approaches lack realism in simulating specialized psychotherapy and fail to capture therapeutic progression over time. Narrative therapy, which helps individuals transform problematic life stories into empowering alternatives, remains underutilized due to limited access and social stigma. We address these limitations through a comprehensive framework with two core components. First, INT (Interactive Narrative Therapist) simulates expert narrative therapists by planning therapeutic stages, guiding reflection levels, and generating contextually appropriate expert-like responses. Second, IMA (Innovative Moment Assessment) provides a therapy-centric evaluation method that quantifies effectiveness by tracking "Innovative Moments" (IMs), critical narrative shifts in client speech signaling therapy progress. Experimental results on 260 simulated clients and 230 human participants reveal that INT consistently outperforms standard LLMs in therapeutic quality and depth. We further demonstrate the effectiveness of INT in synthesizing high-quality support conversations to facilitate social applications.

**Link**: [arxiv](http://arxiv.org/abs/2507.20241v2),  [pdf](http://arxiv.org/pdf/2507.20241v2)

**Tags**: cs.CL 



### Benchmarking Classical, Machine Learning, and Bayesian Survival Models   for Clinical Prediction
**Authors**: Irving Gómez-Méndez, Sivakorn Phromsiri, Ittiphat Kijpaisansak, Settawut Chaithurdthum

**Updated**: 2025-09-12T09:06:05Z

**Summary**: Survival analysis is a statistical framework for modeling time-to-event data, particularly valuable in healthcare for predicting outcomes like patient discharge or recurrence. This study implements and compares several survival models - including Weibull, Weibull AFT, Weibull AFT with Gamma Frailty, Cox Proportional Hazards (CoxPH), Random Survival Forest (RSF), and DeepSurv - using a publicly available breast cancer dataset. This study aims to benchmark classical, machine learning, and Bayesian survival models in terms of their predictive performance, interpretability, and suitability for clinical deployment. The models are evaluated using performance metrics such as the Concordance Index (C-index) and the Root Mean Squared Error (RMSE). DeepSurv showed the highest predictive performance, while interpretable models like RSF and Weibull AFT with Gamma Frailty offered competitive results. We also explored the implementation of statistical models from a Bayesian perspective, including frailty models, due to their ability to properly quantify uncertainty. Notably, frailty models are not readily available in standard survival analysis libraries, necessitating custom implementation. Our results demonstrate that interpretable statistical models, when correctly implemented using parameters that are effectively estimated using a Bayesian approach, can perform competitively with modern black-box models. These findings illustrate the trade-offs between model complexity, interpretability, and predictive power, highlighting the potential of Bayesian survival models in clinical decision-making settings.

**Link**: [arxiv](http://arxiv.org/abs/2509.10073v1),  [pdf](http://arxiv.org/pdf/2509.10073v1)

**Tags**: stat.AP 62N02 



### Color Me Correctly: Bridging Perceptual Color Spaces and Text Embeddings   for Improved Diffusion Generation
**Authors**: Sung-Lin Tsai, Bo-Lun Huang, Yu Ting Shen, Cheng Yu Yeo, Chiang Tseng, Bo-Kai Ruan, Wen-Sheng Lien, Hong-Han Shuai

**Updated**: 2025-09-12T08:44:22Z

**Summary**: Accurate color alignment in text-to-image (T2I) generation is critical for applications such as fashion, product visualization, and interior design, yet current diffusion models struggle with nuanced and compound color terms (e.g., Tiffany blue, lime green, hot pink), often producing images that are misaligned with human intent. Existing approaches rely on cross-attention manipulation, reference images, or fine-tuning but fail to systematically resolve ambiguous color descriptions. To precisely render colors under prompt ambiguity, we propose a training-free framework that enhances color fidelity by leveraging a large language model (LLM) to disambiguate color-related prompts and guiding color blending operations directly in the text embedding space. Our method first employs a large language model (LLM) to resolve ambiguous color terms in the text prompt, and then refines the text embeddings based on the spatial relationships of the resulting color terms in the CIELAB color space. Unlike prior methods, our approach improves color accuracy without requiring additional training or external reference images. Experimental results demonstrate that our framework improves color alignment without compromising image quality, bridging the gap between text semantics and visual generation.

**Link**: [arxiv](http://arxiv.org/abs/2509.10058v1),  [pdf](http://arxiv.org/pdf/2509.10058v1)

**Tags**: cs.CV 



### XAgents: A Unified Framework for Multi-Agent Cooperation via IF-THEN   Rules and Multipolar Task Processing Graph
**Authors**: Hailong Yang, Mingxian Gu, Jianqi Wang, Guanjin Wang, Zhaohong Deng

**Updated**: 2025-09-12T08:40:58Z

**Summary**: The rapid advancement of Large Language Models (LLMs) has significantly enhanced the capabilities of Multi-Agent Systems (MAS) in supporting humans with complex, real-world tasks. However, MAS still face challenges in effective task planning when handling highly complex tasks with uncertainty, often resulting in misleading or incorrect outputs that hinder task execution. To address this, we propose XAgents, a unified multi-agent cooperative framework built on a multipolar task processing graph and IF-THEN rules. XAgents uses the multipolar task processing graph to enable dynamic task planning and handle task uncertainty. During subtask processing, it integrates domain-specific IF-THEN rules to constrain agent behaviors, while global rules enhance inter-agent collaboration. We evaluate the performance of XAgents across three distinct datasets, demonstrating that it consistently surpasses state-of-the-art single-agent and multi-agent approaches in both knowledge-typed and logic-typed question-answering tasks. The codes for XAgents are available at: https://github.com/AGI-FHBC/XAgents.

**Link**: [arxiv](http://arxiv.org/abs/2509.10054v1),  [pdf](http://arxiv.org/pdf/2509.10054v1)

**Tags**: cs.AI 



### Exploring a Gamified Personality Assessment Method through Interaction   with LLM Agents Embodying Different Personalities
**Authors**: Baiqiao Zhang, Xiangxian Li, Chao Zhou, Xinyu Gai, Juan Liu, Xue Yang, Xiaojuan Ma, Yong-jin Liu, Yulong Bian

**Updated**: 2025-09-12T08:36:02Z

**Summary**: The low-intrusion and automated personality assessment is receiving increasing attention in psychology and human-computer interaction fields. This study explores an interactive approach for personality assessment, focusing on the multiplicity of personality representation. We propose a framework of Gamified Personality Assessment through Multi-Personality Representations (Multi-PR GPA). The framework leverages Large Language Models to empower virtual agents with different personalities. These agents elicit multifaceted human personality representations through engaging in interactive games. Drawing upon the multi-type textual data generated throughout the interaction, it achieves two modes of personality assessment (i.e., Direct Assessment and Questionnaire-based Assessment) and provides interpretable insights. Grounded in the classic Big Five personality theory, we developed a prototype system and conducted a user study to evaluate the efficacy of Multi-PR GPA. The results affirm the effectiveness of our approach in personality assessment and demonstrate its superior performance when considering the multiplicity of personality representation.

**Link**: [arxiv](http://arxiv.org/abs/2507.04005v3),  [pdf](http://arxiv.org/pdf/2507.04005v3)

**Tags**: cs.HC cs.CY 



### GeoJSON Agents:A Multi-Agent LLM Architecture for Geospatial   Analysis-Function Calling vs Code Generation
**Authors**: Qianqian Luo, Liuchang Xu, Qingming Lin, Sensen Wu, Ruichen Mao, Chao Wang, Hailin Feng, Bo Huang, Zhenhong Du

**Updated**: 2025-09-12T08:26:37Z

**Summary**: LLMs have made substantial progress in task automation and natural language understanding. However, without expertise in GIS, they continue to encounter limitations. To address these issues, we propose GeoJSON Agents-a multi-agent LLM architecture. This framework transforms natural language tasks into structured GeoJSON operation commands and processes spatial data using two widely adopted LLM enhancement techniques: Function Calling and Code Generation. The architecture consists of three components-task parsing, agent collaboration, and result integration-aimed at enhancing both the performance and scalability of GIS automation. The Planner agent interprets natural language tasks into structured GeoJSON commands. Then, specialized Worker agents collaborate according to assigned roles to perform spatial data processing and analysis, either by invoking predefined function APIs or by dynamically generating and executing Python-based spatial analysis code. Finally, the system integrates the outputs from multiple execution rounds into reusable, standards-compliant GeoJSON files. To systematically evaluate the performance of the two approaches, we constructed a benchmark dataset of 70 tasks with varying complexity and conducted experiments using OpenAI's GPT-4o as the core model. Results indicate that the Function Calling-based GeoJSON Agent achieved an accuracy of 85.71%, while the Code Generation-based agent reached 97.14%, both significantly outperforming the best-performing general-purpose model (48.57%). Further analysis reveals that the Code Generation provides greater flexibility, whereas the Function Calling approach offers more stable execution. This study is the first to introduce an LLM multi-agent framework for GeoJSON data and to compare the strengths and limitations of two mainstream LLM enhancement methods, offering new perspectives for improving GeoAI system performance.

**Link**: [arxiv](http://arxiv.org/abs/2509.08863v2),  [pdf](http://arxiv.org/pdf/2509.08863v2)

**Tags**: cs.SE 



### AReaL: A Large-Scale Asynchronous Reinforcement Learning System for   Language Reasoning
**Authors**: Wei Fu, Jiaxuan Gao, Xujie Shen, Chen Zhu, Zhiyu Mei, Chuyi He, Shusheng Xu, Guo Wei, Jun Mei, Jiashu Wang, Tongkai Yang, Binhang Yuan, Yi Wu

**Updated**: 2025-09-12T07:59:18Z

**Summary**: Reinforcement learning (RL) has become a dominant paradigm for training large language models (LLMs), particularly for reasoning tasks. Effective RL for LLMs requires massive parallelization and poses an urgent need for efficient training systems. Most existing large-scale RL systems for LLMs are synchronous, alternating generation and training in a batch setting where rollouts in each training batch are generated by the same model. This approach stabilizes RL training but suffers from severe system-level inefficiency: generation must wait until the longest output in the batch is completed before model updates, resulting in GPU underutilization. We present AReaL, a fully asynchronous RL system that completely decouples generation from training. Rollout workers in AReaL continuously generate new outputs without waiting, while training workers update the model whenever a batch of data is collected. AReaL also incorporates a collection of system-level optimizations, leading to substantially higher GPU utilization. To stabilize RL training, AReaL balances the workload of rollout and training workers to control data staleness, and adopts a staleness-enhanced PPO variant to better handle outdated training samples. Extensive experiments on math and code reasoning benchmarks show that AReaL achieves up to 2.77$\times$ training speedup compared to synchronous systems with the same number of GPUs and matched or improved final performance. The code of AReaL is available at https://github.com/inclusionAI/AReaL/.

**Link**: [arxiv](http://arxiv.org/abs/2505.24298v3),  [pdf](http://arxiv.org/pdf/2505.24298v3)

**Tags**: cs.LG cs.AI 



### LaV-CoT: Language-Aware Visual CoT with Multi-Aspect Reward Optimization   for Real-World Multilingual VQA
**Authors**: Jing Huang, Zhiya Tan, Shutao Gong, Fanwei Zeng, Jianshu Li

**Updated**: 2025-09-12T07:45:44Z

**Summary**: As large vision language models (VLMs) advance, their capabilities in multilingual visual question answering (mVQA) have significantly improved. Chain-of-thought (CoT) reasoning has been proven to enhance interpretability and complex reasoning. However, most existing approaches rely primarily on textual CoT and provide limited support for multilingual multimodal reasoning, constraining their deployment in real-world applications. To address this gap, we introduce \textbf{LaV-CoT}, the first Language-aware Visual CoT framework with Multi-Aspect Reward Optimization. LaV-CoT incorporates an interpretable multi-stage reasoning pipeline consisting of Text Summary with Bounding Box (BBox), Language Identification, Spatial Object-level Captioning, and Step-by-step Logical Reasoning. Following this reasoning pipeline, we design an automated data curation method that generates multilingual CoT annotations through iterative generation, correction, and refinement, enabling scalable and high-quality training data. To improve reasoning and generalization, LaV-CoT adopts a two-stage training paradigm combining Supervised Fine-Tuning (SFT) with Language-aware Group Relative Policy Optimization (GRPO), guided by verifiable multi-aspect rewards including language consistency, structural accuracy, and semantic alignment. Extensive evaluations on public datasets including MMMB, Multilingual MMBench, and MTVQA show that LaV-CoT achieves up to \(\sim\)9.5\% accuracy improvements over open-source baselines of similar size and even surpasses models with 2$\times$ larger scales by \(\sim\)2.6\%. Moreover, LaV-CoT outperforms advanced proprietary models such as GPT-4o-0513 and Gemini-2.5-flash. We further conducted an online A/B test to validate our method on real-world data, highlighting its effectiveness for industrial deployment. Our code is available at this link: \href{https://github.com/HJNVR/LaV-CoT}

**Link**: [arxiv](http://arxiv.org/abs/2509.10026v1),  [pdf](http://arxiv.org/pdf/2509.10026v1)

**Tags**: cs.CV 



### Fractality of Wireless Mesh Networks: Dimensional Effects on Network   Performance
**Authors**: Marat Zaidyn, Sayat Akhtanov, Dana Turlykozhayeva, Symbat Temesheva, Almat Akhmetali, Alisher Skabylov, Nurzhan Ussipov

**Updated**: 2025-09-12T07:35:03Z

**Summary**: Wireless mesh networks (WMNs) depend on the spatial distribution of nodes, which directly influences connectivity, routing efficiency, and overall network performance. Conventional models typically assume uniform or random node placement, which inadequately represent the complex, hierarchical spatial patterns observed in practical deployments. In this study, we present a novel algorithm that constructs WMN topologies with tunable fractal dimensions, allowing precise control over spatial self-similarity. By systematically varying the fractal dimension, the algorithm generates network layouts spanning a continuum of spatial complexities, ranging from sparse fragmented clusters to dense, cohesive structures. Through NS-3 simulations, Key performance metrics including throughput, latency, jitter, and packet delivery ratio were evaluated across a range of fractal dimensions. Comparative evaluations against classical random, small-world, scale-free, grid and hierarchical tree networks models reveal that high-dimensional fractal topologies achieve enhanced resilience and throughput under equivalent conditions. These findings demonstrate the potential of fractal geometry as a design paradigm for scalable and efficient WMN architectures.

**Link**: [arxiv](http://arxiv.org/abs/2506.19366v2),  [pdf](http://arxiv.org/pdf/2506.19366v2)

**Tags**: cs.NI cs.CG 



### RGBlimp-Q: Robotic Gliding Blimp With Moving Mass Control Based on a   Bird-Inspired Continuum Arm
**Authors**: Hao Cheng, Feitian Zhang

**Updated**: 2025-09-12T07:33:46Z

**Summary**: Robotic blimps, as lighter-than-air aerial platforms, offer extended operational duration and enhanced safety in human-robot interactions due to their buoyant lift. However, achieving robust flight performance under environmental airflow disturbances remains a critical challenge, thereby limiting their broader deployment. Inspired by avian flight mechanics, particularly the ability of birds to perch and stabilize in turbulent wind conditions, this article introduces RGBlimp-Q -- a robotic gliding blimp equipped with a bird-inspired continuum arm featuring a novel moving mass actuation mechanism. This continuum arm enables flexible attitude regulation through internal mass redistribution, significantly enhancing the system's resilience to external disturbances. In addition, it facilitates aerial manipulation by employing end-effector claws that interact with the environment in a manner analogous to avian perching behavior. This article presents the design, modeling, and prototyping of RGBlimp-Q, supported by comprehensive experimental evaluation and comparative analysis. To the best of the authors' knowledge, this represents the first interdisciplinary integration of continuum mechanisms into a lighter-than-air robotic platform, where the continuum arm simultaneously functions as both an actuation and manipulation module. This design establishes a novel paradigm for robotic blimps, expanding their applicability to complex and dynamic environments.

**Link**: [arxiv](http://arxiv.org/abs/2406.10810v2),  [pdf](http://arxiv.org/pdf/2406.10810v2)

**Tags**: cs.RO 



### Can Large Language Models Master Complex Card Games?
**Authors**: Wei Wang, Felix Henry, Junzhe Chen, Dan Zhang, Shiyu Huang, Evgeny Kharlamov, Jie Tang

**Updated**: 2025-09-12T07:26:28Z

**Summary**: Complex games have long been an important benchmark for testing the progress of artificial intelligence algorithms. AlphaGo, AlphaZero, and MuZero have defeated top human players in Go and Chess, garnering widespread societal attention towards artificial intelligence. Concurrently, large language models (LLMs) have exhibited remarkable capabilities across various tasks, raising the question of whether LLMs can achieve similar success in complex games. In this paper, we explore the potential of LLMs in mastering complex card games. We systematically assess the learning capabilities of LLMs across eight diverse card games, evaluating the impact of fine-tuning on high-quality gameplay data, and examining the models' ability to retain general capabilities while mastering these games. Our findings indicate that: (1) LLMs can approach the performance of strong game AIs through supervised fine-tuning on high-quality data, (2) LLMs can master multiple complex card games simultaneously, with performance augmentation for games with similar rules and conflicts for dissimilar ones, and (3) LLMs experience a decline in general capabilities when mastering complex games, but this decline can be mitigated by integrating a certain amount of general instruction data. The evaluation results demonstrate strong learning ability and versatility of LLMs.

**Link**: [arxiv](http://arxiv.org/abs/2509.01328v2),  [pdf](http://arxiv.org/pdf/2509.01328v2)

**Tags**: cs.CL 



### GAMA: A General Anonymizing Multi-Agent System for Privacy Preservation   Enhanced by Domain Rules and Disproof Method
**Authors**: Hailong Yang, Renhuo Zhao, Guanjin Wang, Zhaohong Deng

**Updated**: 2025-09-12T07:22:49Z

**Summary**: With the rapid advancement of Large Language Model (LLM), LLM-based agents exhibit exceptional abilities in understanding and generating natural language, facilitating human-like collaboration and information transmission in LLM-based Multi-Agent System (MAS). High-performance LLMs are often hosted on remote servers in public spaces. When tasks involve privacy data, MAS cannot securely utilize these LLMs without implementing privacy-preserving mechanisms. To address this challenge, we propose a General Anonymizing Multi-Agent system (GAMA), which divides the agents' workspace into private and public spaces and protects privacy through the anonymizing mechanism. In the private space, agents handle sensitive data, while in the public space, only anonymized data is utilized. GAMA incorporates two key modules to mitigate semantic loss caused by anonymization: Domain-Rule-based Knowledge Enhancement (DRKE) and Disproof-based Logic Enhancement (DLE). We evaluate GAMA on two public question-answering datasets: Trivia Creative Writing and Logic Grid Puzzle. The results demonstrate that GAMA has superior performance compared to the state-of-the-art models. To further assess its privacy-preserving capabilities, we designed two new datasets: Knowledge Privacy Preservation and Logic Privacy Preservation. The final results highlight GAMA's exceptional effectiveness in both task processing and privacy preservation.

**Link**: [arxiv](http://arxiv.org/abs/2509.10018v1),  [pdf](http://arxiv.org/pdf/2509.10018v1)

**Tags**: cs.AI 



### OneCAT: Decoder-Only Auto-Regressive Model for Unified Understanding and   Generation
**Authors**: Han Li, Xinyu Peng, Yaoming Wang, Zelin Peng, Xin Chen, Rongxiang Weng, Jingang Wang, Xunliang Cai, Wenrui Dai, Hongkai Xiong

**Updated**: 2025-09-12T07:12:41Z

**Summary**: We introduce OneCAT, a unified multimodal model that seamlessly integrates understanding, generation, and editing within a novel, pure decoder-only transformer architecture. Our framework uniquely eliminates the need for external components such as Vision Transformers (ViT) or vision tokenizer during inference, leading to significant efficiency gains, especially for high-resolution inputs. This is achieved through a modality-specific Mixture-of-Experts (MoE) structure trained with a single autoregressive (AR) objective, which also natively supports dynamic resolutions. Furthermore, we pioneer a multi-scale visual autoregressive mechanism within the Large Language Model (LLM) that drastically reduces decoding steps compared to diffusion-based methods while maintaining state-of-the-art performance. Our findings demonstrate the powerful potential of pure autoregressive modeling as a sufficient and elegant foundation for unified multimodal intelligence. As a result, OneCAT sets a new performance standard, outperforming existing open-source unified multimodal models across benchmarks for multimodal generation, editing, and understanding.

**Link**: [arxiv](http://arxiv.org/abs/2509.03498v2),  [pdf](http://arxiv.org/pdf/2509.03498v2)

**Tags**: cs.CV 



### Multi-Intent Recognition in Dialogue Understanding: A Comparison Between   Smaller Open-Source LLMs
**Authors**: Adnan Ahmad, Philine Kowol, Stefan Hillmann, Sebastian Möller

**Updated**: 2025-09-12T07:10:55Z

**Summary**: In this paper, we provide an extensive analysis of multi-label intent classification using Large Language Models (LLMs) that are open-source, publicly available, and can be run in consumer hardware. We use the MultiWOZ 2.1 dataset, a benchmark in the dialogue system domain, to investigate the efficacy of three popular open-source pre-trained LLMs, namely LLama2-7B-hf, Mistral-7B-v0.1, and Yi-6B. We perform the classification task in a few-shot setup, giving 20 examples in the prompt with some instructions. Our approach focuses on the differences in performance of these models across several performance metrics by methodically assessing these models on multi-label intent classification tasks. Additionally, we compare the performance of the instruction-based fine-tuning approach with supervised learning using the smaller transformer model BertForSequenceClassification as a baseline. To evaluate the performance of the models, we use evaluation metrics like accuracy, precision, and recall as well as micro, macro, and weighted F1 score. We also report the inference time, VRAM requirements, etc. The Mistral-7B-v0.1 outperforms two other generative models on 11 intent classes out of 14 in terms of F-Score, with a weighted average of 0.50. It also has relatively lower Humming Loss and higher Jaccard Similarity, making it the winning model in the few-shot setting. We find BERT based supervised classifier having superior performance compared to the best performing few-shot generative LLM. The study provides a framework for small open-source LLMs in detecting complex multi-intent dialogues, enhancing the Natural Language Understanding aspect of task-oriented chatbots.

**Link**: [arxiv](http://arxiv.org/abs/2509.10010v1),  [pdf](http://arxiv.org/pdf/2509.10010v1)

**Tags**: cs.CL cs.HC 



### Input-Time Scaling
**Authors**: Rapheal Huang, Weilong Guo

**Updated**: 2025-09-12T07:04:59Z

**Summary**: Current Large Language Models (LLMs) are usually post-trained on large-scale carefully curated datasets (data & training scaling) and doing reasoning in test time (inference time scaling). In this work, we present a new scaling paradigm, Input-Time Scaling, to complement previous scaling methods by putting resources on queries (input time). During training and testing, we utilize meta-knowledge from LLMs to refine inputs with different strategies. We also discover a new phenomenon, train-test co-design. It requires us to apply query strategies during training and testing as a whole. Only applying strategies on training or testing would seriously degrade the performance gained. We are also surprised to find that seemingly low data quality datasets can perform better. We can get the best performance even by adding irrelevant information to the queries, with randomly selected 1k examples from a minimally filtered dataset. These findings contradict the widely held inductive bias, "garbage in, garbage out". Curating datasets with seemingly high-quality data can even potentially limit the performance ceiling. In addition, models trained on more data with similar quality (15k VS 1k) perform worse, the intuition of simply scaling the size should also be carefully inspected. The good news is that our findings are compatible with the Less is More phenomenon. 1K examples are enough to invoke high-level reasoning ability. With experiments on Qwen2.5-32B-Instruct, we are able to reach SOTA performance among 32B models on AIME24(76.7%) and AIME25(76.7%) pass@1. We can further achieve AIME24(76.7%) and AIME25(80%) with a majority vote of three models. Starting from DeepSeek-R1-Distill-Qwen-32B, the result would be 90.0% on AIME24 and 80.0% on AIME25. To facilitate reproducibility and further research, we are working on open-source our datasets, data pipelines, evaluation results, and checkpoints.

**Link**: [arxiv](http://arxiv.org/abs/2508.13654v4),  [pdf](http://arxiv.org/pdf/2508.13654v4)

**Tags**: cs.LG cs.AI cs.CL 



### TUNI: Real-time RGB-T Semantic Segmentation with Unified Multi-Modal   Feature Extraction and Cross-Modal Feature Fusion
**Authors**: Xiaodong Guo, Tong Liu, Yike Li, Zi'ang Lin, Zhihong Deng

**Updated**: 2025-09-12T07:02:45Z

**Summary**: RGB-thermal (RGB-T) semantic segmentation improves the environmental perception of autonomous platforms in challenging conditions. Prevailing models employ encoders pre-trained on RGB images to extract features from both RGB and infrared inputs, and design additional modules to achieve cross-modal feature fusion. This results in limited thermal feature extraction and suboptimal cross-modal fusion, while the redundant encoders further compromises the model's real-time efficiency. To address the above issues, we propose TUNI, with an RGB-T encoder consisting of multiple stacked blocks that simultaneously perform multi-modal feature extraction and cross-modal fusion. By leveraging large-scale pre-training with RGB and pseudo-thermal data, the RGB-T encoder learns to integrate feature extraction and fusion in a unified manner. By slimming down the thermal branch, the encoder achieves a more compact architecture. Moreover, we introduce an RGB-T local module to strengthen the encoder's capacity for cross-modal local feature fusion. The RGB-T local module employs adaptive cosine similarity to selectively emphasize salient consistent and distinct local features across RGB-T modalities. Experimental results show that TUNI achieves competitive performance with state-of-the-art models on FMB, PST900 and CART, with fewer parameters and lower computational cost. Meanwhile, it achieves an inference speed of 27 FPS on a Jetson Orin NX, demonstrating its real-time capability in deployment. Codes are available at https://github.com/xiaodonguo/TUNI.

**Link**: [arxiv](http://arxiv.org/abs/2509.10005v1),  [pdf](http://arxiv.org/pdf/2509.10005v1)

**Tags**: cs.CV 



### Unsupervised Hallucination Detection by Inspecting Reasoning Processes
**Authors**: Ponhvoan Srey, Xiaobao Wu, Anh Tuan Luu

**Updated**: 2025-09-12T06:58:17Z

**Summary**: Unsupervised hallucination detection aims to identify hallucinated content generated by large language models (LLMs) without relying on labeled data. While unsupervised methods have gained popularity by eliminating labor-intensive human annotations, they frequently rely on proxy signals unrelated to factual correctness. This misalignment biases detection probes toward superficial or non-truth-related aspects, limiting generalizability across datasets and scenarios. To overcome these limitations, we propose IRIS, an unsupervised hallucination detection framework, leveraging internal representations intrinsic to factual correctness. IRIS prompts the LLM to carefully verify the truthfulness of a given statement, and obtain its contextualized embedding as informative features for training. Meanwhile, the uncertainty of each response is considered a soft pseudolabel for truthfulness. Experimental results demonstrate that IRIS consistently outperforms existing unsupervised methods. Our approach is fully unsupervised, computationally low cost, and works well even with few training data, making it suitable for real-time detection.

**Link**: [arxiv](http://arxiv.org/abs/2509.10004v1),  [pdf](http://arxiv.org/pdf/2509.10004v1)

**Tags**: cs.CL cs.AI 



### Polish-English medical knowledge transfer: A new benchmark and results
**Authors**: Łukasz Grzybowski, Jakub Pokrywka, Michał Ciesiółka, Jeremi I. Kaczmarek, Marek Kubis

**Updated**: 2025-09-12T06:49:21Z

**Summary**: Large Language Models (LLMs) have demonstrated significant potential in handling specialized tasks, including medical problem-solving. However, most studies predominantly focus on English-language contexts. This study introduces a novel benchmark dataset based on Polish medical licensing and specialization exams (LEK, LDEK, PES) taken by medical doctor candidates and practicing doctors pursuing specialization. The dataset was web-scraped from publicly available resources provided by the Medical Examination Center and the Chief Medical Chamber. It comprises over 24,000 exam questions, including a subset of parallel Polish-English corpora, where the English portion was professionally translated by the examination center for foreign candidates. By creating a structured benchmark from these existing exam questions, we systematically evaluate state-of-the-art LLMs, including general-purpose, domain-specific, and Polish-specific models, and compare their performance against human medical students. Our analysis reveals that while models like GPT-4o achieve near-human performance, significant challenges persist in cross-lingual translation and domain-specific understanding. These findings underscore disparities in model performance across languages and medical specialties, highlighting the limitations and ethical considerations of deploying LLMs in clinical practice.

**Link**: [arxiv](http://arxiv.org/abs/2412.00559v2),  [pdf](http://arxiv.org/pdf/2412.00559v2)

**Tags**: cs.CL cs.AI 



### Taming Volatility: Stable and Private QUIC Classification with Federated   Learning
**Authors**: Richard Jozsa, Karel Hynek, Adrian Pekar

**Updated**: 2025-09-12T06:47:07Z

**Summary**: Federated Learning (FL) is a promising approach for privacy-preserving network traffic analysis, but its practical deployment is challenged by the non-IID nature of real-world data. While prior work has addressed statistical heterogeneity, the impact of temporal traffic volatility-the natural daily ebb and flow of network activity-on model stability remains largely unexplored. This volatility can lead to inconsistent data availability at clients, destabilizing the entire training process. In this paper, we systematically address the problem of temporal volatility in federated QUIC classification. We first demonstrate the instability of standard FL in this dynamic setting. We then propose and evaluate a client-side data buffer as a practical mechanism to ensure stable and consistent local training, decoupling it from real-time traffic fluctuations. Using the real-world CESNET-QUIC22 dataset partitioned into 14 autonomous clients, we then demonstrate that this approach enables robust convergence. Our results show that a stable federated system achieves a 95.2% F1 score, a mere 2.3 percentage points below a non-private centralized model. This work establishes a blueprint for building operationally stable FL systems for network management, proving that the challenges of dynamic network environments can be overcome with targeted architectural choices.

**Link**: [arxiv](http://arxiv.org/abs/2509.09997v1),  [pdf](http://arxiv.org/pdf/2509.09997v1)

**Tags**: cs.NI 



### Finite Scalar Quantization Enables Redundant and Transmission-Robust   Neural Audio Compression at Low Bit-rates
**Authors**: Harry Julian, Rachel Beeson, Lohith Konathala, Johanna Ulin, Jiameng Gao

**Updated**: 2025-09-12T06:43:25Z

**Summary**: Neural Audio Codecs (NACs) have become increasingly adopted in speech processing tasks due to their excellent rate-distortion performance and compatibility with Large Language Models (LLMs) as discrete feature representations for audio generation. While most existing codecs rely on Residual Vector Quantization (RVQ), Finite Scalar Quantization (FSQ) has recently emerged as a compelling alternative that simplifies training and natively supports single codebooks. We introduce NeuCodec, an FSQ-based NAC, and show that FSQ encodes baked-in redundancy which produces an encoding which is robust when transmitted through noisy channels. First, through an encoder distillation experiment, we show that two different encoders can learn to encode identical audio into vastly different code sequences whilst maintaining comparable reconstruction quality with the same quantizer and decoder. Second, we demonstrate that FSQ has vastly superior bit-level perturbation robustness by comparing the performance of RVQ and FSQ codecs when simulating the transmission of code sequences through a noisy channel.

**Link**: [arxiv](http://arxiv.org/abs/2509.09550v2),  [pdf](http://arxiv.org/pdf/2509.09550v2)

**Tags**: cs.SD cs.LG 



### Humans Hallucinate Too: Language Models Identify and Correct Subjective   Annotation Errors With Label-in-a-Haystack Prompts
**Authors**: Georgios Chochlakis, Peter Wu, Arjun Bedi, Marcus Ma, Kristina Lerman, Shrikanth Narayanan

**Updated**: 2025-09-12T06:41:58Z

**Summary**: Modeling complex subjective tasks in Natural Language Processing, such as recognizing emotion and morality, is considerably challenging due to significant variation in human annotations. This variation often reflects reasonable differences in semantic interpretations rather than mere noise, necessitating methods to distinguish between legitimate subjectivity and error. We address this challenge by exploring label verification in these contexts using Large Language Models (LLMs). First, we propose a simple In-Context Learning binary filtering baseline that estimates the reasonableness of a document-label pair. We then introduce the Label-in-a-Haystack setting: the query and its label(s) are included in the demonstrations shown to LLMs, which are prompted to predict the label(s) again, while receiving task-specific instructions (e.g., emotion recognition) rather than label copying. We show how the failure to copy the label(s) to the output of the LLM are task-relevant and informative. Building on this, we propose the Label-in-a-Haystack Rectification (LiaHR) framework for subjective label correction: when the model outputs diverge from the reference gold labels, we assign the generated labels to the example instead of discarding it. This approach can be integrated into annotation pipelines to enhance signal-to-noise ratios. Comprehensive analyses, human evaluations, and ecological validity studies verify the utility of LiaHR for label correction. Code is available at https://github.com/gchochla/liahr.

**Link**: [arxiv](http://arxiv.org/abs/2505.17222v2),  [pdf](http://arxiv.org/pdf/2505.17222v2)

**Tags**: cs.CL 



### QuantAgent: Price-Driven Multi-Agent LLMs for High-Frequency Trading
**Authors**: Fei Xiong, Xiang Zhang, Aosong Feng, Siqi Sun, Chenyu You

**Updated**: 2025-09-12T06:35:40Z

**Summary**: Recent advances in Large Language Models (LLMs) have demonstrated impressive capabilities in financial reasoning and market understanding. Multi-agent LLM frameworks such as TradingAgent and FINMEM augment these models to long-horizon investment tasks, leveraging fundamental and sentiment-based inputs for strategic decision-making. However, such systems are ill-suited for the high-speed, precision-critical demands of High-Frequency Trading (HFT). HFT requires rapid, risk-aware decisions based on structured, short-horizon signals, including technical indicators, chart patterns, and trend-based features, distinct from the long-term semantic reasoning typical of traditional financial LLM applications. To this end, we introduce QuantAgent, the first multi-agent LLM framework explicitly designed for high-frequency algorithmic trading. The system decomposes trading into four specialized agents, Indicator, Pattern, Trend, and Risk, each equipped with domain-specific tools and structured reasoning capabilities to capture distinct aspects of market dynamics over short temporal windows. In zero-shot evaluations across ten financial instruments, including Bitcoin and Nasdaq futures, QuantAgent demonstrates superior performance in both predictive accuracy and cumulative return over 4-hour trading intervals, outperforming strong neural and rule-based baselines. Our findings suggest that combining structured financial priors with language-native reasoning unlocks new potential for traceable, real-time decision systems in high-frequency financial markets.

**Link**: [arxiv](http://arxiv.org/abs/2509.09995v1),  [pdf](http://arxiv.org/pdf/2509.09995v1)

**Tags**: cs.CE 



### SPECS: Specificity-Enhanced CLIP-Score for Long Image Caption Evaluation
**Authors**: Xiaofu Chen, Israfel Salazar, Yova Kementchedjhieva

**Updated**: 2025-09-12T05:44:35Z

**Summary**: As interest grows in generating long, detailed image captions, standard evaluation metrics become increasingly unreliable. N-gram-based metrics though efficient, fail to capture semantic correctness. Representational Similarity (RS) metrics, designed to address this, initially saw limited use due to high computational costs, while today, despite advances in hardware, they remain unpopular due to low correlation to human judgments. Meanwhile, metrics based on large language models (LLMs) show strong correlation with human judgments, but remain too expensive for iterative use during model development.   We introduce SPECS (Specificity-Enhanced CLIPScore), a reference-free RS metric tailored to long image captioning. SPECS modifies CLIP with a new objective that emphasizes specificity: rewarding correct details and penalizing incorrect ones. We show that SPECS matches the performance of open-source LLM-based metrics in correlation to human judgments, while being far more efficient. This makes it a practical alternative for iterative checkpoint evaluation during image captioning model development.Our code can be found at https://github.com/mbzuai-nlp/SPECS.

**Link**: [arxiv](http://arxiv.org/abs/2509.03897v2),  [pdf](http://arxiv.org/pdf/2509.03897v2)

**Tags**: cs.CV cs.CL 



### Development of Automated Software Design Document Review Methods Using   Large Language Models
**Authors**: Takasaburo Fukuda, Takao Nakagawa, Keisuke Miyazaki, Susumu Tokumoto

**Updated**: 2025-09-12T05:34:48Z

**Summary**: In this study, we explored an approach to automate the review process of software design documents by using LLM. We first analyzed the review methods of design documents and organized 11 review perspectives. Additionally, we analyzed the issues of utilizing LLMs for these 11 review perspectives and determined which perspectives can be reviewed by current general-purpose LLMs instead of humans. For the reviewable perspectives, we specifically developed new techniques to enable LLMs to comprehend complex design documents that include table data. For evaluation, we conducted experiments using GPT to assess the consistency of design items and descriptions across different design documents in the design process used in actual business operations. Our results confirmed that LLMs can be utilized to identify inconsistencies in software design documents during the review process.

**Link**: [arxiv](http://arxiv.org/abs/2509.09975v1),  [pdf](http://arxiv.org/pdf/2509.09975v1)

**Tags**: cs.SE 



### Drone-Based Multispectral Imaging and Deep Learning for Timely Detection   of Branched Broomrape in Tomato Farms
**Authors**: Mohammadreza Narimani, Alireza Pourreza, Ali Moghimi, Mohsen Mesgaran, Parastoo Farajpoor, Hamid Jafarbiglu

**Updated**: 2025-09-12T05:16:56Z

**Summary**: This study addresses the escalating threat of branched broomrape (Phelipanche ramosa) to California's tomato industry, which supplies over 90 percent of U.S. processing tomatoes. The parasite's largely underground life cycle makes early detection difficult, while conventional chemical controls are costly, environmentally harmful, and often ineffective. To address this, we combined drone-based multispectral imagery with Long Short-Term Memory (LSTM) deep learning networks, using the Synthetic Minority Over-sampling Technique (SMOTE) to handle class imbalance. Research was conducted on a known broomrape-infested tomato farm in Woodland, Yolo County, CA, across five key growth stages determined by growing degree days (GDD). Multispectral images were processed to isolate tomato canopy reflectance. At 897 GDD, broomrape could be detected with 79.09 percent overall accuracy and 70.36 percent recall without integrating later stages. Incorporating sequential growth stages with LSTM improved detection substantially. The best-performing scenario, which integrated all growth stages with SMOTE augmentation, achieved 88.37 percent overall accuracy and 95.37 percent recall. These results demonstrate the strong potential of temporal multispectral analysis and LSTM networks for early broomrape detection. While further real-world data collection is needed for practical deployment, this study shows that UAV-based multispectral sensing coupled with deep learning could provide a powerful precision agriculture tool to reduce losses and improve sustainability in tomato production.

**Link**: [arxiv](http://arxiv.org/abs/2509.09972v1),  [pdf](http://arxiv.org/pdf/2509.09972v1)

**Tags**: eess.IV cs.AI cs.CV cs.LG 



### Securing LLM-Generated Embedded Firmware through AI Agent-Driven   Validation and Patching
**Authors**: Seyed Moein Abtahi, Akramul Azim

**Updated**: 2025-09-12T05:15:35Z

**Summary**: Large Language Models (LLMs) show promise in generating firmware for embedded systems, but often introduce security flaws and fail to meet real-time performance constraints. This paper proposes a three-phase methodology that combines LLM-based firmware generation with automated security validation and iterative refinement in a virtualized environment. Using structured prompts, models like GPT-4 generate firmware for networking and control tasks, deployed on FreeRTOS via QEMU. These implementations are tested using fuzzing, static analysis, and runtime monitoring to detect vulnerabilities such as buffer overflows (CWE-120), race conditions (CWE-362), and denial-of-service threats (CWE-400). Specialized AI agents for Threat Detection, Performance Optimization, and Compliance Verification collaborate to improve detection and remediation. Identified issues are categorized using CWE, then used to prompt targeted LLM-generated patches in an iterative loop. Experiments show a 92.4\% Vulnerability Remediation Rate (37.3\% improvement), 95.8\% Threat Model Compliance, and 0.87 Security Coverage Index. Real-time metrics include 8.6ms worst-case execution time and 195{\mu}s jitter. This process enhances firmware security and performance while contributing an open-source dataset for future research.

**Link**: [arxiv](http://arxiv.org/abs/2509.09970v1),  [pdf](http://arxiv.org/pdf/2509.09970v1)

**Tags**: cs.CR cs.AI 



### Large Language Models Meet Legal Artificial Intelligence: A Survey
**Authors**: Zhitian Hou, Zihan Ye, Nanli Zeng, Tianyong Hao, Kun Zeng

**Updated**: 2025-09-12T05:08:11Z

**Summary**: Large Language Models (LLMs) have significantly advanced the development of Legal Artificial Intelligence (Legal AI) in recent years, enhancing the efficiency and accuracy of legal tasks. To advance research and applications of LLM-based approaches in legal domain, this paper provides a comprehensive review of 16 legal LLMs series and 47 LLM-based frameworks for legal tasks, and also gather 15 benchmarks and 29 datasets to evaluate different legal capabilities. Additionally, we analyse the challenges and discuss future directions for LLM-based approaches in the legal domain. We hope this paper provides a systematic introduction for beginners and encourages future research in this field. Resources are available at https://github.com/ZhitianHou/LLMs4LegalAI.

**Link**: [arxiv](http://arxiv.org/abs/2509.09969v1),  [pdf](http://arxiv.org/pdf/2509.09969v1)

**Tags**: cs.CL cs.AI 



### Integrating Diffusion-based Multi-task Learning with Online   Reinforcement Learning for Robust Quadruped Robot Control
**Authors**: Xinyao Qin, Xiaoteng Ma, Yang Qi, Qihan Liu, Chuanyi Xue, Ning Gui, Qinyu Dong, Jun Yang, Bin Liang

**Updated**: 2025-09-12T04:53:53Z

**Summary**: Recent research has highlighted the powerful capabilities of imitation learning in robotics. Leveraging generative models, particularly diffusion models, these approaches offer notable advantages such as strong multi-task generalization, effective language conditioning, and high sample efficiency. While their application has been successful in manipulation tasks, their use in legged locomotion remains relatively underexplored, mainly due to compounding errors that affect stability and difficulties in task transition under limited data. Online reinforcement learning (RL) has demonstrated promising results in legged robot control in the past years, providing valuable insights to address these challenges. In this work, we propose DMLoco, a diffusion-based framework for quadruped robots that integrates multi-task pretraining with online PPO finetuning to enable language-conditioned control and robust task transitions. Our approach first pretrains the policy on a diverse multi-task dataset using diffusion models, enabling language-guided execution of various skills. Then, it finetunes the policy in simulation to ensure robustness and stable task transition during real-world deployment. By utilizing Denoising Diffusion Implicit Models (DDIM) for efficient sampling and TensorRT for optimized deployment, our policy runs onboard at 50Hz, offering a scalable and efficient solution for adaptive, language-guided locomotion on resource-constrained robotic platforms.

**Link**: [arxiv](http://arxiv.org/abs/2507.05674v2),  [pdf](http://arxiv.org/pdf/2507.05674v2)

**Tags**: cs.RO 



### Déjà Vu: Multilingual LLM Evaluation through the Lens of Machine   Translation Evaluation
**Authors**: Julia Kreutzer, Eleftheria Briakou, Sweta Agrawal, Marzieh Fadaee, Kocmi Tom

**Updated**: 2025-09-12T04:48:46Z

**Summary**: Generation capabilities and language coverage of multilingual large language models (mLLMs) are advancing rapidly. However, evaluation practices for generative abilities of mLLMs are still lacking comprehensiveness, scientific rigor, and consistent adoption across research labs, which undermines their potential to meaningfully guide mLLM development. We draw parallels with machine translation (MT) evaluation, a field that faced similar challenges and has, over decades, developed transparent reporting standards and reliable evaluations for multilingual generative models. Through targeted experiments across key stages of the generative evaluation pipeline, we demonstrate how best practices from MT evaluation can deepen the understanding of quality differences between models. Additionally, we identify essential components for robust meta-evaluation of mLLMs, ensuring the evaluation methods themselves are rigorously assessed. We distill these insights into a checklist of actionable recommendations for mLLM research and development.

**Link**: [arxiv](http://arxiv.org/abs/2504.11829v4),  [pdf](http://arxiv.org/pdf/2504.11829v4)

**Tags**: cs.CL cs.AI 



### Local-Cloud Inference Offloading for LLMs in Multi-Modal, Multi-Task,   Multi-Dialogue Settings
**Authors**: Liangqi Yuan, Dong-Jun Han, Shiqiang Wang, Christopher G. Brinton

**Updated**: 2025-09-12T04:41:28Z

**Summary**: Compared to traditional machine learning models, recent large language models (LLMs) can exhibit multi-task-solving capabilities through multiple dialogues and multi-modal data sources. These unique characteristics of LLMs, together with their large model size, make their deployment more challenging. Specifically, (i) deploying LLMs on local devices faces computational, memory, and energy resource issues, while (ii) deploying them in the cloud cannot guarantee real-time service and incurs communication/usage costs. In this paper, we design TMO, a local-cloud LLM inference system with Three-M Offloading: Multi-modal, Multi-task, and Multi-dialogue. TMO incorporates (i) a lightweight local LLM that can process simple tasks at high speed and (ii) a large-scale cloud LLM that can handle multi-modal data sources. We develop a resource-constrained reinforcement learning (RCRL) strategy for TMO that optimizes the inference location (i.e., local vs. cloud) and multi-modal data sources to use for each task/dialogue, aiming to maximize the long-term reward (response quality, latency, and usage cost) while adhering to resource constraints. We also contribute M4A1, a new dataset we curated that contains reward and cost metrics across multiple modality, task, dialogue, and LLM configurations, enabling evaluation of offloading decisions. We demonstrate the effectiveness of TMO compared to several exploration-decision and LLM-as-Agent baselines, showing significant improvements in latency, cost, and response quality.

**Link**: [arxiv](http://arxiv.org/abs/2502.11007v3),  [pdf](http://arxiv.org/pdf/2502.11007v3)

**Tags**: cs.LG cs.DC 



### Limited Reference, Reliable Generation: A Two-Component Framework for   Tabular Data Generation in Low-Data Regimes
**Authors**: Mingxuan Jiang, Yongxin Wang, Ziyue Dai, Yicun Liu, Hongyi Nie, Sen Liu, Hongfeng Chai

**Updated**: 2025-09-12T04:34:46Z

**Summary**: Synthetic tabular data generation is increasingly essential in data management, supporting downstream applications when real-world and high-quality tabular data is insufficient. Existing tabular generation approaches, such as generative adversarial networks (GANs), diffusion models, and fine-tuned Large Language Models (LLMs), typically require sufficient reference data, limiting their effectiveness in domain-specific databases with scarce records. While prompt-based LLMs offer flexibility without parameter tuning, they often fail to capture dataset-specific feature-label dependencies and generate redundant data, leading to degradation in downstream task performance. To overcome these issues, we propose ReFine, a framework that (i) derives symbolic "if-then" rules from interpretable models and embeds them into prompts to explicitly guide generation toward domain-specific feature distribution, and (ii) applies a dual-granularity filtering strategy that suppresses over-sampling patterns and selectively refines rare but informative samples to reduce distributional imbalance. Extensive experiments on various regression and classification benchmarks demonstrate that ReFine consistently outperforms state-of-the-art methods, achieving up to 0.44 absolute improvement in R-squared for regression and 10.0 percent relative improvement in F1 score for classification tasks.

**Link**: [arxiv](http://arxiv.org/abs/2509.09960v1),  [pdf](http://arxiv.org/pdf/2509.09960v1)

**Tags**: cs.LG cs.AI 



### Oyster-I: Beyond Refusal -- Constructive Safety Alignment for   Responsible Language Models
**Authors**: Ranjie Duan, Jiexi Liu, Xiaojun Jia, Shiji Zhao, Ruoxi Cheng, Fengxiang Wang, Cheng Wei, Yong Xie, Chang Liu, Defeng Li, Yinpeng Dong, Yichi Zhang, Yuefeng Chen, Chongwen Wang, Xingjun Ma, Xingxing Wei, Yang Liu, Hang Su, Jun Zhu, Xinfeng Li, Yitong Sun, Jie Zhang, Jinzhao Hu, Sha Xu, Yitong Yang, Jialing Tao, Hui Xue

**Updated**: 2025-09-12T04:23:22Z

**Summary**: Large language models (LLMs) typically deploy safety mechanisms to prevent harmful content generation. Most current approaches focus narrowly on risks posed by malicious actors, often framing risks as adversarial events and relying on defensive refusals. However, in real-world settings, risks also come from non-malicious users seeking help while under psychological distress (e.g., self-harm intentions). In such cases, the model's response can strongly influence the user's next actions. Simple refusals may lead them to repeat, escalate, or move to unsafe platforms, creating worse outcomes. We introduce Constructive Safety Alignment (CSA), a human-centric paradigm that protects against malicious misuse while actively guiding vulnerable users toward safe and helpful results. Implemented in Oyster-I (Oy1), CSA combines game-theoretic anticipation of user reactions, fine-grained risk boundary discovery, and interpretable reasoning control, turning safety into a trust-building process. Oy1 achieves state-of-the-art safety among open models while retaining high general capabilities. On our Constructive Benchmark, it shows strong constructive engagement, close to GPT-5, and unmatched robustness on the Strata-Sword jailbreak dataset, nearing GPT-o1 levels. By shifting from refusal-first to guidance-first safety, CSA redefines the model-user relationship, aiming for systems that are not just safe, but meaningfully helpful. We release Oy1, code, and the benchmark to support responsible, user-centered AI.

**Link**: [arxiv](http://arxiv.org/abs/2509.01909v4),  [pdf](http://arxiv.org/pdf/2509.01909v4)

**Tags**: cs.AI cs.CL cs.CY cs.HC cs.SC 



### Adaptive Token Merging for Efficient Transformer Semantic Communication   at the Edge
**Authors**: Omar Erak, Omar Alhussein, Hatem Abou-Zeid, Mehdi Bennis, Sami Muhaidat

**Updated**: 2025-09-12T04:11:59Z

**Summary**: Large-scale transformers are central to modern semantic communication, yet their high computational and communication costs hinder deployment on resource-constrained edge devices. This paper introduces a training-free framework for adaptive token merging, a novel mechanism that compresses transformer representations at runtime by selectively merging semantically redundant tokens under per-layer similarity thresholds. Unlike prior fixed-ratio reduction, our approach couples merging directly to input redundancy, enabling data-dependent adaptation that balances efficiency and task relevance without retraining. We cast the discovery of merging strategies as a multi-objective optimization problem and leverage Bayesian optimization to obtain Pareto-optimal trade-offs between accuracy, inference cost, and communication cost. On ImageNet classification, we match the accuracy of the unmodified transformer with 30\% fewer floating-point operations per second and under 20\% of the original communication cost, while for visual question answering our method achieves performance competitive with the full LLaVA model at less than one-third of the compute and one-tenth of the bandwidth. Finally, we show that our adaptive merging is robust across varying channel conditions and provides inherent privacy benefits, substantially degrading the efficacy of model inversion attacks. Our framework provides a practical and versatile solution for deploying powerful transformer models in resource-limited edge intelligence scenarios.

**Link**: [arxiv](http://arxiv.org/abs/2509.09955v1),  [pdf](http://arxiv.org/pdf/2509.09955v1)

**Tags**: cs.LG cs.AI cs.CV eess.IV 



### Humanity's Last Exam
**Authors**: Long Phan, Alice Gatti, Ziwen Han, Nathaniel Li, Josephina Hu, Hugh Zhang, Chen Bo Calvin Zhang, Mohamed Shaaban, John Ling, Sean Shi, Michael Choi, Anish Agrawal, Arnav Chopra, Adam Khoja, Ryan Kim, Richard Ren, Jason Hausenloy, Oliver Zhang, Mantas Mazeika, Dmitry Dodonov, Tung Nguyen, Jaeho Lee, Daron Anderson, Mikhail Doroshenko, Alun Cennyth Stokes, Mobeen Mahmood, Oleksandr Pokutnyi, Oleg Iskra, Jessica P. Wang, John-Clark Levin, Mstyslav Kazakov, Fiona Feng, Steven Y. Feng, Haoran Zhao, Michael Yu, Varun Gangal, Chelsea Zou, Zihan Wang, Serguei Popov, Robert Gerbicz, Geoff Galgon, Johannes Schmitt, Will Yeadon, Yongki Lee, Scott Sauers, Alvaro Sanchez, Fabian Giska, Marc Roth, Søren Riis, Saiteja Utpala, Noah Burns, Gashaw M. Goshu, Mohinder Maheshbhai Naiya, Chidozie Agu, Zachary Giboney, Antrell Cheatom, Francesco Fournier-Facio, Sarah-Jane Crowson, Lennart Finke, Zerui Cheng, Jennifer Zampese, Ryan G. Hoerr, Mark Nandor, Hyunwoo Park, Tim Gehrunger, Jiaqi Cai, Ben McCarty, Alexis C Garretson, Edwin Taylor, Damien Sileo, Qiuyu Ren, Usman Qazi, Lianghui Li, Jungbae Nam, John B. Wydallis, Pavel Arkhipov, Jack Wei Lun Shi, Aras Bacho, Chris G. Willcocks, Hangrui Cao, Sumeet Motwani, Emily de Oliveira Santos, Johannes Veith, Edward Vendrow, Doru Cojoc, Kengo Zenitani, Joshua Robinson, Longke Tang, Yuqi Li, Joshua Vendrow, Natanael Wildner Fraga, Vladyslav Kuchkin, Andrey Pupasov Maksimov, Pierre Marion, Denis Efremov, Jayson Lynch, Kaiqu Liang, Aleksandar Mikov, Andrew Gritsevskiy, Julien Guillod, Gözdenur Demir, Dakotah Martinez, Ben Pageler, Kevin Zhou, Saeed Soori, Ori Press, Henry Tang, Paolo Rissone, Sean R. Green, Lina Brüssel, Moon Twayana, Aymeric Dieuleveut, Joseph Marvin Imperial, Ameya Prabhu, Jinzhou Yang, Nick Crispino, Arun Rao, Dimitri Zvonkine, Gabriel Loiseau, Mikhail Kalinin, Marco Lukas, Ciprian Manolescu, Nate Stambaugh, Subrata Mishra, Tad Hogg, Carlo Bosio, Brian P Coppola, Julian Salazar, Jaehyeok Jin, Rafael Sayous, Stefan Ivanov, Philippe Schwaller, Shaipranesh Senthilkuma, Andres M Bran, Andres Algaba, Kelsey Van den Houte, Lynn Van Der Sypt, Brecht Verbeken, David Noever, Alexei Kopylov, Benjamin Myklebust, Bikun Li, Lisa Schut, Evgenii Zheltonozhskii, Qiaochu Yuan, Derek Lim, Richard Stanley, Tong Yang, John Maar, Julian Wykowski, Martí Oller, Anmol Sahu, Cesare Giulio Ardito, Yuzheng Hu, Ariel Ghislain Kemogne Kamdoum, Alvin Jin, Tobias Garcia Vilchis, Yuexuan Zu, Martin Lackner, James Koppel, Gongbo Sun, Daniil S. Antonenko, Steffi Chern, Bingchen Zhao, Pierrot Arsene, Joseph M Cavanagh, Daofeng Li, Jiawei Shen, Donato Crisostomi, Wenjin Zhang, Ali Dehghan, Sergey Ivanov, David Perrella, Nurdin Kaparov, Allen Zang, Ilia Sucholutsky, Arina Kharlamova, Daniil Orel, Vladislav Poritski, Shalev Ben-David, Zachary Berger, Parker Whitfill, Michael Foster, Daniel Munro, Linh Ho, Shankar Sivarajan, Dan Bar Hava, Aleksey Kuchkin, David Holmes, Alexandra Rodriguez-Romero, Frank Sommerhage, Anji Zhang, Richard Moat, Keith Schneider, Zakayo Kazibwe, Don Clarke, Dae Hyun Kim, Felipe Meneguitti Dias, Sara Fish, Veit Elser, Tobias Kreiman, Victor Efren Guadarrama Vilchis, Immo Klose, Ujjwala Anantheswaran, Adam Zweiger, Kaivalya Rawal, Jeffery Li, Jeremy Nguyen, Nicolas Daans, Haline Heidinger, Maksim Radionov, Václav Rozhoň, Vincent Ginis, Christian Stump, Niv Cohen, Rafał Poświata, Josef Tkadlec, Alan Goldfarb, Chenguang Wang, Piotr Padlewski, Stanislaw Barzowski, Kyle Montgomery, Ryan Stendall, Jamie Tucker-Foltz, Jack Stade, T. Ryan Rogers, Tom Goertzen, Declan Grabb, Abhishek Shukla, Alan Givré, John Arnold Ambay, Archan Sen, Muhammad Fayez Aziz, Mark H Inlow, Hao He, Ling Zhang, Younesse Kaddar, Ivar Ängquist, Yanxu Chen, Harrison K Wang, Kalyan Ramakrishnan, Elliott Thornley, Antonio Terpin, Hailey Schoelkopf, Eric Zheng, Avishy Carmi, Ethan D. L. Brown, Kelin Zhu, Max Bartolo, Richard Wheeler, Martin Stehberger, Peter Bradshaw, JP Heimonen, Kaustubh Sridhar, Ido Akov, Jennifer Sandlin, Yury Makarychev, Joanna Tam, Hieu Hoang, David M. Cunningham, Vladimir Goryachev, Demosthenes Patramanis, Michael Krause, Andrew Redenti, David Aldous, Jesyin Lai, Shannon Coleman, Jiangnan Xu, Sangwon Lee, Ilias Magoulas, Sandy Zhao, Ning Tang, Michael K. Cohen, Orr Paradise, Jan Hendrik Kirchner, Maksym Ovchynnikov, Jason O. Matos, Adithya Shenoy, Michael Wang, Yuzhou Nie, Anna Sztyber-Betley, Paolo Faraboschi, Robin Riblet, Jonathan Crozier, Shiv Halasyamani, Shreyas Verma, Prashant Joshi, Eli Meril, Ziqiao Ma, Jérémy Andréoletti, Raghav Singhal, Jacob Platnick, Volodymyr Nevirkovets, Luke Basler, Alexander Ivanov, Seri Khoury, Nils Gustafsson, Marco Piccardo, Hamid Mostaghimi, Qijia Chen, Virendra Singh, Tran Quoc Khánh, Paul Rosu, Hannah Szlyk, Zachary Brown, Himanshu Narayan, Aline Menezes, Jonathan Roberts, William Alley, Kunyang Sun, Arkil Patel, Max Lamparth, Anka Reuel, Linwei Xin, Hanmeng Xu, Jacob Loader, Freddie Martin, Zixuan Wang, Andrea Achilleos, Thomas Preu, Tomek Korbak, Ida Bosio, Fereshteh Kazemi, Ziye Chen, Biró Bálint, Eve J. Y. Lo, Jiaqi Wang, Maria Inês S. Nunes, Jeremiah Milbauer, M Saiful Bari, Zihao Wang, Behzad Ansarinejad, Yewen Sun, Stephane Durand, Hossam Elgnainy, Guillaume Douville, Daniel Tordera, George Balabanian, Hew Wolff, Lynna Kvistad, Hsiaoyun Milliron, Ahmad Sakor, Murat Eron, Andrew Favre D. O., Shailesh Shah, Xiaoxiang Zhou, Firuz Kamalov, Sherwin Abdoli, Tim Santens, Shaul Barkan, Allison Tee, Robin Zhang, Alessandro Tomasiello, G. Bruno De Luca, Shi-Zhuo Looi, Vinh-Kha Le, Noam Kolt, Jiayi Pan, Emma Rodman, Jacob Drori, Carl J Fossum, Niklas Muennighoff, Milind Jagota, Ronak Pradeep, Honglu Fan, Jonathan Eicher, Michael Chen, Kushal Thaman, William Merrill, Moritz Firsching, Carter Harris, Stefan Ciobâcă, Jason Gross, Rohan Pandey, Ilya Gusev, Adam Jones, Shashank Agnihotri, Pavel Zhelnov, Mohammadreza Mofayezi, Alexander Piperski, David K. Zhang, Kostiantyn Dobarskyi, Roman Leventov, Ignat Soroko, Joshua Duersch, Vage Taamazyan, Andrew Ho, Wenjie Ma, William Held, Ruicheng Xian, Armel Randy Zebaze, Mohanad Mohamed, Julian Noah Leser, Michelle X Yuan, Laila Yacar, Johannes Lengler, Katarzyna Olszewska, Claudio Di Fratta, Edson Oliveira, Joseph W. Jackson, Andy Zou, Muthu Chidambaram, Timothy Manik, Hector Haffenden, Dashiell Stander, Ali Dasouqi, Alexander Shen, Bita Golshani, David Stap, Egor Kretov, Mikalai Uzhou, Alina Borisovna Zhidkovskaya, Nick Winter, Miguel Orbegozo Rodriguez, Robert Lauff, Dustin Wehr, Colin Tang, Zaki Hossain, Shaun Phillips, Fortuna Samuele, Fredrik Ekström, Angela Hammon, Oam Patel, Faraz Farhidi, George Medley, Forough Mohammadzadeh, Madellene Peñaflor, Haile Kassahun, Alena Friedrich, Rayner Hernandez Perez, Daniel Pyda, Taom Sakal, Omkar Dhamane, Ali Khajegili Mirabadi, Eric Hallman, Kenchi Okutsu, Mike Battaglia, Mohammad Maghsoudimehrabani, Alon Amit, Dave Hulbert, Roberto Pereira, Simon Weber, Handoko, Anton Peristyy, Stephen Malina, Mustafa Mehkary, Rami Aly, Frank Reidegeld, Anna-Katharina Dick, Cary Friday, Mukhwinder Singh, Hassan Shapourian, Wanyoung Kim, Mariana Costa, Hubeyb Gurdogan, Harsh Kumar, Chiara Ceconello, Chao Zhuang, Haon Park, Micah Carroll, Andrew R. Tawfeek, Stefan Steinerberger, Daattavya Aggarwal, Michael Kirchhof, Linjie Dai, Evan Kim, Johan Ferret, Jainam Shah, Yuzhou Wang, Minghao Yan, Krzysztof Burdzy, Lixin Zhang, Antonio Franca, Diana T. Pham, Kang Yong Loh, Joshua Robinson, Abram Jackson, Paolo Giordano, Philipp Petersen, Adrian Cosma, Jesus Colino, Colin White, Jacob Votava, Vladimir Vinnikov, Ethan Delaney, Petr Spelda, Vit Stritecky, Syed M. Shahid, Jean-Christophe Mourrat, Lavr Vetoshkin, Koen Sponselee, Renas Bacho, Zheng-Xin Yong, Florencia de la Rosa, Nathan Cho, Xiuyu Li, Guillaume Malod, Orion Weller, Guglielmo Albani, Leon Lang, Julien Laurendeau, Dmitry Kazakov, Fatimah Adesanya, Julien Portier, Lawrence Hollom, Victor Souza, Yuchen Anna Zhou, Julien Degorre, Yiğit Yalın, Gbenga Daniel Obikoya, Rai, Filippo Bigi, M. C. Boscá, Oleg Shumar, Kaniuar Bacho, Gabriel Recchia, Mara Popescu, Nikita Shulga, Ngefor Mildred Tanwie, Thomas C. H. Lux, Ben Rank, Colin Ni, Matthew Brooks, Alesia Yakimchyk, Huanxu, Liu, Stefano Cavalleri, Olle Häggström, Emil Verkama, Joshua Newbould, Hans Gundlach, Leonor Brito-Santana, Brian Amaro, Vivek Vajipey, Rynaa Grover, Ting Wang, Yosi Kratish, Wen-Ding Li, Sivakanth Gopi, Andrea Caciolai, Christian Schroeder de Witt, Pablo Hernández-Cámara, Emanuele Rodolà, Jules Robins, Dominic Williamson, Vincent Cheng, Brad Raynor, Hao Qi, Ben Segev, Jingxuan Fan, Sarah Martinson, Erik Y. Wang, Kaylie Hausknecht, Michael P. Brenner, Mao Mao, Christoph Demian, Peyman Kassani, Xinyu Zhang, David Avagian, Eshawn Jessica Scipio, Alon Ragoler, Justin Tan, Blake Sims, Rebeka Plecnik, Aaron Kirtland, Omer Faruk Bodur, D. P. Shinde, Yan Carlos Leyva Labrador, Zahra Adoul, Mohamed Zekry, Ali Karakoc, Tania C. B. Santos, Samir Shamseldeen, Loukmane Karim, Anna Liakhovitskaia, Nate Resman, Nicholas Farina, Juan Carlos Gonzalez, Gabe Maayan, Earth Anderson, Rodrigo De Oliveira Pena, Elizabeth Kelley, Hodjat Mariji, Rasoul Pouriamanesh, Wentao Wu, Ross Finocchio, Ismail Alarab, Joshua Cole, Danyelle Ferreira, Bryan Johnson, Mohammad Safdari, Liangti Dai, Siriphan Arthornthurasuk, Isaac C. McAlister, Alejandro José Moyano, Alexey Pronin, Jing Fan, Angel Ramirez-Trinidad, Yana Malysheva, Daphiny Pottmaier, Omid Taheri, Stanley Stepanic, Samuel Perry, Luke Askew, Raúl Adrián Huerta Rodríguez, Ali M. R. Minissi, Ricardo Lorena, Krishnamurthy Iyer, Arshad Anil Fasiludeen, Ronald Clark, Josh Ducey, Matheus Piza, Maja Somrak, Eric Vergo, Juehang Qin, Benjámin Borbás, Eric Chu, Jack Lindsey, Antoine Jallon, I. M. J. McInnis, Evan Chen, Avi Semler, Luk Gloor, Tej Shah, Marc Carauleanu, Pascal Lauer, Tran Đuc Huy, Hossein Shahrtash, Emilien Duc, Lukas Lewark, Assaf Brown, Samuel Albanie, Brian Weber, Warren S. Vaz, Pierre Clavier, Yiyang Fan, Gabriel Poesia Reis e Silva, Long, Lian, Marcus Abramovitch, Xi Jiang, Sandra Mendoza, Murat Islam, Juan Gonzalez, Vasilios Mavroudis, Justin Xu, Pawan Kumar, Laxman Prasad Goswami, Daniel Bugas, Nasser Heydari, Ferenc Jeanplong, Thorben Jansen, Antonella Pinto, Archimedes Apronti, Abdallah Galal, Ng Ze-An, Ankit Singh, Tong Jiang, Joan of Arc Xavier, Kanu Priya Agarwal, Mohammed Berkani, Gang Zhang, Zhehang Du, Benedito Alves de Oliveira Junior, Dmitry Malishev, Nicolas Remy, Taylor D. Hartman, Tim Tarver, Stephen Mensah, Gautier Abou Loume, Wiktor Morak, Farzad Habibi, Sarah Hoback, Will Cai, Javier Gimenez, Roselynn Grace Montecillo, Jakub Łucki, Russell Campbell, Asankhaya Sharma, Khalida Meer, Shreen Gul, Daniel Espinosa Gonzalez, Xavier Alapont, Alex Hoover, Gunjan Chhablani, Freddie Vargus, Arunim Agarwal, Yibo Jiang, Deepakkumar Patil, David Outevsky, Kevin Joseph Scaria, Rajat Maheshwari, Abdelkader Dendane, Priti Shukla, Ashley Cartwright, Sergei Bogdanov, Niels Mündler, Sören Möller, Luca Arnaboldi, Kunvar Thaman, Muhammad Rehan Siddiqi, Prajvi Saxena, Himanshu Gupta, Tony Fruhauff, Glen Sherman, Mátyás Vincze, Siranut Usawasutsakorn, Dylan Ler, Anil Radhakrishnan, Innocent Enyekwe, Sk Md Salauddin, Jiang Muzhen, Aleksandr Maksapetyan, Vivien Rossbach, Chris Harjadi, Mohsen Bahaloohoreh, Claire Sparrow, Jasdeep Sidhu, Sam Ali, Song Bian, John Lai, Eric Singer, Justine Leon Uro, Greg Bateman, Mohamed Sayed, Ahmed Menshawy, Darling Duclosel, Dario Bezzi, Yashaswini Jain, Ashley Aaron, Murat Tiryakioglu, Sheeshram Siddh, Keith Krenek, Imad Ali Shah, Jun Jin, Scott Creighton, Denis Peskoff, Zienab EL-Wasif, Ragavendran P V, Michael Richmond, Joseph McGowan, Tejal Patwardhan, Hao-Yu Sun, Ting Sun, Nikola Zubić, Samuele Sala, Stephen Ebert, Jean Kaddour, Manuel Schottdorf, Dianzhuo Wang, Gerol Petruzella, Alex Meiburg, Tilen Medved, Ali ElSheikh, S Ashwin Hebbar, Lorenzo Vaquero, Xianjun Yang, Jason Poulos, Vilém Zouhar, Sergey Bogdanik, Mingfang Zhang, Jorge Sanz-Ros, David Anugraha, Yinwei Dai, Anh N. Nhu, Xue Wang, Ali Anil Demircali, Zhibai Jia, Yuyin Zhou, Juncheng Wu, Mike He, Nitin Chandok, Aarush Sinha, Gaoxiang Luo, Long Le, Mickaël Noyé, Michał Perełkiewicz, Ioannis Pantidis, Tianbo Qi, Soham Sachin Purohit, Letitia Parcalabescu, Thai-Hoa Nguyen, Genta Indra Winata, Edoardo M. Ponti, Hanchen Li, Kaustubh Dhole, Jongee Park, Dario Abbondanza, Yuanli Wang, Anupam Nayak, Diogo M. Caetano, Antonio A. W. L. Wong, Maria del Rio-Chanona, Dániel Kondor, Pieter Francois, Ed Chalstrey, Jakob Zsambok, Dan Hoyer, Jenny Reddish, Jakob Hauser, Francisco-Javier Rodrigo-Ginés, Suchandra Datta, Maxwell Shepherd, Thom Kamphuis, Qizheng Zhang, Hyunjun Kim, Ruiji Sun, Jianzhu Yao, Franck Dernoncourt, Satyapriya Krishna, Sina Rismanchian, Bonan Pu, Francesco Pinto, Yingheng Wang, Kumar Shridhar, Kalon J. Overholt, Glib Briia, Hieu Nguyen, David, Soler Bartomeu, Tony CY Pang, Adam Wecker, Yifan Xiong, Fanfei Li, Lukas S. Huber, Joshua Jaeger, Romano De Maddalena, Xing Han Lù, Yuhui Zhang, Claas Beger, Patrick Tser Jern Kon, Sean Li, Vivek Sanker, Ming Yin, Yihao Liang, Xinlu Zhang, Ankit Agrawal, Li S. Yifei, Zechen Zhang, Mu Cai, Yasin Sonmez, Costin Cozianu, Changhao Li, Alex Slen, Shoubin Yu, Hyun Kyu Park, Gabriele Sarti, Marcin Briański, Alessandro Stolfo, Truong An Nguyen, Mike Zhang, Yotam Perlitz, Jose Hernandez-Orallo, Runjia Li, Amin Shabani, Felix Juefei-Xu, Shikhar Dhingra, Orr Zohar, My Chiffon Nguyen, Alexander Pondaven, Abdurrahim Yilmaz, Xuandong Zhao, Chuanyang Jin, Muyan Jiang, Stefan Todoran, Xinyao Han, Jules Kreuer, Brian Rabern, Anna Plassart, Martino Maggetti, Luther Yap, Robert Geirhos, Jonathon Kean, Dingsu Wang, Sina Mollaei, Chenkai Sun, Yifan Yin, Shiqi Wang, Rui Li, Yaowen Chang, Anjiang Wei, Alice Bizeul, Xiaohan Wang, Alexandre Oliveira Arrais, Kushin Mukherjee, Jorge Chamorro-Padial, Jiachen Liu, Xingyu Qu, Junyi Guan, Adam Bouyamourn, Shuyu Wu, Martyna Plomecka, Junda Chen, Mengze Tang, Jiaqi Deng, Shreyas Subramanian, Haocheng Xi, Haoxuan Chen, Weizhi Zhang, Yinuo Ren, Haoqin Tu, Sejong Kim, Yushun Chen, Sara Vera Marjanović, Junwoo Ha, Grzegorz Luczyna, Jeff J. Ma, Zewen Shen, Dawn Song, Cedegao E. Zhang, Zhun Wang, Gaël Gendron, Yunze Xiao, Leo Smucker, Erica Weng, Kwok Hao Lee, Zhe Ye, Stefano Ermon, Ignacio D. Lopez-Miguel, Theo Knights, Anthony Gitter, Namkyu Park, Boyi Wei, Hongzheng Chen, Kunal Pai, Ahmed Elkhanany, Han Lin, Philipp D. Siedler, Jichao Fang, Ritwik Mishra, Károly Zsolnai-Fehér, Xilin Jiang, Shadab Khan, Jun Yuan, Rishab Kumar Jain, Xi Lin, Mike Peterson, Zhe Wang, Aditya Malusare, Maosen Tang, Isha Gupta, Ivan Fosin, Timothy Kang, Barbara Dworakowska, Kazuki Matsumoto, Guangyao Zheng, Gerben Sewuster, Jorge Pretel Villanueva, Ivan Rannev, Igor Chernyavsky, Jiale Chen, Deepayan Banik, Ben Racz, Wenchao Dong, Jianxin Wang, Laila Bashmal, Duarte V. Gonçalves, Wei Hu, Kaushik Bar, Ondrej Bohdal, Atharv Singh Patlan, Shehzaad Dhuliawala, Caroline Geirhos, Julien Wist, Yuval Kansal, Bingsen Chen, Kutay Tire, Atak Talay Yücel, Brandon Christof, Veerupaksh Singla, Zijian Song, Sanxing Chen, Jiaxin Ge, Kaustubh Ponkshe, Isaac Park, Tianneng Shi, Martin Q. Ma, Joshua Mak, Sherwin Lai, Antoine Moulin, Zhuo Cheng, Zhanda Zhu, Ziyi Zhang, Vaidehi Patil, Ketan Jha, Qiutong Men, Jiaxuan Wu, Tianchi Zhang, Bruno Hebling Vieira, Alham Fikri Aji, Jae-Won Chung, Mohammed Mahfoud, Ha Thi Hoang, Marc Sperzel, Wei Hao, Kristof Meding, Sihan Xu, Vassilis Kostakos, Davide Manini, Yueying Liu, Christopher Toukmaji, Jay Paek, Eunmi Yu, Arif Engin Demircali, Zhiyi Sun, Ivan Dewerpe, Hongsen Qin, Roman Pflugfelder, James Bailey, Johnathan Morris, Ville Heilala, Sybille Rosset, Zishun Yu, Peter E. Chen, Woongyeong Yeo, Eeshaan Jain, Ryan Yang, Sreekar Chigurupati, Julia Chernyavsky, Sai Prajwal Reddy, Subhashini Venugopalan, Hunar Batra, Core Francisco Park, Hieu Tran, Guilherme Maximiano, Genghan Zhang, Yizhuo Liang, Hu Shiyu, Rongwu Xu, Rui Pan, Siddharth Suresh, Ziqi Liu, Samaksh Gulati, Songyang Zhang, Peter Turchin, Christopher W. Bartlett, Christopher R. Scotese, Phuong M. Cao, Aakaash Nattanmai, Gordon McKellips, Anish Cheraku, Asim Suhail, Ethan Luo, Marvin Deng, Jason Luo, Ashley Zhang, Kavin Jindel, Jay Paek, Kasper Halevy, Allen Baranov, Michael Liu, Advaith Avadhanam, David Zhang, Vincent Cheng, Brad Ma, Evan Fu, Liam Do, Joshua Lass, Hubert Yang, Surya Sunkari, Vishruth Bharath, Violet Ai, James Leung, Rishit Agrawal, Alan Zhou, Kevin Chen, Tejas Kalpathi, Ziqi Xu, Gavin Wang, Tyler Xiao, Erik Maung, Sam Lee, Ryan Yang, Roy Yue, Ben Zhao, Julia Yoon, Sunny Sun, Aryan Singh, Ethan Luo, Clark Peng, Tyler Osbey, Taozhi Wang, Daryl Echeazu, Hubert Yang, Timothy Wu, Spandan Patel, Vidhi Kulkarni, Vijaykaarti Sundarapandiyan, Ashley Zhang, Andrew Le, Zafir Nasim, Srikar Yalam, Ritesh Kasamsetty, Soham Samal, Hubert Yang, David Sun, Nihar Shah, Abhijeet Saha, Alex Zhang, Leon Nguyen, Laasya Nagumalli, Kaixin Wang, Alan Zhou, Aidan Wu, Jason Luo, Anwith Telluri, Summer Yue, Alexandr Wang, Dan Hendrycks

**Updated**: 2025-09-12T04:08:53Z

**Summary**: Benchmarks are important tools for tracking the rapid advancements in large language model (LLM) capabilities. However, benchmarks are not keeping pace in difficulty: LLMs now achieve over 90\% accuracy on popular benchmarks like MMLU, limiting informed measurement of state-of-the-art LLM capabilities. In response, we introduce Humanity's Last Exam (HLE), a multi-modal benchmark at the frontier of human knowledge, designed to be the final closed-ended academic benchmark of its kind with broad subject coverage. HLE consists of 2,500 questions across dozens of subjects, including mathematics, humanities, and the natural sciences. HLE is developed globally by subject-matter experts and consists of multiple-choice and short-answer questions suitable for automated grading. Each question has a known solution that is unambiguous and easily verifiable, but cannot be quickly answered via internet retrieval. State-of-the-art LLMs demonstrate low accuracy and calibration on HLE, highlighting a significant gap between current LLM capabilities and the expert human frontier on closed-ended academic questions. To inform research and policymaking upon a clear understanding of model capabilities, we publicly release HLE at https://lastexam.ai.

**Link**: [arxiv](http://arxiv.org/abs/2501.14249v8),  [pdf](http://arxiv.org/pdf/2501.14249v8)

**Tags**: cs.LG cs.AI cs.CL 



### Toward Green Code: Prompting Small Language Models for Energy-Efficient   Code Generation
**Authors**: Humza Ashraf, Syed Muhammad Danish, Zeeshan Sattar

**Updated**: 2025-09-12T03:38:15Z

**Summary**: There is a growing concern about the environmental impact of large language models (LLMs) in software development, particularly due to their high energy use and carbon footprint. Small Language Models (SLMs) offer a more sustainable alternative, requiring fewer computational resources while remaining effective for fundamental programming tasks. In this study, we investigate whether prompt engineering can improve the energy efficiency of SLMs in code generation. We evaluate four open-source SLMs, StableCode-Instruct-3B, Qwen2.5-Coder-3B-Instruct, CodeLlama-7B-Instruct, and Phi-3-Mini-4K-Instruct, across 150 Python problems from LeetCode, evenly distributed into easy, medium, and hard categories. Each model is tested under four prompting strategies: role prompting, zero-shot, few-shot, and chain-of-thought (CoT). For every generated solution, we measure runtime, memory usage, and energy consumption, comparing the results with a human-written baseline. Our findings show that CoT prompting provides consistent energy savings for Qwen2.5-Coder and StableCode-3B, while CodeLlama-7B and Phi-3-Mini-4K fail to outperform the baseline under any prompting strategy. These results highlight that the benefits of prompting are model-dependent and that carefully designed prompts can guide SLMs toward greener software development.

**Link**: [arxiv](http://arxiv.org/abs/2509.09947v1),  [pdf](http://arxiv.org/pdf/2509.09947v1)

**Tags**: cs.SE 



### Agentic Vehicles for Human-Centered Mobility Systems
**Authors**: Jiangbo Yu

**Updated**: 2025-09-12T03:15:11Z

**Summary**: Autonomy, from the Greek autos (self) and nomos (law), refers to the capacity to operate according to internal rules without external control. Autonomous vehicles (AuVs) are therefore understood as systems that perceive their environment and execute pre-programmed tasks independently of external input, consistent with the SAE levels of automated driving. Yet recent research and real-world deployments have begun to showcase vehicles that exhibit behaviors outside the scope of this definition. These include natural language interaction with humans, goal adaptation, contextual reasoning, external tool use, and the handling of unforeseen ethical dilemmas, enabled in part by multimodal large language models (LLMs). These developments highlight not only a gap between technical autonomy and the broader cognitive and social capacities required for human-centered mobility, but also the emergence of a form of vehicle intelligence that currently lacks a clear designation. To address this gap, the paper introduces the concept of agentic vehicles (AgVs): vehicles that integrate agentic AI systems to reason, adapt, and interact within complex environments. It synthesizes recent advances in agentic systems and suggests how AgVs can complement and even reshape conventional autonomy to ensure mobility services are aligned with user and societal needs. The paper concludes by outlining key challenges in the development and governance of AgVs and their potential role in shaping future agentic transportation systems.

**Link**: [arxiv](http://arxiv.org/abs/2507.04996v5),  [pdf](http://arxiv.org/pdf/2507.04996v5)

**Tags**: cs.CY cs.CE cs.CL cs.HC cs.RO 



### SmartCoder-R1: Towards Secure and Explainable Smart Contract Generation   with Security-Aware Group Relative Policy Optimization
**Authors**: Lei Yu, Jingyuan Zhang, Xin Wang, Jiajia Ma, Li Yang, Fengjun Zhang

**Updated**: 2025-09-12T03:14:50Z

**Summary**: Smart contracts automate the management of high-value assets, where vulnerabilities can lead to catastrophic financial losses. This challenge is amplified in Large Language Models (LLMs) by two interconnected failures: they operate as unauditable "black boxes" lacking a transparent reasoning process, and consequently, generate code riddled with critical security vulnerabilities. To address both issues, we propose SmartCoder-R1 (based on Qwen2.5-Coder-7B), a novel framework for secure and explainable smart contract generation. It begins with Continual Pre-training (CPT) to specialize the model. We then apply Long Chain-of-Thought Supervised Fine-Tuning (L-CoT SFT) on 7,998 expert-validated reasoning-and-code samples to train the model to emulate human security analysis. Finally, to directly mitigate vulnerabilities, we employ Security-Aware Group Relative Policy Optimization (S-GRPO), a reinforcement learning phase that refines the generation policy by optimizing a weighted reward signal for compilation success, security compliance, and format correctness. Evaluated against 17 baselines on a benchmark of 756 real-world functions, SmartCoder-R1 establishes a new state of the art, achieving top performance across five key metrics: a ComPass of 87.70%, a VulRate of 8.60%, a SafeAval of 80.16%, a FuncRate of 53.84%, and a FullRate of 50.53%. This FullRate marks a 45.79% relative improvement over the strongest baseline, DeepSeek-R1. Crucially, its generated reasoning also excels in human evaluations, achieving high-quality ratings for Functionality (82.7%), Security (85.3%), and Clarity (90.7%).

**Link**: [arxiv](http://arxiv.org/abs/2509.09942v1),  [pdf](http://arxiv.org/pdf/2509.09942v1)

**Tags**: cs.CR cs.AI cs.SE 



### Enhancing Speech Large Language Models with Prompt-Aware Mixture of   Audio Encoders
**Authors**: Weiqiao Shan, Yuang Li, Yuhao Zhang, Yingfeng Luo, Chen Xu, Xiaofeng Zhao, Long Meng, Yunfei Lu, Min Zhang, Hao Yang, Tong Xiao, Jingbo Zhu

**Updated**: 2025-09-12T03:03:36Z

**Summary**: Connecting audio encoders with large language models (LLMs) allows the LLM to perform various audio understanding tasks, such as automatic speech recognition (ASR) and audio captioning (AC). Most research focuses on training an adapter layer to generate a unified audio feature for the LLM. However, different tasks may require distinct features that emphasize either semantic or acoustic aspects, making task-specific audio features more desirable. In this paper, we propose Prompt-aware Mixture (PaM) to enhance the Speech LLM that uses multiple audio encoders. Our approach involves using different experts to extract different features based on the prompt that indicates different tasks. Experiments demonstrate that with PaM, only one Speech LLM surpasses the best performances achieved by all single-encoder Speech LLMs on ASR, Speaker Number Verification, and AC tasks. PaM also outperforms other feature fusion baselines, such as concatenation and averaging. Our code would be available at: https://github.com/shanweiqiao/PaM

**Link**: [arxiv](http://arxiv.org/abs/2502.15178v2),  [pdf](http://arxiv.org/pdf/2502.15178v2)

**Tags**: eess.AS cs.SD 



